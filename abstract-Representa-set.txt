1. Front Neurosci. 2023 Jan 4;16:1075288. doi: 10.3389/fnins.2022.1075288. 
eCollection 2022.

The Temporal Voice Areas are not "just" Speech Areas.

Trapeau R(1), Thoret E(2)(3), Belin P(1)(4).

Author information:
(1)La Timone Neuroscience Institute, CNRS and Aix-Marseille University, UMR 
7289, Marseille, France.
(2)Aix-Marseille University, CNRS, UMR7061 PRISM, UMR7020 LIS, Marseille, 
France.
(3)Institute of Language, Communication and the Brain (ILCB), Marseille, France.
(4)Department of Psychology, Montreal University, Montreal, QC, Canada.

The Temporal Voice Areas (TVAs) respond more strongly to speech sounds than to 
non-speech vocal sounds, but does this make them Temporal "Speech" Areas? We 
provide a perspective on this issue by combining univariate, multivariate, and 
representational similarity analyses of fMRI activations to a balanced set of 
speech and non-speech vocal sounds. We find that while speech sounds activate 
the TVAs more than non-speech vocal sounds, which is likely related to their 
larger temporal modulations in syllabic rate, they do not appear to activate 
additional areas nor are they segregated from the non-speech vocal sounds when 
their higher activation is controlled. It seems safe, then, to continue calling 
these regions the Temporal Voice Areas.

Copyright © 2023 Trapeau, Thoret and Belin.

DOI: 10.3389/fnins.2022.1075288
PMCID: PMC9846853
PMID: 36685244

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


2. Psychophysiology. 2023 Jan 18:e14240. doi: 10.1111/psyp.14240. Online ahead of 
print.

The optimal balance of controlled and spontaneous processing in insight problem 
solving: fMRI evidence from Chinese idiom guessing.

Liu D(1), Hao L(2)(3), Han L(4), Zhou Y(1), Qin S(3), Niki K(5)(6), Shen W(7), 
Shi B(1)(2), Luo J(1)(8).

Author information:
(1)Beijing Key Laboratory of Learning and Cognition & School of Psychology, 
Capital Normal University, Beijing, China.
(2)College of Teacher Education, Southwest University, Chongqing, China.
(3)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brain Research, Faculty of Psychology at Beijing Normal 
University, Beijing, China.
(4)School of Psychology, Shandong Normal University, Jinan, China.
(5)Human Informatics Research Institute, Advanced Industrial Science and 
Technology, Tsukuba, Japan.
(6)Keio University Graduate School of Human Relations, Keio University, Tokyo, 
Japan.
(7)School of Public Administration and Institute of Applied Psychology, Hohai 
University, Nanjing, China.
(8)Department of Psychology, Shaoxing University, Shaoxing, China.

Cognitive control is a key factor in insight generation. However, the 
neurocognitive mechanisms underlying the generation of insight for different 
cognitive control remain poorly understood. This study developed a parametric 
fMRI design, wherein hints for solving Chinese idiom riddles were gradually 
provided in a stepwise manner (from the first hint, H1, to the final hint, H4). 
By classifying the step-specific items solved in different hint-uncovering 
steps/conditions, we could identify insightful responses for different levels of 
spontaneous or controlled processing. At the behavioral level, the number of 
insightful problem solving trials reached the maximum at a intermediate level of 
the cognitively controlled processing and the spontaneously idea generating in 
H3, while the bilateral insular cortex and thalamus showed the robust 
engagement, implying the function of these regions in making the optimal balance 
between external hint processing and internal generated ideas. In addition, we 
identified brain areas, including the dorsolateral prefrontal cortex (dlPFC), 
angular gyrus (AG), dorsal anterior cingulate cortex (dACC), and precuneus 
(PreC), whose activities were parametrically increased with the levels of 
controlled (from H1 to H4) insightful processing which were increasingly 
produced by the sequentially revealed hints. Further representational similarity 
analysis (RSA) found that spontaneous processing in insight featured greater 
within-condition representational variabilities in widely distributed regions in 
the executive, salience, and default networks. Altogether, the present study 
provided new evidence for the relationship between the process of cognitive 
control and that of spontaneous idea generation in insight problem solving and 
demystified the function of the insula and thalamus as an interactive interface 
for the optimal balance of these two processes.

© 2023 Society for Psychophysiological Research.

DOI: 10.1111/psyp.14240
PMID: 36651323


3. Neurosci Res. 2023 Jan 10:S0168-0102(23)00001-9. doi: 
10.1016/j.neures.2023.01.001. Online ahead of print.

Distinct neural representations of hand movement direction between motor imagery 
and execution in the presupplementary motor area.

Yang Y(1), Yang H(2), Imai F(1), Ogawa K(3).

Author information:
(1)Department of Psychology, Graduate School of Humanities and Human Sciences, 
Hokkaido University.
(2)Institute for Advanced Co-Creation Studies, Osaka University.
(3)Department of Psychology, Graduate School of Humanities and Human Sciences, 
Hokkaido University. Electronic address: ogawa@let.hokudai.ac.jp.

Motor simulation theory proposes a functional equivalence between motor 
execution (ME) and its simulation, suggesting that motor imagery (MI) is the 
self-intentioned simulation of one's actions. This study used functional 
magnetic resonance imaging (fMRI) with multivoxel pattern analysis to test 
whether the direction of hand movement is represented with a similar neural code 
between ME and MI. In our study, participants used their right hand to move an 
on-screen cursor in the left-right direction with a joystick or imagined the 
same movement without execution. The results indicated that the left-right 
direction as well as their modality (ME or MI) could be decoded significantly 
above the chance level in the presupplementary motor area (pre-SMA) and primary 
visual cortex (V1). Next, we used activation patterns of ME as inputs to the 
decoder to predict hand move directions in MI sessions and found a significantly 
higher-than-chance accuracy only in V1, not in pre-SMA. Moreover, the 
representational similarity analysis showed similar activation patterns for the 
same directions between ME and MI in V1 but not in pre-SMA. This study's finding 
indicates distinct spatial activation patterns for movement directions between 
ME and MI in pre-SMA.

Copyright © 2023 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.neures.2023.01.001
PMID: 36638915

Conflict of interest statement: Declaration of Interest None.


4. Hum Brain Mapp. 2023 Jan 13. doi: 10.1002/hbm.26189. Online ahead of print.

Neural representations of the perception of handwritten digits and visual 
objects from a convolutional neural network compared to humans.

Lee J(1), Jung M(1), Lustig N(1), Lee JH(1).

Author information:
(1)Department of Brain and Cognitive Engineering, Korea University, Seoul, 
Republic of Korea.

We investigated neural representations for visual perception of 10 handwritten 
digits and six visual objects from a convolutional neural network (CNN) and 
humans using functional magnetic resonance imaging (fMRI). Once our CNN model 
was fine-tuned using a pre-trained VGG16 model to recognize the visual stimuli 
from the digit and object categories, representational similarity analysis (RSA) 
was conducted using neural activations from fMRI and feature representations 
from the CNN model across all 16 classes. The encoded neural representation of 
the CNN model exhibited the hierarchical topography mapping of the human visual 
system. The feature representations in the lower convolutional (Conv) layers 
showed greater similarity with the neural representations in the early visual 
areas and parietal cortices, including the posterior cingulate cortex. The 
feature representations in the higher Conv layers were encoded in the 
higher-order visual areas, including the ventral/medial/dorsal stream and middle 
temporal complex. The neural representations in the classification layers were 
observed mainly in the ventral stream visual cortex (including the inferior 
temporal cortex), superior parietal cortex, and prefrontal cortex. There was a 
surprising similarity between the neural representations from the CNN model and 
the neural representations for human visual perception in the context of the 
perception of digits versus objects, particularly in the primary visual and 
associated areas. This study also illustrates the uniqueness of human visual 
perception. Unlike the CNN model, the neural representation of digits and 
objects for humans is more widely distributed across the whole brain, including 
the frontal and temporal areas.

© 2023 The Authors. Human Brain Mapping published by Wiley Periodicals LLC.

DOI: 10.1002/hbm.26189
PMID: 36637109


5. Hum Brain Mapp. 2022 Dec 29. doi: 10.1002/hbm.26195. Online ahead of print.

The depth of semantic processing modulates cross-language pattern similarity in 
Chinese-English bilinguals.

Li H(1)(2)(3), Cao Y(1)(2)(3), Chen C(4), Liu X(1)(2)(3), Zhang S(1)(2)(3), Mei 
L(1).

Author information:
(1)Philosophy and Social Science Laboratory of Reading and Development in 
Children and Adolescents, South China Normal University, Ministry of Education, 
Guangzhou, China.
(2)School of Psychology, South China Normal University, Guangzhou, China.
(3)Guangdong Key Laboratory of Mental Health and Cognitive Science, South China 
Normal University, Guangzhou, China.
(4)Department of Psychological Science, University of California, Irvine, 
California, USA.

Previous studies have investigated factors related to the degree of 
cross-language overlap in brain activations in bilinguals/multilinguals. 
However, it is still unclear whether and how the depth of semantic processing (a 
critical task-related factor) affects the neural pattern similarity between 
native and second languages. To address this question, 26 Chinese-English 
bilinguals were scanned with fMRI while performing a word naming task (i.e., a 
task with shallow semantic processing) and a semantic judgment task (i.e., a 
task with deep semantic processing) in both native and second languages. Based 
on three sets of representational similarity analysis (whole brain, ROI-based, 
and within-language vs. cross-language semantic representation), we found that 
select regions in the reading brain network showed higher cross-language pattern 
similarity and higher cross-language semantic representations during deep 
semantic processing than during shallow semantic processing. These results 
suggest that compared to shallow semantic processing, deep semantic processing 
may lead to greater language-independent processing (i.e., cross-language 
semantic representation) and cross-language pattern similarity, and provide 
direct quantitative neuroimaging evidence for cognitive models of bilingual 
lexical memory.

© 2022 The Authors. Human Brain Mapping published by Wiley Periodicals LLC.

DOI: 10.1002/hbm.26195
PMID: 36579666


6. Neuropsychologia. 2023 Jan 28;179:108464. doi: 
10.1016/j.neuropsychologia.2022.108464. Epub 2022 Dec 21.

Neural similarities and differences between native and second languages in the 
bilateral fusiform cortex in Chinese-English bilinguals.

Liu X(1), Hu L(1), Qu J(1), Zhang S(1), Su X(1), Li A(1), Mei L(2).

Author information:
(1)Philosophy and Social Science Laboratory of Reading and Development in 
Children and Adolescents (South China Normal University), Ministry of Education, 
China; School of Psychology, South China Normal University, 510631, Guangzhou, 
China; Guangdong Key Laboratory of Mental Health and Cognitive Science, South 
China Normal University, 510631, Guangzhou, China.
(2)Philosophy and Social Science Laboratory of Reading and Development in 
Children and Adolescents (South China Normal University), Ministry of Education, 
China. Electronic address: mll830925@126.com.

In the field of bilingualism, researchers have proposed an assimilation 
hypothesis that posits that bilinguals apply the neural network of their native 
language to process their second language. In Chinese-English bilinguals, the 
bilateral fusiform gyrus has been identified as the key brain region showing the 
assimilation process. Specifically, in contrast to left-lateralized activation 
in the fusiform gyrus in native English speakers, Chinese-English bilinguals 
recruit the bilateral fusiform cortex to process English words as they do in the 
processing of Chinese characters. Nevertheless, it is unclear which type of 
information processing is assimilated in the fusiform gyrus. Using 
representational similarity analysis (RSA) and psychophysiological interaction 
(PPI) analysis, this study examined the differences in information 
representation and functional connectivity between both languages in the 
fusiform subregions in Chinese-English bilinguals. Univariate analysis revealed 
that both Chinese and English naming elicited strong activations in the 
bilateral fusiform gyrus, which confirmed the assimilation process at the 
activation intensity level. RSA indicated that the neural pattern of English 
phonological information was assimilated by Chinese in the anterior and middle 
right fusiform gyrus, while those of orthographic and visual form information 
were not. Further PPI analysis demonstrated that the neural representation of 
English phonological information in the right anterior fusiform subregion was 
related to its interaction with the frontotemporal areas for high-level 
linguistic processing, while the neural representation of English orthographic 
information in the right middle fusiform subregion was linked to its interaction 
with the left inferior occipital cortex for visual processing. These results 
suggest that, despite the recruitment of similar neural resources in one's 
native and second languages, the assimilation of information representation is 
limited in the bilateral fusiform cortex. Our results shed light on the neural 
mechanisms of second language processing.

Copyright © 2022 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2022.108464
PMID: 36565993 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


7. Cereb Cortex. 2022 Dec 23:bhac501. doi: 10.1093/cercor/bhac501. Online ahead of 
print.

Neuroimaging evidence for the direct role of auditory scene analysis in object 
perception.

Gurariy G(1), Randall R(2), Greenberg AS(1).

Author information:
(1)Department of Biomedical Engineering, Medical College of Wisconsin and 
Marquette University, 8701 W Watertown Plank Rd, Milwaukee, WI 53233, United 
States.
(2)School of Music and Neuroscience Institute, Carnegie Mellon University, 
Pittsburgh, PA 15213, United States.

Auditory Scene Analysis (ASA) refers to the grouping of acoustic signals into 
auditory objects. Previously, we have shown that perceived musicality of 
auditory sequences varies with high-level organizational features. Here, we 
explore the neural mechanisms mediating ASA and auditory object perception. 
Participants performed musicality judgments on randomly generated pure-tone 
sequences and manipulated versions of each sequence containing low-level changes 
(amplitude; timbre). Low-level manipulations affected auditory object perception 
as evidenced by changes in musicality ratings. fMRI was used to measure neural 
activation to sequences rated most and least musical, and the altered versions 
of each sequence. Next, we generated two partially overlapping networks: (i) a 
music processing network (music localizer) and (ii) an ASA network (base 
sequences vs. ASA manipulated sequences). Using Representational Similarity 
Analysis, we correlated the functional profiles of each ROI to a model generated 
from behavioral musicality ratings as well as models corresponding to low-level 
feature processing and music perception. Within overlapping regions, areas near 
primary auditory cortex correlated with low-level ASA models, whereas right IPS 
was correlated with musicality ratings. Shared neural mechanisms that correlate 
with behavior and underlie both ASA and music perception suggests that low-level 
features of auditory stimuli play a role in auditory object perception.

© The Author(s) 2022. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permission@oup.com.

DOI: 10.1093/cercor/bhac501
PMID: 36562994


8. J Neurosci. 2023 Jan 18;43(3):484-500. doi: 10.1523/JNEUROSCI.1546-22.2022. Epub 
2022 Dec 19.

The Spatiotemporal Neural Dynamics of Object Recognition for Natural Images and 
Line Drawings.

Singer JJD(1)(2), Cichy RM(2), Hebart MN(3)(4).

Author information:
(1)Max Planck Institute for Human Cognitive and Brain Sciences, Vision and 
Computational Cognition Group, 04103 Leipzig, Germany johannes.singer@arcor.de.
(2)Department of Education and Psychology, Freie Universität Berlin, 14195 
Berlin, Germany.
(3)Max Planck Institute for Human Cognitive and Brain Sciences, Vision and 
Computational Cognition Group, 04103 Leipzig, Germany.
(4)Department of Medicine, Justus-Liebig-Universität Gießen, 35390 Gießen, 
Germany.

Drawings offer a simple and efficient way to communicate meaning. While line 
drawings capture only coarsely how objects look in reality, we still perceive 
them as resembling real-world objects. Previous work has shown that this 
perceived similarity is mirrored by shared neural representations for drawings 
and natural images, which suggests that similar mechanisms underlie the 
recognition of both. However, other work has proposed that representations of 
drawings and natural images become similar only after substantial processing has 
taken place, suggesting distinct mechanisms. To arbitrate between those 
alternatives, we measured brain responses resolved in space and time using fMRI 
and MEG, respectively, while human participants (female and male) viewed images 
of objects depicted as photographs, line drawings, or sketch-like drawings. 
Using multivariate decoding, we demonstrate that object category information 
emerged similarly fast and across overlapping regions in occipital, 
ventral-temporal, and posterior parietal cortex for all types of depiction, yet 
with smaller effects at higher levels of visual abstraction. In addition, 
cross-decoding between depiction types revealed strong generalization of object 
category information from early processing stages on. Finally, by combining fMRI 
and MEG data using representational similarity analysis, we found that visual 
information traversed similar processing stages for all types of depiction, yet 
with an overall stronger representation for photographs. Together, our results 
demonstrate broad commonalities in the neural dynamics of object recognition 
across types of depiction, thus providing clear evidence for shared neural 
mechanisms underlying recognition of natural object images and abstract 
drawings.SIGNIFICANCE STATEMENT When we see a line drawing, we effortlessly 
recognize it as an object in the world despite its simple and abstract style. 
Here we asked to what extent this correspondence in perception is reflected in 
the brain. To answer this question, we measured how neural processing of objects 
depicted as photographs and line drawings with varying levels of detail (from 
natural images to abstract line drawings) evolves over space and time. We find 
broad commonalities in the spatiotemporal dynamics and the neural 
representations underlying the perception of photographs and even abstract 
drawings. These results indicate a shared basic mechanism supporting recognition 
of drawings and natural images.

Copyright © 2023 Singer et al.

DOI: 10.1523/JNEUROSCI.1546-22.2022
PMID: 36535769 [Indexed for MEDLINE]


9. Neuroimage. 2023 Jan;265:119804. doi: 10.1016/j.neuroimage.2022.119804. Epub 
2022 Dec 9.

Stress disrupts insight-driven mnemonic reconfiguration in the medial temporal 
lobe.

Grob AM(1), Milivojevic B(2), Alink A(3), Doeller CF(4), Schwabe L(5).

Author information:
(1)Department of Cognitive Psychology, Institute of Psychology, Universität 
Hamburg, Von-Melle-Park 5, Hamburg 20146, Germany.
(2)Donders Institute for Brain, Cognition and Behaviour, Radboud University, 
Nijmegen 6525 AJ, the Netherlands.
(3)Department of General Psychology, Institute of Psychology, Universität 
Hamburg, Hamburg 20146, Germany; Institute of Systems Neuroscience, University 
Medical Center Hamburg-Eppendorf, Hamburg, 20246, Germany.
(4)Max-Planck-Insitute for Human Cognitive and Brain Sciences, Leipzig 04103, 
Germany; Kavli Institute for Systems Neuroscience, Centre for Neural 
Computation, The Egil and Pauline Braathen and Fred Kavli Centre for Cortical 
Microcircuits, Jebsen Centre for Alzheimer's Disease, Norwegian University of 
Science and Technology, Trondheim 7491, Norway; Wilhelm Wundt Institute of 
Psychology, Leipzig University, Leipzig 04109, Germany.
(5)Department of Cognitive Psychology, Institute of Psychology, Universität 
Hamburg, Von-Melle-Park 5, Hamburg 20146, Germany. Electronic address: 
Lars.Schwabe@uni-hamburg.de.

Memories are not stored in isolation. Insight into the relationship of initially 
unrelated events may trigger a flexible reconfiguration of the mnemonic 
representation of these events. Such representational changes allow the 
integration of events into coherent episodes and help to build up-to-date-models 
of the world around us. This process is, however, frequently impaired in 
stress-related mental disorders resulting in symptoms such as fragmented 
memories in PTSD. Here, we combined a real life-like narrative-insight task, in 
which participants learned how initially separate events are linked, with 
fMRI-based representational similarity analysis to test if and how acute stress 
interferes with the insight-driven reconfiguration of memories. Our results 
showed that stress reduced the activity of medial temporal and prefrontal areas 
when participants gained insight into the link between events. Moreover, stress 
abolished the insight-related increase in representational dissimilarity for 
linked events in the anterior part of the hippocampus as well as its association 
with measures of subsequent memory that we observed in non-stressed controls. 
However, memory performance, as assessed in a forced-choice recognition test, 
was even enhanced in the stress group. Our findings suggest that acute stress 
impedes the neural integration of events into coherent episodes but promotes 
long-term memory for these integrated narratives and may thus have implications 
for understanding memory distortions in stress-related mental disorders.

Copyright © 2022 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2022.119804
PMID: 36503160 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare no competing interests


10. Neuroimage. 2023 Jan;265:119775. doi: 10.1016/j.neuroimage.2022.119775. Epub 
2022 Nov 28.

Neural representations of self-generated thought during think-aloud fMRI.

Li HX(1), Lu B(1), Wang YW(1), Li XY(1), Chen X(1), Yan CG(2).

Author information:
(1)CAS Key Laboratory of Behavioral Science, Institute of Psychology, Beijing, 
China; Department of Psychology, University of Chinese Academy of Sciences, 
Beijing, China; International Big-Data Center for Depression Research, Institute 
of Psychology, Chinese Academy of Sciences, Beijing, China.
(2)CAS Key Laboratory of Behavioral Science, Institute of Psychology, Beijing, 
China; Department of Psychology, University of Chinese Academy of Sciences, 
Beijing, China; International Big-Data Center for Depression Research, Institute 
of Psychology, Chinese Academy of Sciences, Beijing, China; Magnetic Resonance 
Imaging Research Center, Institute of Psychology, Chinese Academy of Sciences, 
Beijing, China. Electronic address: yancg@psych.ac.cn.

Is the brain at rest during the so-called resting state? Ongoing experiences in 
the resting state vary in unobserved and uncontrolled ways across time, 
individuals, and populations. However, the role of self-generated thoughts in 
resting-state fMRI remains largely unexplored. In this study, we collected 
real-time self-generated thoughts during "resting-state" fMRI scans via the 
think-aloud method (i.e., think-aloud fMRI), which required participants to 
report whatever they were currently thinking. We first investigated brain 
activation patterns during a think-aloud condition and found that significantly 
activated brain areas included all brain regions required for speech. We then 
calculated the relationship between divergence in thought content and brain 
activation during think-aloud and found that divergence in thought content was 
associated with many brain regions. Finally, we explored the neural 
representation of self-generated thoughts by performing representational 
similarity analysis (RSA) at three neural scales: a voxel-wise whole-brain 
searchlight level, a region-level whole-brain analysis using the Schaefer 
400-parcels, and at the systems level using the Yeo seven-networks. We found 
that "resting-state" self-generated thoughts were distributed across a wide 
range of brain regions involving all seven Yeo networks. This study highlights 
the value of considering ongoing experiences during resting-state fMRI and 
providing preliminary methodological support for think-aloud fMRI.

Copyright © 2022. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2022.119775
PMID: 36455761 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare no conflicts of interest.


11. Front Neurosci. 2022 Nov 11;16:797277. doi: 10.3389/fnins.2022.797277. 
eCollection 2022.

Integrative interaction of emotional speech in audio-visual modality.

Dong H(1), Li N(1), Fan L(2), Wei J(1), Xu J(1).

Author information:
(1)Tianjin Key Lab of Cognitive Computing and Application, College of 
Intelligence and Computing, Tianjin University, Tianjin, China.
(2)Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, 
Beijing, China.

Emotional clues are always expressed in many ways in our daily life, and the 
emotional information we receive is often represented by multiple modalities. 
Successful social interactions require a combination of multisensory cues to 
accurately determine the emotion of others. The integration mechanism of 
multimodal emotional information has been widely investigated. Different brain 
activity measurement methods were used to determine the location of brain 
regions involved in the audio-visual integration of emotional information, 
mainly in the bilateral superior temporal regions. However, the methods adopted 
in these studies are relatively simple, and the materials of the study rarely 
contain speech information. The integration mechanism of emotional speech in the 
human brain still needs further examinations. In this paper, a functional 
magnetic resonance imaging (fMRI) study was conducted using event-related design 
to explore the audio-visual integration mechanism of emotional speech in the 
human brain by using dynamic facial expressions and emotional speech to express 
emotions of different valences. Representational similarity analysis (RSA) based 
on regions of interest (ROIs), whole brain searchlight analysis, modality 
conjunction analysis and supra-additive analysis were used to analyze and verify 
the role of relevant brain regions. Meanwhile, a weighted RSA method was used to 
evaluate the contributions of each candidate model in the best fitted model of 
ROIs. The results showed that only the left insula was detected by all methods, 
suggesting that the left insula played an important role in the audio-visual 
integration of emotional speech. Whole brain searchlight analysis, modality 
conjunction analysis and supra-additive analysis together revealed that the 
bilateral middle temporal gyrus (MTG), right inferior parietal lobule and 
bilateral precuneus might be involved in the audio-visual integration of 
emotional speech from other aspects.

Copyright © 2022 Dong, Li, Fan, Wei and Xu.

DOI: 10.3389/fnins.2022.797277
PMCID: PMC9695733
PMID: 36440282

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


12. Neuroimage. 2022 Dec 1;264:119769. doi: 10.1016/j.neuroimage.2022.119769. Epub 
2022 Nov 24.

Dissociation and hierarchy of human visual pathways for simultaneously coding 
facial identity and expression.

Ding X(1), Zhang H(2).

Author information:
(1)School of Engineering Medicine, Beihang University, Beijing 100191, China; 
School of Biological Science and Medical Engineering, Beihang University, 
Beijing 100191, China; Key Laboratory of Biomechanics and Mechanobiology 
(Beihang University), Ministry of Education, Beijing 100191, China.
(2)School of Engineering Medicine, Beihang University, Beijing 100191, China; 
Key Laboratory of Biomechanics and Mechanobiology (Beihang University), Ministry 
of Education, Beijing 100191, China. Electronic address: hui.zhang@buaa.edu.cn.

Humans have an extraordinary ability to recognize facial expression and identity 
from a single face simultaneously and effortlessly, however, the underlying 
neural computation is not well understood. Here, we optimized a multi-task deep 
neural network to classify facial expression and identity simultaneously. Under 
various optimization training strategies, the best-performing model consistently 
showed 'share-separate' organization. The two separate branches of the 
best-performing model also exhibited distinct abilities to categorize facial 
expression and identity, and these abilities increased along the facial 
expression or identity branches toward high layers. By comparing the 
representational similarities between the best-performing model and functional 
magnetic resonance imaging (fMRI) responses in the human visual cortex to the 
same face stimuli, the face-selective posterior superior temporal sulcus (pSTS) 
in the dorsal visual cortex was significantly correlated with layers in the 
expression branch of the model, and the anterior inferotemporal cortex (aIT) and 
anterior fusiform face area (aFFA) in the ventral visual cortex were 
significantly correlated with layers in the identity branch of the model. 
Besides, the aFFA and aIT better matched the high layers of the model, while the 
posterior FFA (pFFA) and occipital facial area (OFA) better matched the middle 
and early layers of the model, respectively. Overall, our study provides a 
task-optimization computational model to better understand the neural mechanism 
underlying face recognition, which suggest that similar to the best-performing 
model, the human visual system exhibits both dissociated and hierarchical 
neuroanatomical organization when simultaneously coding facial identity and 
expression.

Copyright © 2022. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2022.119769
PMID: 36435341 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare no conflict of interest.


13. Soc Neurosci. 2022 Oct;17(5):428-440. doi: 10.1080/17470919.2022.2138536. Epub 
2022 Oct 30.

Does the TPJ fit it all? Representational similarity analysis of different forms 
of mentalizing.

Golec-Staśkiewicz K(1), Pluta A(1)(2), Wojciechowski J(2)(3), Okruszek Ł(4), 
Haman M(1), Wysocka J(1), Wolak T(2).

Author information:
(1)Faculty of Psychology, University of Warsaw, Warsaw, Poland.
(2)Bioimaging Research Center, Institute of Physiology and Pathology of Hearing, 
World Hearing Center, Kajetany, Poland.
(3)Laboratory of Emotions Neurobiology, Nencki Institute of Experimental 
Biology, Warsaw, Poland.
(4)Social Neuroscience Lab, Institute of Psychology, Polish Academy of Sciences, 
Warsaw, Poland.

Mentalizing is the key socio-cognitive ability. Its heterogeneous structure may 
result from a variety of forms of mental state inference, which may be based on 
lower-level processing of cues encoded in the observable behavior of others, or 
rather involve higher-level computations aimed at understanding another person's 
perspective. Here we aimed to investigate the representational content of the 
brain regions engaged in mentalizing. To this end, 61 healthy adults took part 
in an fMRI study. We explored ROI activity patterns associated with five 
well-recognized ToM tasks that induce either decoding of mental states from 
motion kinematics or belief-reasoning. By using multivariate representational 
similarity analysis, we examined whether these examples of lower- and 
higher-level forms of social inference induced common or distinct patterns of 
brain activity. Distinct patterns of brain activity related to decoding of 
mental states from motion kinematics and belief-reasoning were found in lTPJp 
and the left IFG, but not the rTPJp. This may indicate that rTPJp supports a 
general mechanism for the representation of mental states. The divergent 
patterns of activation in lTPJp and frontal areas likely reflect differences in 
the degree of involvement of cognitive functions which support the basic 
mentalizing processes engaged by the two task groups.

DOI: 10.1080/17470919.2022.2138536
PMID: 36309870 [Indexed for MEDLINE]


14. Soc Cogn Affect Neurosci. 2022 Oct 25:nsac059. doi: 10.1093/scan/nsac059. Online 
ahead of print.

Neural Encoding of Novel Social Networks: Evidence that Perceivers Prioritize 
Others' Centrality.

Schwyck ME(1), Du M(1), Natarajan P(2), Chwe JA(3), Parkinson C(1)(4).

Author information:
(1)Department of Psychology, University of California, Los Angeles.
(2)Silver School of Social Work, New York University.
(3)Department of Psychology, New York University.
(4)Brain Research Institute, University of California, Los Angeles.

Knowledge of someone's friendships can powerfully impact how one interacts with 
them. Past research suggests that information about others' real-world social 
network positions-e.g., how well-connected they are (centrality), 'degrees of 
separation' (relative social distance)-is spontaneously encoded when 
encountering familiar individuals. However, many types of information covary 
with where someone sits in a social network. For instance, strangers' face-based 
trait impressions are associated with their social network centrality, and 
social distance and centrality are inherently intertwined with familiarity, 
interpersonal similarity, and memories. To disentangle the encoding of social 
network position from other social information, participants learned a novel 
social network in which social network position was decoupled from other 
factors, then saw each person's image during functional magnetic resonance 
imaging scanning. Using representational similarity analysis, we found that 
social network centrality was robustly encoded in regions associated with visual 
attention and mentalizing. Thus, even when considering a social network in which 
one is not included and where centrality was unlinked from perceptual and 
experience-based features to which it is inextricably tied in naturalistic 
contexts, the brain encodes information about others' importance in that 
network, likely shaping future perceptions of and interactions with those 
individuals.

© The Author(s) 2022. Published by Oxford University Press.

DOI: 10.1093/scan/nsac059
PMID: 36281998


15. Elife. 2022 Oct 25;11:e78162. doi: 10.7554/eLife.78162.

Neural defensive circuits underlie helping under threat in humans.

Vieira JB(1)(2), Olsson A(2).

Author information:
(1)Department of Psychology, Faculty of Health and Life Sciences, University of 
Exeter, Exeter, United Kingdom.
(2)Department of Clinical Neuroscience, Karolinska Institutet, Stockholm, 
Sweden.

Empathy for others' distress has long been considered the driving force of 
helping. However, when deciding to help others in danger, one must consider not 
only their distress, but also the risk to oneself. Whereas the role of 
self-defense in helping has been overlooked in human research, studies in other 
animals indicate defensive responses are necessary for the protection of 
conspecifics. In this pre-registered study (N=49), we demonstrate that human 
defensive neural circuits are implicated in helping others under threat. 
Participants underwent fMRI scanning while deciding whether to help another 
participant avoid aversive electrical shocks, at the risk of also being shocked. 
We found that higher engagement of neural circuits that coordinate fast escape 
from self-directed danger (including the insula, PAG, and ACC) facilitated 
decisions to help others. Importantly, using representational similarity 
analysis, we found that the strength with which the amygdala and insula uniquely 
represented the threat to oneself (and not the other's distress) predicted 
helping. Our findings indicate that in humans, as other mammals, defensive 
mechanisms play a greater role in helping behavior than previously understood.

© 2022, Vieira and Olsson.

DOI: 10.7554/eLife.78162
PMCID: PMC9596154
PMID: 36281636 [Indexed for MEDLINE]

Conflict of interest statement: JV, AO No competing interests declared


16. Front Behav Neurosci. 2022 Sep 23;16:958580. doi: 10.3389/fnbeh.2022.958580. 
eCollection 2022.

Early life stress is associated with the default mode and fronto-limbic network 
connectivity among young adults.

Ilomäki M(1), Lindblom J(2)(3), Salmela V(1), Flykt M(1)(2), Vänskä M(2), Salmi 
J(1)(4), Tolonen T(1), Alho K(1)(5), Punamäki RL(2), Wikman P(1).

Author information:
(1)Department of Psychology and Logopedics, Faculty of Medicine, University of 
Helsinki, Helsinki, Finland.
(2)Faculty of Social Sciences/Psychology, Tampere University, Tampere, Finland.
(3)Department of Clinical Medicine, Faculty of Medicine, University of Turku, 
Turku, Finland.
(4)Department of Neuroscience and Biomedical Engineering, Aalto University, 
Helsinki, Finland.
(5)Advanced Magnetic Imaging Centre, Aalto NeuroImaging, Aalto University, 
Espoo, Finland.

Exposure to early life stress (ELS) is associated with a variety of detrimental 
psychological and neurodevelopmental effects. Importantly, ELS has been 
associated with regional alterations and aberrant connectivity in the structure 
and functioning of brain regions involved in emotion processing and 
self-regulation, creating vulnerability to mental health problems. However, 
longitudinal research regarding the impact of ELS on functional connectivity 
between brain regions in the default mode network (DMN) and fronto-limbic 
network (FLN), both implicated in emotion-related processes, is relatively 
scarce. Neuroimaging research on ELS has mostly focused on single nodes or 
bi-nodal connectivity instead of functional networks. We examined how ELS is 
associated with connectivity patterns within the DMN and FLN during rest in 
early adulthood. The participants (n = 86; 47 females) in the current functional 
magnetic resonance imaging (fMRI) study were young adults (18-21 years old) 
whose families had participated in a longitudinal study since pregnancy. ELS was 
assessed both prospectively (parental reports of family relationship problems 
and mental health problems during pregnancy and infancy) and retrospectively 
(self-reported adverse childhood experiences). Inter-subject representational 
similarity analysis (IS-RSA) and multivariate distance matrix regression (MDMR) 
were used to analyze the association between ELS and the chosen networks. The 
IS-RSA results suggested that prospective ELS was associated with complex 
alterations within the DMN, and that retrospective ELS was associated with 
alterations in the FLN. MDMR results, in turn, suggested that that retrospective 
ELS was associated with DMN connectivity. Mean connectivity of the DMN was also 
associated with retrospective ELS. Analyses further showed that ELS-related 
alterations in the FLN were associated with increased connectivity between the 
prefrontal and limbic regions, and between different prefrontal regions. These 
results suggest that exposure to ELS in infancy might have long-lasting 
influences on functional brain connectivity that persist until early adulthood. 
Our results also speak for the importance of differentiating prospective and 
retrospective assessment methods to understand the specific neurodevelopmental 
effects of ELS.

Copyright © 2022 Ilomäki, Lindblom, Salmela, Flykt, Vänskä, Salmi, Tolonen, 
Alho, Punamäki and Wikman.

DOI: 10.3389/fnbeh.2022.958580
PMCID: PMC9537946
PMID: 36212193

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


17. Curr Biol. 2022 Oct 10;32(19):4172-4185.e7. doi: 10.1016/j.cub.2022.08.010. Epub 
2022 Aug 26.

Distinct neural representations for prosocial and self-benefiting effort.

Lockwood PL(1), Wittmann MK(2), Nili H(3), Matsumoto-Ryan M(4), Abdurahman A(5), 
Cutler J(6), Husain M(7), Apps MAJ(8).

Author information:
(1)Centre for Human Brain Health, School of Psychology, University of 
Birmingham, Birmingham B15 2TT, UK; Institute for Mental Health, School of 
Psychology, University of Birmingham, Birmingham B15 2TT, UK; Department of 
Experimental Psychology, University of Oxford, Anna Watts Building, Woodstock 
Road, Oxford OX2 6GG, UK; Wellcome Centre for Integrative Neuroimaging, 
University of Oxford, John Radcliffe Hospital, FMRIB Building, Headington, 
Oxford OX3 9DU, UK; Christ Church, University of Oxford, St Aldate's, Oxford OX1 
1DP, UK. Electronic address: p.l.lockwood@bham.ac.uk.
(2)Department of Experimental Psychology, University of Oxford, Anna Watts 
Building, Woodstock Road, Oxford OX2 6GG, UK; Wellcome Centre for Integrative 
Neuroimaging, University of Oxford, John Radcliffe Hospital, FMRIB Building, 
Headington, Oxford OX3 9DU, UK; Department of Experimental Psychology, 
University College London, 26 Bedford Way, London WC1H 0AP, UK; Max Planck UCL 
Centre for Computational Psychiatry and Ageing Research, University College 
London, Russell Square House 10-12 Russell Square, London WC1B 5EH, UK.
(3)Wellcome Centre for Integrative Neuroimaging, University of Oxford, John 
Radcliffe Hospital, FMRIB Building, Headington, Oxford OX3 9DU, UK; Department 
of Excellence for Neural Information Processing, Center for Molecular 
Neurobiology (ZMNH), University Medical Center Hamburg-Eppendorf (UKE), 
Martinistraße 52, 20251 Hamburg, Germany.
(4)Department of Experimental Psychology, University of Oxford, Anna Watts 
Building, Woodstock Road, Oxford OX2 6GG, UK.
(5)Department of Experimental Psychology, University of Oxford, Anna Watts 
Building, Woodstock Road, Oxford OX2 6GG, UK; Wellcome Centre for Integrative 
Neuroimaging, University of Oxford, John Radcliffe Hospital, FMRIB Building, 
Headington, Oxford OX3 9DU, UK; Department of Psychology, University of 
Cambridge, Downing Place, Cambridge CB2 3EB, UK.
(6)Centre for Human Brain Health, School of Psychology, University of 
Birmingham, Birmingham B15 2TT, UK; Institute for Mental Health, School of 
Psychology, University of Birmingham, Birmingham B15 2TT, UK; Department of 
Experimental Psychology, University of Oxford, Anna Watts Building, Woodstock 
Road, Oxford OX2 6GG, UK.
(7)Department of Experimental Psychology, University of Oxford, Anna Watts 
Building, Woodstock Road, Oxford OX2 6GG, UK; Nuffield Department of Clinical 
Neurosciences, University of Oxford, Oxford OX3 9DU, UK.
(8)Centre for Human Brain Health, School of Psychology, University of 
Birmingham, Birmingham B15 2TT, UK; Institute for Mental Health, School of 
Psychology, University of Birmingham, Birmingham B15 2TT, UK; Department of 
Experimental Psychology, University of Oxford, Anna Watts Building, Woodstock 
Road, Oxford OX2 6GG, UK; Christ Church, University of Oxford, St Aldate's, 
Oxford OX1 1DP, UK.

Prosocial behaviors-actions that benefit others-are central to individual and 
societal well-being. Although the mechanisms underlying the financial and moral 
costs of prosocial behaviors are increasingly understood, this work has often 
ignored a key influence on behavior: effort. Many prosocial acts are effortful, 
and people are averse to the costs of exerting them. However, how the brain 
encodes effort costs when actions benefit others is unknown. During fMRI, 
participants completed a decision-making task where they chose in each trial 
whether to "work" and exert force (30%-70% of maximum grip strength) or "rest" 
(no effort) for rewards (2-10 credits). Crucially, on separate trials, they made 
these decisions either to benefit another person or themselves. We used a 
combination of multivariate representational similarity analysis and model-based 
univariate analysis to reveal how the costs of prosocial and self-benefiting 
efforts are processed. Strikingly, we identified a unique neural signature of 
effort in the anterior cingulate gyrus (ACCg) for prosocial acts, both when 
choosing to help others and when exerting force to benefit them. This pattern 
was absent for self-benefiting behaviors. Moreover, stronger, specific 
representations of prosocial effort in the ACCg were linked to higher levels of 
empathy and higher subsequent exerted force to benefit others. In contrast, the 
ventral tegmental area and ventral insula represented value preferentially when 
choosing for oneself and not for prosocial acts. These findings advance our 
understanding of the neural mechanisms of prosocial behavior, highlighting the 
critical role that effort has in the brain circuits that guide helping others.

Copyright © 2022 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.cub.2022.08.010
PMCID: PMC9616728
PMID: 36029773 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of interests The authors declare no 
competing interests.


18. Handb Clin Neurol. 2022;187:109-126. doi: 10.1016/B978-0-12-823493-8.00002-X.

Components of language processing and their long-term and working memory storage 
in the brain.

Yue Q(1), Martin RC(2).

Author information:
(1)Department of Psychology, Vanderbilt University, Nashville, TN, United 
States.
(2)Department of Psychological Sciences, Rice University, Houston, TX, United 
States. Electronic address: rmartin@rice.edu.

There is a consensus that the temporal lobes are involved in representing 
various types of information critical for language processing, including 
phonological (i.e., speech sound), semantic (meaning), and orthographic 
(spelling) representations. An important question is whether the same regions 
that represent our long-term knowledge of phonology, semantics, and orthography 
are used to support the maintenance of these types of information in working 
memory (WM) (for instance, maintaining semantic information during sentence 
comprehension), or whether regions outside the temporal lobes provide the neural 
basis for WM maintenance in these domains. This review focuses on the issue of 
whether temporal lobe regions support WM for phonological information, with a 
brief discussion of related findings in the semantic and orthographic domains. 
Across all three domains, evidence from lesion-symptom mapping and functional 
neuroimaging indicates that parietal or frontal regions are critical for 
supporting WM, with different regions supporting WM in the three domains. The 
distinct regions in different domains argue against these regions as playing a 
general attentional role. The findings imply an interaction between the temporal 
lobe regions housing the long-term memory representations in these domains and 
the frontal and parietal regions needed to maintain these representations over 
time.

Copyright © 2022 Elsevier B.V. All rights reserved.

DOI: 10.1016/B978-0-12-823493-8.00002-X
PMID: 35964966 [Indexed for MEDLINE]


19. J Neurosci. 2022 Sep 14;42(37):7121-7130. doi: 10.1523/JNEUROSCI.1243-21.2022. 
Epub 2022 Aug 8.

A Distributed Network for Multimodal Experiential Representation of Concepts.

Tong J(1)(2), Binder JR(1)(2), Humphries C(1), Mazurchuk S(1)(2), Conant LL(1), 
Fernandino L(3)(4).

Author information:
(1)Departments of Neurology.
(2)Biophysics, Medical College of Wisconsin, Milwaukee, Wisconsin 53226.
(3)Departments of Neurology lfernandino@mcw.edu.
(4)Department of Biomedical Engineering, Marquette University and Medical 
College of Wisconsin, Milwaukee, Wisconsin 53233.

Neuroimaging, neuropsychological, and psychophysical evidence indicate that 
concept retrieval selectively engages specific sensory and motor brain systems 
involved in the acquisition of the retrieved concept. However, it remains 
unclear which supramodal cortical regions contribute to this process and what 
kind of information they represent. Here, we used representational similarity 
analysis of two large fMRI datasets with a searchlight approach to generate a 
detailed map of human brain regions where the semantic similarity structure 
across individual lexical concepts can be reliably detected. We hypothesized 
that heteromodal cortical areas typically associated with the default mode 
network encode multimodal experiential information about concepts, consistent 
with their proposed role as cortical integration hubs. In two studies involving 
different sets of concepts and different participants (both sexes), we found a 
distributed, bihemispheric network engaged in concept representation, composed 
of high-level association areas in the anterior, lateral, and ventral temporal 
lobe; inferior parietal lobule; posterior cingulate gyrus and precuneus; and 
medial, dorsal, ventrolateral, and orbital prefrontal cortex. In both studies, a 
multimodal model combining sensory, motor, affective, and other types of 
experiential information explained significant variance in the neural similarity 
structure observed in these regions that was not explained by unimodal 
experiential models or by distributional semantics (i.e., word2vec similarity). 
These results indicate that during concept retrieval, lexical concepts are 
represented across a vast expanse of high-level cortical regions, especially in 
the areas that make up the default mode network, and that these regions encode 
multimodal experiential information.SIGNIFICANCE STATEMENT Conceptual knowledge 
includes information acquired through various modalities of experience, such as 
visual, auditory, tactile, and emotional information. We investigated which 
brain regions encode mental representations that combine information from 
multiple modalities when participants think about the meaning of a word. We 
found that such representations are encoded across a widely distributed network 
of cortical areas in both hemispheres, including temporal, parietal, limbic, and 
prefrontal association areas. Several areas not traditionally associated with 
semantic cognition were also implicated. Our results indicate that the retrieval 
of conceptual knowledge during word comprehension relies on a much larger 
portion of the cerebral cortex than previously thought and that multimodal 
experiential information is represented throughout the entire network.

Copyright © 2022 the authors.

DOI: 10.1523/JNEUROSCI.1243-21.2022
PMCID: PMC9480893
PMID: 35940877 [Indexed for MEDLINE]


20. Neuroimage. 2022 Nov 1;261:119532. doi: 10.1016/j.neuroimage.2022.119532. Epub 
2022 Aug 2.

Decoding the temporal dynamics of affective scene processing.

Bo K(1), Cui L(2), Yin S(2), Hu Z(2), Hong X(3), Kim S(4), Keil A(5), Ding M(6).

Author information:
(1)J. Crayton Pruitt Family Department of Biomedical Engineering, University of 
Florida, Gainesville, FL 32611, USA; Department of Psychological and Brain 
Sciences, Dartmouth college, Hanover, NH 03755, USA.
(2)J. Crayton Pruitt Family Department of Biomedical Engineering, University of 
Florida, Gainesville, FL 32611, USA.
(3)J. Crayton Pruitt Family Department of Biomedical Engineering, University of 
Florida, Gainesville, FL 32611, USA; Shanghai Key Laboratory of Psychotic 
Disorders, Shanghai Mental Health Center, Shanghai Jiao Tong University School 
of Medicine, Shanghai 200030, China.
(4)J. Crayton Pruitt Family Department of Biomedical Engineering, University of 
Florida, Gainesville, FL 32611, USA; Department of Human-Computer Interaction, 
Hanyang University, Ansan, Republic of Korea.
(5)Department of Psychology, University of Florida, Gainesville, FL 32611, USA.
(6)J. Crayton Pruitt Family Department of Biomedical Engineering, University of 
Florida, Gainesville, FL 32611, USA. Electronic address: mding@bme.ufl.edu.

Natural images containing affective scenes are used extensively to investigate 
the neural mechanisms of visual emotion processing. Functional fMRI studies have 
shown that these images activate a large-scale distributed brain network that 
encompasses areas in visual, temporal, and frontal cortices. The underlying 
spatial and temporal dynamics, however, remain to be better characterized. We 
recorded simultaneous EEG-fMRI data while participants passively viewed 
affective images from the International Affective Picture System (IAPS). 
Applying multivariate pattern analysis to decode EEG data, and representational 
similarity analysis to fuse EEG data with simultaneously recorded fMRI data, we 
found that: (1) ∼80 ms after picture onset, perceptual processing of complex 
visual scenes began in early visual cortex, proceeding to ventral visual cortex 
at ∼100 ms, (2) between ∼200 and ∼300 ms (pleasant pictures: ∼200 ms; unpleasant 
pictures: ∼260 ms), affect-specific neural representations began to form, 
supported mainly by areas in occipital and temporal cortices, and (3) 
affect-specific neural representations were stable, lasting up to ∼2 s, and 
exhibited temporally generalizable activity patterns. These results suggest that 
affective scene representations in the brain are formed temporally in a 
valence-dependent manner and may be sustained by recurrent neural interactions 
among distributed brain areas.

Copyright © 2022. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2022.119532
PMID: 35931307 [Indexed for MEDLINE]


21. Front Hum Neurosci. 2022 Jun 23;16:890483. doi: 10.3389/fnhum.2022.890483. 
eCollection 2022.

Phonological Working Memory Representations in the Left Inferior Parietal Lobe 
in the Face of Distraction and Neural Stimulation.

Yue Q(1)(2), Martin RC(1).

Author information:
(1)Department of Psychological Sciences, Rice University, Houston, TX, United 
States.
(2)Department of Psychology, Vanderbilt University, Nashville, TN, United 
States.

The neural basis of phonological working memory (WM) was investigated through an 
examination of the effects of irrelevant speech distractors and disruptive 
neural stimulation from transcranial magnetic stimulation (TMS). Embedded 
processes models argue that the same regions involved in speech perception are 
used to support phonological WM whereas buffer models assume that a region 
separate from speech perception regions is used to support WM. Thus, according 
to the embedded processes approach but not the buffer approach, irrelevant 
speech and TMS to the speech perception region should disrupt the decoding of 
phonological WM representations. According to the buffer account, decoding of WM 
items should be possible in the buffer region despite distraction and should be 
disrupted with TMS to this region. Experiment 1 used fMRI and representational 
similarity analyses (RSA) with a delayed recognition memory paradigm using 
nonword stimuli. Results showed that decoding of memory items in the speech 
perception regions (superior temporal gyrus, STG) was possible in the absence of 
distractors. However, the decoding evidence in the left STG was susceptible to 
interference from distractors presented during the delay period whereas decoding 
in the proposed buffer region (supramarginal gyrus, SMG) persisted. Experiment 2 
examined the causal roles of the speech processing region and the buffer region 
in phonological WM performance using TMS. TMS to the SMG during the early delay 
period caused a disruption in recognition performance for the memory nonwords, 
whereas stimulations at the STG and an occipital control region did not affect 
WM performance. Taken together, results from the two experiments are consistent 
with predictions of a buffer model of phonological WM, pointing to a critical 
role of the left SMG in maintaining phonological representations.

Copyright © 2022 Yue and Martin.

DOI: 10.3389/fnhum.2022.890483
PMCID: PMC9259857
PMID: 35814962

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


22. Sci Rep. 2022 Jul 7;12(1):11517. doi: 10.1038/s41598-022-15687-5.

Longitudinal changes in auditory and reward systems following receptive 
music-based intervention in older adults.

Quinci MA(1), Belden A(1), Goutama V(1), Gong D(1), Hanser S(2), Donovan NJ(3), 
Geddes M(3)(4), Loui P(5).

Author information:
(1)Northeastern University, 360 Huntington Avenue, ISEC 129, Boston, MA, 02115, 
USA.
(2)Berklee College of Music, 1140 Boylston Street, Boston, MA, 02215, USA.
(3)Brigham and Women's Hospital and Harvard Medical School, 75 Francis Street, 
Boston, MA, 02115, USA.
(4)McGill University, 845 Sherbrooke Street West, Montreal, Quebec, Canada, H3A 
0G4.
(5)Northeastern University, 360 Huntington Avenue, ISEC 129, Boston, MA, 02115, 
USA. p.loui@northeastern.edu.

Listening to pleasurable music is known to engage the brain's reward system. 
This has motivated many cognitive-behavioral interventions for healthy aging, 
but little is known about the effects of music-based intervention (MBI) on 
activity and connectivity of the brain's auditory and reward systems. Here we 
show preliminary evidence that brain network connectivity can change after 
receptive MBI in cognitively unimpaired older adults. Using a combination of 
whole-brain regression, seed-based connectivity analysis, and representational 
similarity analysis (RSA), we examined fMRI responses during music listening in 
older adults before and after an 8-week personalized MBI. Participants rated 
self-selected and researcher-selected musical excerpts on liking and 
familiarity. Parametric effects of liking, familiarity, and selection showed 
simultaneous activation in auditory, reward, and default mode network (DMN) 
areas. Functional connectivity within and between auditory and reward networks 
was modulated by participant liking and familiarity ratings. RSA showed 
significant representations of selection and novelty at both time-points, and an 
increase in striatal representation of musical stimuli following intervention. 
An exploratory seed-based connectivity analysis comparing pre- and 
post-intervention showed significant increase in functional connectivity between 
auditory regions and medial prefrontal cortex (mPFC). Taken together, results 
show how regular music listening can provide an auditory channel towards the 
mPFC, thus offering a potential neural mechanism for MBI supporting healthy 
aging.

© 2022. The Author(s).

DOI: 10.1038/s41598-022-15687-5
PMCID: PMC9261172
PMID: 35798784 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


23. Neuroimage. 2022 Oct 1;259:119442. doi: 10.1016/j.neuroimage.2022.119442. Epub 
2022 Jul 3.

Dynamic changes in neural representations underlie the repetition effect on 
false memory.

Shao X(1), Chen C(2), Loftus EF(2), Xue G(3), Zhu B(4).

Author information:
(1)State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal 
University, Beijing 100875, China; Institute of Developmental Psychology, 
Beijing Normal University, Beijing 100875, China; Beijing Key Laboratory of 
Brain Imaging and Connectomics, Beijing Normal University, Beijing 100875, 
China; IDG/McGovern Institute for Brain Research, Beijing Normal University, 
Beijing 100875, China.
(2)Department of Psychological Science, University of California, Irvine, CA 
92697, United States.
(3)State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal 
University, Beijing 100875, China.
(4)State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal 
University, Beijing 100875, China; Institute of Developmental Psychology, 
Beijing Normal University, Beijing 100875, China; Beijing Key Laboratory of 
Brain Imaging and Connectomics, Beijing Normal University, Beijing 100875, 
China; IDG/McGovern Institute for Brain Research, Beijing Normal University, 
Beijing 100875, China. Electronic address: zhubi@bnu.edu.cn.

Restudying word lists (e.g., dream, awake, and bed) strengthens true memory of 
the studied words and reduces false memory for unstudied but semantically 
related lures (e.g., sleep). Yet, the neural mechanisms involved in this 
repetition effect on false memory remain unclear. Possible mechanisms involve 
item-specific and semantic neural representations at encoding, and the memory 
strength between encoding and retrieval. This study first replicated the 
behavioral results (Exp. 1) and then investigated various neural mechanisms by 
using slow event-related functional magnetic resonance imaging (fMRI) and 
representational similarity analysis (Exp. 2). Behavioral results confirmed that 
restudy improved true memory and reduced false memory. The fMRI results showed 
that restudy induced item-specific neural representations at encoding in the 
left occipital pole, but reduced neural overlap between semantic representations 
at encoding in the left temporal pole. Individual differences in these two 
encoding neural mechanisms were correlated with the behavioral measure of false 
memory, with greater restudy-induced representational changes at encoding 
(item-specific neural representations and reduced neural overlap between 
semantic representations) being associated with lower false memory. Moreover, 
restudy enhanced the memory strength between encoding and retrieval in the 
visuoparietal cortex but reduced it in the frontal cortex. These findings 
suggest that dynamic changes in neural representations underlie the repetition 
effect on false memory, supporting a dual-coding neural framework.

Copyright © 2022 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2022.119442
PMID: 35788042 [Indexed for MEDLINE]

Conflict of interest statement: Declarations of Competing Interest none


24. Neuroimage. 2022 Oct 1;259:119403. doi: 10.1016/j.neuroimage.2022.119403. Epub 
2022 Jun 20.

A two-stage framework for neural processing of biological motion.

Duarte JV(1), Abreu R(2), Castelo-Branco M(3).

Author information:
(1)Centre of Biomedical Imaging and Translational Research (CIBIT), Institute of 
Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Portugal; 
Faculty of Medicine, University of Coimbra, Portugal.
(2)Centre of Biomedical Imaging and Translational Research (CIBIT), Institute of 
Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Portugal.
(3)Centre of Biomedical Imaging and Translational Research (CIBIT), Institute of 
Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Portugal; 
Faculty of Medicine, University of Coimbra, Portugal. Electronic address: 
mcbranco@fmed.uc.pt.

It remains to be understood how biological motion is hierarchically computed, 
from discrimination of local biological motion animacy to global dynamic body 
perception. Here, we addressed this functional separation of the correlates of 
the perception of local biological motion from perception of global motion of a 
body. We hypothesized that local biological motion processing can be isolated, 
by using a single dot motion perceptual decision paradigm featuring the 
biomechanical details of local realistic motion of a single joint. To ensure 
that we were indeed tackling processing of biological motion properties we used 
discrimination instead of detection task. We discovered using representational 
similarity analysis that two key early dorsal and two ventral stream regions 
(visual motion selective hMT+ and V3A, extrastriate body area EBA and a region 
within fusiform gyrus FFG) showed robust and separable signals related to 
encoding of local biological motion and global motion-mediated shape. These 
signals reflected two independent processing stages, as revealed by 
representational similarity analysis and deconvolution of fMRI responses to each 
motion pattern. This study showed that higher level pSTS encodes both classes of 
biological motion in a similar way, revealing a higher-level integrative stage, 
reflecting scale independent biological motion perception. Our results reveal a 
two-stage framework for neural computation of biological motion, with an 
independent contribution of dorsal and ventral regions for the initial stage.

Copyright © 2022 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2022.119403
PMID: 35738331 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that no competing interests exist.


25. Cogn Neuropsychol. 2021 Oct-Dec;38(7-8):468-489. doi: 
10.1080/02643294.2022.2085085. Epub 2022 Jun 21.

Cochlea to categories: The spatiotemporal dynamics of semantic auditory 
representations.

Lowe MX(1)(2), Mohsenzadeh Y(1)(3)(4)(5), Lahner B(1), Charest I(6)(7), Oliva 
A(1), Teng S(1)(8).

Author information:
(1)Computer Science and Artificial Intelligence Lab (CSAIL), MIT, Cambridge, MA, 
USA.
(2)Unlimited Sciences, Colorado Springs, CO, USA.
(3)The Brain and Mind Institute, The University of Western Ontario, London, 
Canada.
(4)Department of Computer Science, The University of Western Ontario, London, 
Canada.
(5)Vector Institute for ArtificialIntelligence, Toronto, Ontario,Canada.
(6)Département de Psychologie, Université de Montréal, Montréal, Canada.
(7)Center for Human Brain Health, University of Birmingham, Birmingham, UK.
(8)Smith-Kettlewell Eye Research Institute (SKERI), San Francisco, CA, USA.

How does the auditory system categorize natural sounds? Here we apply multimodal 
neuroimaging to illustrate the progression from acoustic to semantically 
dominated representations. Combining magnetoencephalographic (MEG) and 
functional magnetic resonance imaging (fMRI) scans of observers listening to 
naturalistic sounds, we found superior temporal responses beginning ∼55 ms 
post-stimulus onset, spreading to extratemporal cortices by ∼100 ms. Early 
regions were distinguished less by onset/peak latency than by functional 
properties and overall temporal response profiles. Early acoustically-dominated 
representations trended systematically toward category dominance over time 
(after ∼200 ms) and space (beyond primary cortex). Semantic category 
representation was spatially specific: Vocalizations were preferentially 
distinguished in frontotemporal voice-selective regions and the fusiform; scenes 
and objects were distinguished in parahippocampal and medial place areas. Our 
results are consistent with real-world events coded via an extended auditory 
processing hierarchy, in which acoustic representations rapidly enter multiple 
streams specialized by category, including areas typically considered visual 
cortex.

DOI: 10.1080/02643294.2022.2085085
PMID: 35729704 [Indexed for MEDLINE]


26. Neuroimage. 2022 Sep;258:119355. doi: 10.1016/j.neuroimage.2022.119355. Epub 
2022 Jun 1.

Neural signatures of individual variability in context-dependent perception of 
ambiguous facial expression.

Kim KI(1), Jung WH(2), Woo CW(3), Kim H(4).

Author information:
(1)School of Psychology, Korea University, Seoul, Republic of Korea.
(2)Department of Psychology, Gachon University, Seongnam, Republic of Korea.
(3)Center for Neuroscience Imaging Research, Institute for Basic Science (IBS), 
Sungkyunkwan University, Suwon, Republic of Korea; Department of Biomedical 
Engineering, Sungkyunkwan University, Suwon, Republic of Korea; Department of 
Intelligent Precision Healthcare Convergence, Sungkyunkwan University, Suwon, 
Republic of Korea.
(4)School of Psychology, Korea University, Seoul, Republic of Korea. Electronic 
address: hackjinkim@korea.ac.kr.

How do we incorporate contextual information to infer others' emotional state? 
Here we employed a naturalistic context-dependent facial expression estimation 
task where participants estimated pleasantness levels of others' ambiguous 
expression faces when sniffing different contextual cues (e.g., urine, fish, 
water, and rose). Based on their pleasantness rating data, we placed 
participants on a context-dependency continuum and mapped the individual 
variability in the context-dependency onto the neural representation using a 
representational similarity analysis. We found that the individual variability 
in the context-dependency of facial expression estimation correlated with the 
activity level of the pregenual anterior cingulate cortex (pgACC) and the 
amygdala and was also decoded by the neural representation of the ventral 
anterior insula (vAI). A dynamic causal modeling revealed that those with higher 
context-dependency exhibited a greater degree of the modulation from vAI to the 
pgACC. These findings provide novel insights into the neural circuitry 
associated with the individual variability in context-dependent facial 
expression estimation and the first empirical evidence for individual 
variability in the predictive accounts of affective states.

Copyright © 2022 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2022.119355
PMID: 35660000 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare no competing financial interests.


27. Cereb Cortex. 2022 May 31:bhac209. doi: 10.1093/cercor/bhac209. Online ahead of 
print.

Gestational age-related changes in the fetal functional connectome: in utero 
evidence for the global signal.

Kim JH(1), De Asis-Cruz J(1), Cook KM(1), Limperopoulos C(1).

Author information:
(1)Developing Brain Institue, Children's National Hospital, 111 Michigan Avenue, 
N.W., Washington, DC, 20010, USA.

The human brain begins to develop in the third gestational week and rapidly 
grows and matures over the course of pregnancy. Compared to fetal structural 
neurodevelopment, less is known about emerging functional connectivity in utero. 
Here, we investigated gestational age (GA)-associated in vivo changes in 
functional brain connectivity during the second and third trimesters in a large 
dataset of 110 resting-state functional magnetic resonance imaging scans from a 
cohort of 95 healthy fetuses. Using representational similarity analysis, a 
multivariate analytical technique that reveals pair-wise similarity in 
high-order space, we showed that intersubject similarity of fetal functional 
connectome patterns was strongly related to between-subject GA differences 
(r = 0.28, P < 0.01) and that GA sensitivity of functional connectome was 
lateralized, especially at the frontal area. Our analysis also revealed a 
subnetwork of connections that were critical for predicting age (mean absolute 
error = 2.72 weeks); functional connectome patterns of individual fetuses 
reliably predicted their GA (r = 0.51, P < 0.001). Lastly, we identified the 
primary principal brain network that tracked fetal brain maturity. The main 
network showed a global synchronization pattern resembling global signal in the 
adult brain.

© The Author(s) 2022. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permission@oup.com.

DOI: 10.1093/cercor/bhac209
PMID: 35641159


28. Proc Natl Acad Sci U S A. 2022 May 31;119(22):e2116944119. doi: 
10.1073/pnas.2116944119. Epub 2022 May 23.

Neural representations of others' traits predict social decisions.

Kobayashi K(1), Kable JW(1), Hsu M(2), Jenkins AC(1).

Author information:
(1)Department of Psychology, University of Pennsylvania, Philadelphia, PA 19104.
(2)Haas School of Business and Helen Wills Neuroscience Institute, University of 
California, Berkeley, CA 94720.

To guide social interaction, people often rely on expectations about the traits 
of other people, based on markers of social group membership (i.e., 
stereotypes). Although the influence of stereotypes on social behavior is 
widespread, key questions remain about how traits inferred from social-group 
membership are instantiated in the brain and incorporated into neural 
computations that guide social behavior. Here, we show that the human lateral 
orbitofrontal cortex (OFC) represents the content of stereotypes about members 
of different social groups in the service of social decision-making. During 
functional MRI scanning, participants decided how to distribute resources across 
themselves and members of a variety of social groups in a modified Dictator 
Game. Behaviorally, we replicated our recent finding that inferences about 
others' traits, captured by a two-dimensional framework of stereotype content 
(warmth and competence), had dissociable effects on participants' 
monetary-allocation choices: recipients' warmth increased participants’ aversion 
to advantageous inequity (i.e., earning more than recipients), and recipients’ 
competence increased participants’ aversion to disadvantageous inequity (i.e., 
earning less than recipients). Neurally, representational similarity analysis 
revealed that others' traits in the two-dimensional space were represented in 
the temporoparietal junction and superior temporal sulcus, two regions 
associated with mentalizing, and in the lateral OFC, known to represent inferred 
features of a decision context outside the social domain. Critically, only the 
latter predicted individual choices, suggesting that the effect of stereotypes 
on behavior is mediated by inference-based decision-making processes in the OFC.

DOI: 10.1073/pnas.2116944119
PMCID: PMC9295729
PMID: 35605117 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interest.


29. Neuroimage. 2022 Aug 15;257:119294. doi: 10.1016/j.neuroimage.2022.119294. Epub 
2022 May 14.

Feature-reweighted representational similarity analysis: A method for improving 
the fit between computational models, brains, and behavior.

Kaniuth P(1), Hebart MN(2).

Author information:
(1)Vision and Computational Cognition Group, Max Planck Institute for Human 
Cognitive and Brain Sciences, Leipzig, Germany. Electronic address: 
kaniuth@cbs.mpg.de.
(2)Vision and Computational Cognition Group, Max Planck Institute for Human 
Cognitive and Brain Sciences, Leipzig, Germany. Electronic address: 
hebart@cbs.mpg.de.

Representational Similarity Analysis (RSA) has emerged as a popular method for 
relating representational spaces from human brain activity, behavioral data, and 
computational models. RSA is based on the comparison of representational 
(dis-)similarity matrices (RDMs or RSMs), which characterize the pairwise 
(dis-)similarities of all conditions across all features (e.g. fMRI voxels or 
units of a model). However, classical RSA treats each feature as equally 
important. This 'equal weights' assumption contrasts with the flexibility of 
multivariate decoding, which reweights individual features for predicting a 
target variable. As a consequence, classical RSA may lead researchers to 
underestimate the correspondence between a model and a brain region and, in case 
of model comparison, may lead them to select an inferior model. The aim of this 
work is twofold: First, we sought to broadly test feature-reweighted RSA 
(FR-RSA) applied to computational models and reveal the extent to which 
reweighting model features improves RSM correspondence and affects model 
selection. Previous work suggested that reweighting can improve model selection 
in RSA but it has remained unclear to what extent these results generalize 
across datasets and data modalities. To draw more general conclusions, we 
utilized a range of publicly available datasets and three popular deep neural 
networks (DNNs). Second, we propose voxel-reweighted RSA, a novel use case of 
FR-RSA that reweights fMRI voxels, mirroring the rationale of multivariate 
decoding of optimally combining voxel activity patterns. We found that 
reweighting individual model units markedly improved the fit between model RSMs 
and target RSMs derived from several fMRI and behavioral datasets and affected 
model selection, highlighting the importance of considering FR-RSA. For 
voxel-reweighted RSA, improvements in RSM correspondence were even more 
pronounced, demonstrating the utility of this novel approach. We additionally 
show that classical noise ceilings can be exceeded when FR-RSA is applied and 
propose an updated approach for their computation. Taken together, our results 
broadly validate the use of FR-RSA for improving the fit between computational 
models, brain, and behavioral data, allowing us to better adjudicate between 
competing computational models. Further, our results suggest that FR-RSA applied 
to brain measurement channels could become an important new method to assess the 
correspondence between representational spaces.

Copyright © 2022. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2022.119294
PMID: 35580810 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest None.


30. J Neural Eng. 2022 May 30;19(3). doi: 10.1088/1741-2552/ac6f81.

Semantic fMRI neurofeedback: a multi-subject study at 3 tesla.

Ciarlo A(1), Russo AG(1)(2), Ponticorvo S(1), di Salle F(1)(3), Lührs M(4)(5), 
Goebel R(4)(5), Esposito F(2).

Author information:
(1)Department of Medicine, Surgery and Dentistry, Scuola Medica Salernitana, 
University of Salerno, Baronissi, SA, Italy.
(2)Department of Advanced Medical and Surgical Sciences, School of Medicine and 
Surgery, University of Campania 'Luigi Vanvitelli', Naples, Italy.
(3)Department of Diagnostic Imaging, University Hospital 'San Giovanni di Dio e 
Ruggi d'Aragona', Salerno, Italy.
(4)Department of Cognitive Neuroscience, University of Maastricht, Maastricht, 
The Netherlands.
(5)Research Department, Brain Innovation B.V., Maastricht, The Netherlands.

Objective.Real-time functional magnetic resonance imaging neurofeedback 
(rt-fMRI-NF) is a non-invasive procedure allowing the self-regulation of brain 
functions via enhanced self-control of fMRI based neural activation. In semantic 
rt-fMRI-NF, an estimated relation between multivariate fMRI activation patterns 
and abstract mental states is exploited for a multi-dimensional feedback 
stimulus via real-time representational similarity analysis (rt-RSA). Here, we 
assessed the performances of this framework in a multi-subject multi-session 
study on a 3 T MRI clinical scanner.Approach.Eighteen healthy volunteers 
underwent two semantic rt-fMRI-NF sessions on two different days. In each 
session, participants were first requested to engage in specific mental states 
while local fMRI patterns of brain activity were recorded during stimulated 
mental imagery of concrete objects (pattern generation). The obtained neural 
representations were to be replicated and modulated by the participants in 
subsequent runs of the same session under the guidance of a rt-RSA generated 
visual feedback (pattern modulation). Performance indicators were derived from 
the rt-RSA output to assess individual abilities in replicating (and maintaining 
over time) a target pattern. Simulations were carried out to assess the impact 
of the geometric distortions implied by the low-dimensional representation of 
patterns' dissimilarities in the visual feedback.Main results.Sixteen subjects 
successfully completed both semantic rt-fMRI-NF sessions. Considering some 
performance indicators, a significant improvement between the first and the 
second runs, and within run increasing modulation performances were observed, 
whereas no improvements were found between sessions. Simulations confirmed that 
in a small percentage of cases visual feedback could be affected by metric 
distortions due to dimensionality reduction implicit to the rt-RSA 
approach.Significance.Our results proved the feasibility of the semantic 
rt-fMRI-NF at 3 T, showing that subjects can successfully modulate and maintain 
a target mental state when guided by rt-RSA derived feedback. Further 
development is needed to encourage future clinical applications.

© 2022 IOP Publishing Ltd.

DOI: 10.1088/1741-2552/ac6f81
PMID: 35561669 [Indexed for MEDLINE]


31. Hum Brain Mapp. 2022 Sep;43(13):4074-4090. doi: 10.1002/hbm.25903. Epub 2022 May 
12.

Neural similarity between mentalizing and live social interaction during the 
transition to adolescence.

Merchant JS(1)(2), Alkire D(1)(2), Redcay E(1)(2).

Author information:
(1)Neuroscience and Cognitive Science Program, University of Maryland, College 
Park, Maryland, USA.
(2)Department of Psychology, University of Maryland, College Park, Maryland, 
USA.

Social interactions are essential for human development, yet little neuroimaging 
research has examined their underlying neurocognitive mechanisms using socially 
interactive paradigms during childhood and adolescence. Recent neuroimaging 
research has revealed activity in the mentalizing network when children engage 
with a live social partner, even when mentalizing is not required. While this 
finding suggests that social-interactive contexts may spontaneously engage 
mentalizing, it is not a direct test of how similarly the brain responds to 
these two contexts. The current study used representational similarity analysis 
on data from 8- to 14-year-olds who made mental and nonmental judgments about an 
abstract character and a live interaction partner during fMRI. A within-subject, 
2 (Mental/Nonmental) × 2 (Peer/Character) design enabled us to examine response 
pattern similarity between conditions, and estimate fit to three conceptual 
models of how the two contexts relate: (1) social interaction and mentalizing 
about an abstract character are represented similarly; (2) interactive peers and 
abstract characters are represented differently regardless of the evaluation 
type; and (3) mental and nonmental states are represented dissimilarly 
regardless of target. We found that the temporal poles represent mentalizing and 
peer interactions similarly (Model 1), suggesting a neurocognitive link between 
the two in these regions. Much of the rest of the social brain exhibits 
different representations of interactive peers and abstract characters (Model 
2). Our findings highlight the importance of studying social-cognitive processes 
using interactive approaches, and the utility of pattern-based analyses for 
understanding how social-cognitive processes relate to each other.

© 2022 The Authors. Human Brain Mapping published by Wiley Periodicals LLC.

DOI: 10.1002/hbm.25903
PMCID: PMC9374881
PMID: 35545954 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no competing 
interests, financial or otherwise.


32. Hum Brain Mapp. 2022 Sep;43(13):4013-4029. doi: 10.1002/hbm.25900. Epub 2022 May 
12.

Neural representation of phonological information during Chinese character 
reading.

Li A(1)(2)(3), Yang R(1)(2)(3), Qu J(1)(2)(3), Dong J(1)(2)(3), Gu L(1)(2)(3), 
Mei L(1).

Author information:
(1)Philosophy and Social Science Laboratory of Reading and Development in 
Children and Adolescents, South China Normal University, Ministry of Education, 
Guangzhou, China.
(2)School of Psychology, South China Normal University, Guangzhou, China.
(3)Guangdong Key Laboratory of Mental Health and Cognitive Science, South China 
Normal University, Guangzhou, China.

Previous studies have revealed that phonological processing of Chinese 
characters elicited activation in the left prefrontal cortex, bilateral parietal 
cortex, and occipitotemporal regions. However, it is controversial what role the 
left middle frontal gyrus plays in Chinese character reading, and whether the 
core regions (e.g., the left superior temporal gyrus and supramarginal gyrus) 
for phonological processing of alphabetic languages are also involved in Chinese 
character reading. To address these questions, the present study used both 
univariate and multivariate analysis (i.e., representational similarity 
analysis, RSA) to explore neural representations of phonological information 
during Chinese character reading. Participants were scanned while performing a 
reading aloud task. Univariate activation analysis revealed a widely distributed 
network for word reading, including the bilateral inferior frontal gyrus, middle 
frontal gyrus, lateral temporal cortex, and occipitotemporal cortex. More 
importantly, RSA showed that the left prefrontal (i.e., the left middle frontal 
gyrus and left inferior frontal gyrus) and bilateral occipitotemporal areas 
(i.e., the left inferior and middle temporal gyrus and bilateral fusiform gyrus) 
represented phonological information of Chinese characters. These results 
confirmed the importance of the left middle frontal gyrus and regions in ventral 
pathway in representing phonological information of Chinese characters.

© 2022 The Authors. Human Brain Mapping published by Wiley Periodicals LLC.

DOI: 10.1002/hbm.25900
PMCID: PMC9374885
PMID: 35545935 [Indexed for MEDLINE]

Conflict of interest statement: All authors declare that they have no conflict 
of interest.


33. eNeuro. 2022 Jun 1;9(3):ENEURO.0495-21.2022. doi: 10.1523/ENEURO.0495-21.2022. 
Print 2022 May-Jun.

Functional Gradient of the Fusiform Cortex for Chinese Character Recognition.

Guo W(1)(2), Geng S(1)(2), Cao M(3)(2), Feng J(3)(2).

Author information:
(1)Institute of Science and Technology for Brain-Inspired Intelligence, Fudan 
University, Shanghai 200433, China.
(2)Ministry of Education, Key Laboratory of Computational Neuroscience and 
Brain-Inspired Intelligence (Fudan University), Shanghai 200433 China.
(3)Institute of Science and Technology for Brain-Inspired Intelligence, Fudan 
University, Shanghai 200433, China mcao@fudan.edu.cn jianfeng64@gmail.com.

Visual word recognition has been proposed to have a functional and spatial 
organization corresponding to hierarchical language-like word forms in the left 
fusiform gyrus (FG) during visual word recognition in alphabetic languages. 
However, it is still unclear whether the similar functional gradients of 
word-like representation exist during Chinese character recognition. In this 
study, we adopted univariate activation analysis and representational similarity 
analysis (RSA) methods to investigate the functional organization in the FG for 
Chinese character recognition using task fMRI data. Native Chinese readers were 
visually presented with four types of character-like stimuli (i.e., real 
characters, pseudo-characters, false characters, and stroke combinations). After 
analysis, we observed a posterior-to-anterior functional gradient in the left FG 
corresponding to the degree of likeness of stimuli to character. Additionally, 
distinct subregions of the left FG harbor different orthographic codes. The 
middle part of the left FG was involved in abstract orthographic processing, 
while the anterior part of the left FG was involved in lexical orthographic 
processing (i.e., mapping orthography onto phonology or semantics). Notably, for 
the right FG, we did not find similar coding pattern for selectivity to 
character likeness, indicating the asymmetry of the functional hierarchical 
organization in favor of the left hemisphere. In conclusion, our findings 
revealed that the left FG presents a posterior-to-anterior gradient functional 
processing for Chinese character recognition, which expands our understanding of 
the psychological, neural, and computational theories of word reading.

Copyright © 2022 Guo et al.

DOI: 10.1523/ENEURO.0495-21.2022
PMCID: PMC9172282
PMID: 35545424 [Indexed for MEDLINE]


34. Brain Sci. 2022 Mar 31;12(4):466. doi: 10.3390/brainsci12040466.

Features and Extra-Striate Body Area Representations of Diagnostic Body Parts in 
Anger and Fear Perception.

Ren J(1)(2), Ding R(1)(2), Li S(1)(2), Zhang M(1)(2), Wei D(3), Feng C(4), Xu 
P(5), Luo W(1)(2).

Author information:
(1)Research Center of Brain and Cognitive Neuroscience, Liaoning Normal 
University, Dalian 116029, China.
(2)Key Laboratory of Brain and Cognitive Neuroscience, Dalian 116029, China.
(3)Faculty of Psychology, Southwest University, Chongqing 400715, China.
(4)School of Psychology, South China Normal University, Guangzhou 510631, China.
(5)Faculty of Psychology, Beijing Normal University, Beijing 100875, China.

Social species perceive emotion via extracting diagnostic features of body 
movements. Although extensive studies have contributed to knowledge on how the 
entire body is used as context for decoding bodily expression, we know little 
about whether specific body parts (e.g., arms and legs) transmit enough 
information for body understanding. In this study, we performed behavioral 
experiments using the Bubbles paradigm on static body images to directly explore 
diagnostic body parts for categorizing angry, fearful and neutral expressions. 
Results showed that subjects recognized emotional bodies through diagnostic 
features from the torso with arms. We then conducted a follow-up functional 
magnetic resonance imaging (fMRI) experiment on body part images to examine 
whether diagnostic parts modulated body-related brain activity and corresponding 
neural representations. We found greater activations of the extra-striate body 
area (EBA) in response to both anger and fear than neutral for the torso and 
arms. Representational similarity analysis showed that neural patterns of the 
EBA distinguished different bodily expressions. Furthermore, the torso with arms 
and whole body had higher similarities in EBA representations relative to the 
legs and whole body, and to the head and whole body. Taken together, these 
results indicate that diagnostic body parts (i.e., torso with arms) can 
communicate bodily expression in a detectable manner.

DOI: 10.3390/brainsci12040466
PMCID: PMC9028525
PMID: 35447997

Conflict of interest statement: The authors declare no conflict of interest.


35. Cereb Cortex Commun. 2022 Feb 17;3(1):tgac009. doi: 10.1093/texcom/tgac009. 
eCollection 2022.

Benefit from retrieval practice is linked to temporal and frontal activity in 
healthy young and older humans.

Guran CA(1), Deuker L(2), Göttlich M(3), Axmacher N(2), Bunzeck N(1).

Author information:
(1)Department of Psychology I, University of Lübeck, Maria-Goeppert-Straße 9a, 
Lübeck 23562, Germany.
(2)Department of Neuropsychology, Faculty of Psychology, Institute of Cognitive 
Neuroscience, Ruhr University Bochum, Universitätsstraße 150, Bochum 44801, 
Germany.
(3)Department of Neurology, University Hospital Schleswig-Holstein, University 
of Lübeck, Ratzeburger Allee 160, Lübeck 23538, Germany.

Retrieval practice improves retention of information in long-term memory more 
than restudy, but the underlying neural mechanisms of this "retrieval practice 
effect" (RPE) remain poorly understood. Therefore, we investigated the 
behavioral and neural differences between previously retrieved versus restudied 
items at final retrieval. Thirty younger (20-30 years old) and twenty-five older 
(50+ years old) adults learned familiar and new picture stimuli either through 
retrieval or restudy. At final recognition, hemodynamic activity was measured 
using functional magnetic resonance imaging (fMRI). Behaviorally, younger and 
older adults showed similar benefits of retrieval practice, with higher 
recollection, but unchanged familiarity rates. In a univariate analysis of the 
fMRI data, activation in medial prefrontal cortex and left temporal regions 
correlated with an individual's amount of behavioral benefit from retrieval 
practice, irrespective of age. Compatible with this observation, in a 
multivariate representational similarity analysis (RSA), retrieval practice led 
to an increase in pattern similarity for retested items in a priori defined 
regions of interest, including the medial temporal lobe, as well as prefrontal 
and parietal cortex. Our findings demonstrate that retrieval practice leads to 
enhanced long-term memories in younger and older adults alike, and this effect 
may be driven by fast consolidation processes.

© The Author(s) 2022. Published by Oxford University Press.

DOI: 10.1093/texcom/tgac009
PMCID: PMC8966694
PMID: 35372838


36. Curr Biol. 2022 May 9;32(9):2067-2075.e4. doi: 10.1016/j.cub.2022.02.076. Epub 
2022 Mar 23.

Pattern differentiation and tuning shift in human sensory cortex underlie 
long-term threat memory.

You Y(1), Novak LR(2), Clancy KJ(2), Li W(3).

Author information:
(1)Department of Psychology, Florida State University, 1107 W. Call St., 
Tallahassee, FL 32306, USA. Electronic address: youlilly@gmail.com.
(2)Department of Psychology, Florida State University, 1107 W. Call St., 
Tallahassee, FL 32306, USA.
(3)Department of Psychology, Florida State University, 1107 W. Call St., 
Tallahassee, FL 32306, USA. Electronic address: wenli@psy.fsu.edu.

Comment in
    Curr Biol. 2022 May 9;32(9):R426-R428.

The amygdala-prefrontal-cortex circuit has long occupied the center of the 
threat system,1 but new evidence has rapidly amassed to implicate threat 
processing outside this canonical circuit.2-4 Through nonhuman research, the 
sensory cortex has emerged as a critical substrate for long-term threat 
memory,5-9 underpinned by sensory cortical pattern separation/completion10,11 
and tuning shift.12,13 In humans, research has begun to associate the human 
sensory cortex with long-term threat memory,14,15 but the lack of mechanistic 
insights obscures a direct linkage. Toward that end, we assessed human olfactory 
threat conditioning and long-term (9 days) threat memory, combining affective 
appraisal, olfactory psychophysics, and functional magnetic resonance imaging 
(fMRI) over a linear odor-morphing continuum (five levels of binary mixtures of 
the conditioned stimuli/CS+ and CS- odors). Affective ratings and olfactory 
perceptual discrimination confirmed (explicit) affective and perceptual learning 
and memory via conditioning. fMRI representational similarity analysis (RSA) and 
voxel-based tuning analysis further revealed associative plasticity in the human 
olfactory (piriform) cortex, including immediate and lasting pattern 
differentiation between CS and neighboring non-CS and a late onset, lasting 
tuning shift toward the CS. The two plastic processes were especially salient 
and lasting in anxious individuals, among whom they were further correlated. 
These findings thus support an evolutionarily conserved sensory cortical system 
of long-term threat representation, which can underpin threat perception and 
memory. Importantly, hyperfunctioning of this sensory mnemonic system of threat 
in anxiety further implicates a hitherto underappreciated sensory mechanism of 
anxiety.

Copyright © 2022 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.cub.2022.02.076
PMCID: PMC9090975
PMID: 35325599 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of interests The authors declare no 
competing interests.


37. Neuropsychologia. 2022 May 3;169:108192. doi: 
10.1016/j.neuropsychologia.2022.108192. Epub 2022 Mar 1.

The role of animal faces in the animate-inanimate distinction in the ventral 
temporal cortex.

Proklova D(1), Goodale MA(2).

Author information:
(1)The Brain and Mind Institute, Western University, London, Ontario, N6A 5B7, 
Canada; Department of Psychology, Western University, London, Ontario, N6A 5C2, 
Canada. Electronic address: d.proklova@gmail.com.
(2)The Brain and Mind Institute, Western University, London, Ontario, N6A 5B7, 
Canada; Department of Psychology, Western University, London, Ontario, N6A 5C2, 
Canada.

Animate and inanimate objects elicit distinct response patterns in the human 
ventral temporal cortex (VTC), but the exact features driving this distinction 
are still poorly understood. One prominent feature that distinguishes typical 
animals from inanimate objects and that could potentially explain the 
animate-inanimate distinction in the VTC is the presence of a face. In the 
current fMRI study, we investigated this possibility by creating a stimulus set 
that included animals with faces, faceless animals, and inanimate objects, 
carefully matched in order to minimize other visual differences. We used both 
searchlight-based and ROI-based representational similarity analysis (RSA) to 
test whether the presence of a face explains the animate-inanimate distinction 
in the VTC. The searchlight analysis revealed that when animals with faces were 
removed from the analysis, the animate-inanimate distinction almost disappeared. 
The ROI-based RSA revealed a similar pattern of results, but also showed that, 
even in the absence of faces, information about agency (a combination of 
animal's ability to move and think) is present in parts of the VTC that are 
sensitive to animacy. Together, these analyses showed that animals with faces do 
elicit a stronger animate/inanimate response in the VTC, but that faces are not 
necessary in order to observe high-level animacy information (e.g., agency) in 
parts of the VTC. A possible explanation could be that this animacy-related 
activity is driven not by faces per se, or the visual features of faces, but by 
other factors that correlate with face presence, such as the capacity for 
self-movement and thought. In short, the VTC might treat the face as a proxy for 
agency, a ubiquitous feature of familiar animals.

Copyright © 2022 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2022.108192
PMID: 35245528 [Indexed for MEDLINE]


38. Cereb Cortex. 2022 Dec 15;33(1):152-166. doi: 10.1093/cercor/bhac058.

Context free and context-dependent conceptual representation in the brain.

Gao Z(1), Zheng L(2), Gouws A(1), Krieger-Redwood K(1), Wang X(1), Varga D(3), 
Smallwood J(4), Jefferies E(1).

Author information:
(1)Department of Psychology, University of York, Heslington, NY YO10 5DD, United 
Kingdom.
(2)Department of Psychology, University of Arizona, Tucson, AZ 85719, United 
States.
(3)School of Psychology, University of Sussex, Brighton BN1 9RH, United Kingdom.
(4)Department of Psychology, Queen's University, Kingston, ON K7L 3N6, Canada.

How concepts are coded in the brain is a core issue in cognitive neuroscience. 
Studies have focused on how individual concepts are processed, but the way in 
which conceptual representation changes to suit the context is unclear. We 
parametrically manipulated the association strength between words, presented in 
pairs one word at a time using a slow event-related fMRI design. We combined 
representational similarity analysis and computational linguistics to probe the 
neurocomputational content of these trials. Individual word meaning was 
maintained in supramarginal gyrus (associated with verbal short-term memory) 
when items were judged to be unrelated, but not when a linking context was 
retrieved. Context-dependent meaning was instead represented in left lateral 
prefrontal gyrus (associated with controlled retrieval), angular gyrus, and 
ventral temporal lobe (regions associated with integrative aspects of memory). 
Analyses of informational connectivity, examining the similarity of activation 
patterns across trials between sites, showed that control network regions had 
more similar multivariate responses across trials when association strength was 
weak, reflecting a common controlled retrieval state when the task required more 
unusual associations. These findings indicate that semantic control and 
representational sites amplify contextually relevant meanings in trials judged 
to be related.

© The Author(s) 2022. Published by Oxford University Press.

DOI: 10.1093/cercor/bhac058
PMCID: PMC9758583
PMID: 35196710 [Indexed for MEDLINE]


39. Neuroimage. 2022 May 1;251:119005. doi: 10.1016/j.neuroimage.2022.119005. Epub 
2022 Feb 14.

Deep neural networks reveal topic-level representations of sentences in medial 
prefrontal cortex, lateral anterior temporal lobe, precuneus, and angular gyrus.

Acunzo DJ(1), Low DM(2), Fairhall SL(3).

Author information:
(1)CIMeC/University of Trento, Corso Bettini 31, Rovereto 38068, Italy.
(2)Program in Speech and Hearing Bioscience and Technology, Harvard Medical 
School, United States; Brain and Cognitive Sciences Department, MIT, United 
States.
(3)CIMeC/University of Trento, Corso Bettini 31, Rovereto 38068, Italy. 
Electronic address: scott.fairhall@unitn.it.

When reading a sentence, individual words can be combined to create more complex 
meaning. In this study, we sought to uncover brain regions that reflect the 
representation of the meaning of sentences at the topic level, as opposed to the 
meaning of their individual constituent words when considered irrespective of 
their context. Using fMRI, we recorded the neural activity of participants while 
reading sentences. We constructed a topic-level sentence representations using 
the final layer of a convolutional neural network (CNN) trained to classify 
Wikipedia sentences into broad semantic categories. This model was contrasted 
with word-level sentence representations constructed using the average of the 
word embeddings constituting the sentence. Using representational similarity 
analysis, we found that the medial prefrontal cortex, lateral anterior temporal 
lobe, precuneus, and angular gyrus more strongly represent sentence topic-level, 
compared to word-level, meaning, uncovering the important role of these semantic 
system regions in the representation of topic-level meaning. Results were 
comparable when sentence meaning was modelled with a multilayer perceptron that 
was not sensitive to word order within a sentence, suggesting that the learning 
objective, in the terms of the topic being modelled, is the critical factor in 
capturing these neural representational spaces.

Copyright © 2022. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2022.119005
PMID: 35176493 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare no competing interests.


40. Front Psychol. 2022 Jan 20;12:782754. doi: 10.3389/fpsyg.2021.782754. 
eCollection 2021.

Personality Traits Induce Different Brain Patterns When Processing Social and 
Valence Information.

Hevia-Orozco JC(1)(2), Reyes-Aguilar A(3), Hernández-Pérez R(4), González-Santos 
L(2), Pasaye EH(2), Barrios FA(2).

Author information:
(1)Escuela de Psicología, Universidad Anáhuac Mayab, Mérida, Mexico.
(2)Instituto de Neurobiología, Universidad Nacional Autónoma de México, Santiago 
de Querétaro, Mexico.
(3)Facultad de Psicología, Universidad Nacional Autónoma de México, Mexico City, 
Mexico.
(4)Department of Ethology, Institute of Biology, Eötvös Loránd University, 
Budapest, Hungary.

This paper shows the brain correlates of Cloninger's personality model during 
the presentation of social scenarios under positive or negative valence 
situations. Social scenarios were constructed when participants played the 
Dictator game with two confederates that had two opposites roles as the 
cooperator (Coop) and non-cooperator (NoCoop). Later the same day during a fMRI 
scanning session, participants read negative (Neg) and positive (Pos) situations 
that happened to confederates in the past. Participants were asked to think "how 
do you think those people felt during that situation?" A dissimilarity matrix 
between stimuli were obtained from fMRI results. Results shown that Harm 
Avoidance trait people make use of right middle frontal gyrus and left superior 
frontal gyrus to discriminate between Coop and NoCoop. Cooperation as a trait 
makes use of the right superior temporal gyrus and the right precuneus to 
discriminate between Coop and NoCoop in positive social scenarios. Finally, 
Self-directedness trait people make use of the right inferior parietal lobe to 
discriminate between Coop and NoCoop in negative social scenarios and the right 
precuneus to discriminate between Coop and Strangers. An intuitive link between 
discrimination findings and behavioral patterns of those personality traits is 
proposed.

Copyright © 2022 Hevia-Orozco, Reyes-Aguilar, Hernández-Pérez, González-Santos, 
Pasaye and Barrios.

DOI: 10.3389/fpsyg.2021.782754
PMCID: PMC8833229
PMID: 35153905

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


41. Cereb Cortex. 2022 Dec 8;32(24):5489-5502. doi: 10.1093/cercor/bhac029.

Spatiotemporal and sensory modality attention processing with domain-specific 
representations in frontoparietal areas.

Wang L(1), Li C(2)(3)(4), Han Z(5), Wu Q(6)(7), Sun L(2)(3)(4), Zhang 
X(2)(3)(4), Go R(5), Wu J(5)(7), Yan T(8).

Author information:
(1)School of Life Science, Shanghai University, Shanghai 200444, China.
(2)School of Biomedical Engineering, Capital Medical University, Beijing 100069, 
China.
(3)Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, 
Capital Medical University, Beijing 100069, China.
(4)Beijing Key Laboratory of Fundamental Research on Biomechanics in Clinical 
Application, Capital Medical University, Beijing 100069, China.
(5)School of Mechatronical Engineering, Beijing Institute of Technology, Beijing 
100081, China.
(6)Department of Psychology, Suzhou University of Science and Technology, Suzhou 
215009, China.
(7)Cognitive Neuroscience Lab, Graduate School of Interdisciplinary Science and 
Engineering in Health Systems, Okayama University, Okayama 700-0084, Japan.
(8)School of Life Science, Beijing Institute of Technology, Beijing 100081, 
China.

The frontoparietal network (FPN), including bilateral frontal eye field, 
inferior parietal sulcus, and supplementary motor area, has been linked to 
attention processing, including spatiotemporal and sensory modality domains. 
However, it is unclear whether FPN encodes representations of these domains that 
are generalizable across subdomains. We decomposed multivariate patterns of 
functional magnetic resonance imaging activity from 20 participants into 
domain-specific components and identified latent multivariate representations 
that generalized across subdomains. The 30 experimental conditions were 
organized into unimodal-bimodal and spatial-temporal models. We found that brain 
areas in the FPN, form the primary network that modulated during attention 
across domains. However, the activation patterns of areas within the FPN were 
reorganized according to the specific attentional demand, especially when pay 
attention to different sensory, suggesting distinct regional neural 
representations associated with specific attentional processes within FPN. In 
addition, there were also other domain-specific areas outside the FPN, such as 
the dorsolateral prefrontal cortex. Our conclusion is that, according to the 
results of the analysis of representation similarity, 2 types of activated brain 
regions, related to attention domain detailed information processing and general 
information processing, can be revealed.

© The Author(s) 2022. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhac029
PMID: 35136999 [Indexed for MEDLINE]


42. Neuroimage. 2022 May 1;251:118889. doi: 10.1016/j.neuroimage.2022.118889. Epub 
2022 Jan 20.

Distinct medial-tempora lobe mechanisms of encoding and amygdala-mediated memory 
reinstatement for disgust and fear.

Riegel M(1), Wierzba M(2), Wypych M(2), Ritchey M(3), Jednoróg K(2), Grabowska 
A(4), Vuilleumier P(5), Marchewka A(2).

Author information:
(1)Laboratory of Brain Imaging, Nencki Institute of Experimental Biology of 
Polish Academy of Sciences, Warsaw 02-093, Poland; Department of Psychology, 
Columbia University, New York 10027, United States of America; Centre 
interfacultaire de gérontologie et d'études des vulnerabilities, University of 
Geneva, CH-Geneva 1211, Switzerland. Electronic address: 
riegel.monika@gmail.com.
(2)Laboratory of Brain Imaging, Nencki Institute of Experimental Biology of 
Polish Academy of Sciences, Warsaw 02-093, Poland.
(3)Department of Psychology and Neuroscience, Boston College, Chestnut Hill, MA 
02467, United States of America.
(4)SWPS University of Social Sciences and Humanities, Warsaw 03-815, Poland.
(5)Department of Neuroscience, University Medical Center, Geneva CH-1211, 
Switzerland; Swiss Center for Affective Sciences, University of Geneva, Campus 
Biotech, CH-Geneva 1211, Switzerland; Geneva Neuroscience Center, University of 
Geneva, Geneva CH-1211, Switzerland.

Current models of episodic memory posit that retrieval involves the reenactment 
of encoding processes. Recent evidence has shown that this reinstatement process 
- indexed by subsequent encoding-retrieval similarity of brain activity patterns 
- is related to the activity in the hippocampus during encoding. However, we 
tend to re-experience emotional events in memory more richly than dull events. 
The role of amygdala - a critical hub of emotion processing - in reinstatement 
of emotional events was poorly understood. To investigate it, we leveraged a 
previously overlooked divergence in the role of amygdala in memory modulation by 
distinct emotions - disgust and fear. Here we used a novel paradigm in which 
participants encoded complex events (word pairs) and their memory was tested 
after 3 weeks, both phases during fMRI scanning. Using representational 
similarity analysis and univariate analyses, we show that the strength of 
amygdala activation during encoding was correlated with memory reinstatement of 
individual event representations in emotion-specific regions. Critically, 
amygdala modulated reinstatement more for disgust than fear. This was in line 
with other differences observed at the level of memory performance and neural 
mechanisms of encoding. Specifically, amygdala and perirhinal cortex were more 
involved during encoding of disgust-related events, whereas hippocampus and 
parahippocampal gyrus during encoding of fear-related events. Together, these 
findings shed a new light on the role of the amygdala and medial temporal lobe 
regions in encoding and reinstatement of specific emotional memories.

Copyright © 2022 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2022.118889
PMID: 35065268 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest No competing 
interests declared.


43. Cereb Cortex. 2022 Aug 22;32(17):3848-3863. doi: 10.1093/cercor/bhab452.

Representational similarity scores of digits in the sensorimotor cortex are 
associated with behavioral performance.

Gooijers J(1)(2), Chalavi S(1)(2), Koster LK(1), Roebroeck A(3), Kaas A(3), 
Swinnen SP(1)(2).

Author information:
(1)Movement Control and Neuroplasticity Research Group, Department of Movement 
Sciences, KU Leuven, Leuven 3000, Belgium.
(2)LBI-KU Leuven Brain Institute, Leuven 3000, Belgium.
(3)Department of Cognitive Neuroscience, Faculty of Psychology & Neuroscience, 
Maastricht University, Maastricht 6229 EV, the Netherlands.

Previous studies aimed to unravel a digit-specific somatotopy in the primary 
sensorimotor (SM1) cortex. However, it remains unknown whether digit somatotopy 
is associated with motor preparation and/or motor execution during different 
types of tasks. We adopted multivariate representational similarity analysis to 
explore digit activation patterns in response to a finger tapping task (FTT). 
Sixteen healthy young adults underwent magnetic resonance imaging, and 
additionally performed an out-of-scanner choice reaction time task (CRTT) to 
assess digit selection performance. During both the FTT and CRTT, force data of 
all digits were acquired using force transducers. This allowed us to assess 
execution-related interference (i.e., digit enslavement; obtained from FTT & 
CRTT), as well as planning-related interference (i.e., digit selection deficit; 
obtained from CRTT) and determine their correlation with digit representational 
similarity scores of SM1. Findings revealed that digit enslavement during FTT 
was associated with contralateral SM1 representational similarity scores. During 
the CRTT, digit enslavement of both hands was also associated with 
representational similarity scores of the contralateral SM1. In addition, right 
hand digit selection performance was associated with representational similarity 
scores of left S1. In conclusion, we demonstrate a cortical origin of digit 
enslavement, and uniquely reveal that digit selection is associated with digit 
representations in primary somatosensory cortex (S1). Significance statement In 
current systems neuroscience, it is of critical importance to understand the 
relationship between brain function and behavioral outcome. With the present 
work, we contribute significantly to this understanding by uniquely assessing 
how digit representations in the sensorimotor cortex are associated with 
planning- and execution-related digit interference during a continuous finger 
tapping and a choice reaction time task. We observe that digit enslavement 
(i.e., execution-related interference) finds its origin in contralateral digit 
representations of SM1, and that deficits in digit selection (i.e., 
planning-related interference) in the right hand during a choice reaction time 
task are associated with more overlapping digit representations in left S1. This 
knowledge sheds new light on the functional contribution of the sensorimotor 
cortex to everyday motor skills.

© The Author(s) 2022. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhab452
PMID: 35029640 [Indexed for MEDLINE]


44. Cereb Cortex. 2022 Jul 21;32(15):3302-3317. doi: 10.1093/cercor/bhab416.

Orienting to different dimensions of word meaning alters the representation of 
word meaning in early processing regions.

Meersmans K(1), Storms G(2), De Deyne S(3), Bruffaerts R(1), Dupont P(1), 
Vandenberghe R(1)(4).

Author information:
(1)Laboratory for Cognitive Neurology, Department of Neurosciences, Leuven Brain 
Institute, 3000 Leuven, Belgium.
(2)Laboratory of Experimental Psychology, 3000 Leuven, Belgium.
(3)Computational Cognitive Science Lab, Melbourne School of Psychological 
Sciences, University of Melbourne, 3010 Melbourne, Australia.
(4)Neurology Department, University Hospitals Leuven, 3000 Leuven, Belgium.

Conscious processing of word meaning can be guided by attention. In this 
event-related functional magnetic resonance imaging study in 22 healthy young 
volunteers, we examined in which regions orienting attention to two fundamental 
and generic dimensions of word meaning, concreteness versus valence, alters the 
semantic representations coded in activity patterns. The stimuli consisted of 
120 nouns in written or spoken modality which varied factorially along the 
concreteness and valence axis. Participants performed a forced-choice judgement 
of either concreteness or valence. Rostral and subgenual anterior cingulate were 
strongly activated during valence judgement, and precuneus and the dorsal 
attention network during concreteness judgement. Task and stimulus type 
interacted in right posterior fusiform gyrus, left lingual gyrus, precuneus, and 
insula. In the right posterior fusiform gyrus and the left lingual gyrus, the 
correlation between the pairwise similarity in activity patterns evoked by words 
and the pairwise distance in valence and concreteness was modulated by the 
direction of attention, word valence or concreteness. The data indicate that 
orienting attention to basic dimensions of word meaning exerts effects on the 
representation of word meaning in more peripheral nodes, such as the ventral 
occipital cortex, rather than the core perisylvian language regions.

© The Author(s) 2021. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permission@oup.com.

DOI: 10.1093/cercor/bhab416
PMCID: PMC9340395
PMID: 34963135 [Indexed for MEDLINE]


45. Front Neurol. 2021 Nov 29;12:674275. doi: 10.3389/fneur.2021.674275. eCollection 
2021.

Multivariate FMRI Signatures of Learning in a Hebb Repetition Paradigm With Tone 
Sequences.

Loo C(1)(2), Lee ACH(1)(2), Buchsbaum BR(1)(2).

Author information:
(1)Rotman Research Institute, Baycrest, Toronto, ON, Canada.
(2)Department of Psychology, University of Toronto, Toronto, ON, Canada.

Important information from the environment often arrives to the brain in 
temporally extended sequences. Language, music, actions, and complex events 
generally unfold over time. When such informational sequences exceed the limited 
capacity of working memory, the human brain relies on its ability to accumulate 
information in long-term memory over several encounters with a complex stimulus. 
A longstanding question in psychology and neuroscience is whether the neural 
structures associated with working memory storage-often viewed as capacity 
limited and temporary-have any builtin ability to store information across 
longer temporal delays. According to the classic Hebbian dual memory theory, 
temporally local "activity traces" underlie immediate perception and working 
memory, whereas "structural traces" undergird long-term learning. Here we 
examine whether brain structures known to be involved in working maintenance of 
auditory sequences, such as area Spt, also show evidence of memory persistence 
across trials. We used representational similarity analysis (RSA) and the Hebb 
repetition paradigm with supracapacity tonal sequences to test whether repeated 
sequences have distinguishable multivoxel activity patterns in the 
auditory-motor networks of the brain. We found that, indeed, area Spt and other 
nodes of the auditory dorsal stream show multivoxel patterns for tone sequences 
that become gradually more distinct with repetition during working memory for 
supracapacity tone-sequences. The findings suggest that the structures are 
important for working memory are not "blank slates," wiped clean from moment to 
moment, but rather encode information in a way can lead to cross-trial 
persistence.

Copyright © 2021 Loo, Lee and Buchsbaum.

DOI: 10.3389/fneur.2021.674275
PMCID: PMC8666569
PMID: 34912281

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


46. R Soc Open Sci. 2021 Nov 24;8(11):202116. doi: 10.1098/rsos.202116. eCollection 
2021 Nov.

Model-based representational similarity analysis of blood-oxygen-level-dependent 
fMRI captures threat learning in social interactions.

Undeger I(1), Visser RM(2), Becker N(1), de Boer L(3)(4), Golkar A(1)(5), Olsson 
A(1).

Author information:
(1)Section for Psychology, Department of Clinical Neuroscience, Karolinska 
Institutet, Nobels väg 9, 171 77 Stockholm, Sweden.
(2)Department of Clinical Psychology, University of Amsterdam, Nieuwe 
Achtergracht 129-B, 1018 WT Amsterdam, The Netherlands.
(3)Department of Neuroscience, Care Sciences and Society, Karolinska Institutet, 
Nobels väg 9, 171 77 Stockholm, Sweden.
(4)Aging Research Center, Tomtebodavägen 18A, 11330 Solna, Stockholms Lån, 
Sweden.
(5)Department of Psychology, Stockholm University, Frescati Hagväg 14, 114 19, 
Stockholm, Sweden.

Past research has shown that attributions of intentions to other's actions 
determine how we experience these actions and their consequences. Yet, it is 
unknown how such attributions affect our learning and memory. Addressing this 
question, we combined neuroimaging with an interactive threat learning paradigm 
in which two interaction partners (confederates) made choices that had either 
threatening (shock) or safe (no shock) consequences for the participants. 
Importantly, participants were led to believe that one partner intentionally 
caused the delivery of shock, whereas the other did not (i.e. unintentional 
partner). Following intentional versus unintentional shocks, participants 
reported an inflated number of shocks and a greater increase in anger and 
vengeance. We applied a model-based representational similarity analysis to 
blood-oxygen-level-dependent (BOLD)-MRI patterns during learning. Surprisingly, 
we did not find any effects of intentionality. The threat value of actions, 
however, was represented as a trial-by-trial increase in representational 
similarity in the insula and the inferior frontal gyrus. Our findings illustrate 
how neural pattern formation can be used to study a complex interaction.

© 2021 The Authors.

DOI: 10.1098/rsos.202116
PMCID: PMC8611347
PMID: 34849237


47. Neuropsychologia. 2022 Jan 7;164:108092. doi: 
10.1016/j.neuropsychologia.2021.108092. Epub 2021 Nov 18.

Skeletal representations of shape in the human visual cortex.

Ayzenberg V(1), Kamps FS(2), Dilks DD(3), Lourenco SF(4).

Author information:
(1)Department of Psychology, Carnegie Mellon University, USA. Electronic 
address: vayzenbe@andrew.cmu.edu.
(2)Department of Brain and Cognitive Sciences, Massachusetts Institute of 
Technology, USA.
(3)Department of Psychology, Emory University, USA.
(4)Department of Psychology, Emory University, USA. Electronic address: 
stella.lourenco@emory.edu.

Shape perception is crucial for object recognition. However, it remains unknown 
exactly how shape information is represented and used by the visual system. 
Here, we tested the hypothesis that the visual system represents object shape 
via a skeletal structure. Using functional magnetic resonance imaging (fMRI) and 
representational similarity analysis (RSA), we found that a model of skeletal 
similarity explained significant unique variance in the response profiles of V3 
and LO. Moreover, the skeletal model remained predictive in these regions even 
when controlling for other models of visual similarity that approximate low-to 
high-level visual features (i.e., Gabor-jet, GIST, HMAX, and AlexNet), and 
across different surface forms, a manipulation that altered object contours 
while preserving the underlying skeleton. Together, these findings shed light on 
shape processing in human vision, as well as the computational properties of V3 
and LO. We discuss how these regions may support two putative roles of shape 
skeletons: namely, perceptual organization and object recognition.

Copyright © 2021 The Authors. Published by Elsevier Ltd.. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2021.108092
PMCID: PMC9840386
PMID: 34801519 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
declare no conflicts of interest.


48. Neuroimage. 2021 Dec 15;245:118686. doi: 10.1016/j.neuroimage.2021.118686. Epub 
2021 Oct 31.

The unreliable influence of multivariate noise normalization on the reliability 
of neural dissimilarity.

Ritchie JB(1), Lee Masson H(2), Bracci S(3), Op de Beeck HP(4).

Author information:
(1)Department of Brain and Cognition, Leuven Brain Institute, KU Leuven, 3000 
Leuven, Flemish Brabant, Belgium. Electronic address: 
j.brendan.w.ritchie@gmail.com.
(2)Department of Cognitive Science, Johns Hopkins University, Baltimore, USA.
(3)Centre for Mind/Brain Sciences, University of Trento, Rovereto, Italy.
(4)Department of Brain and Cognition, Leuven Brain Institute, KU Leuven, 3000 
Leuven, Flemish Brabant, Belgium.

Representational similarity analysis (RSA) is a key element in the multivariate 
pattern analysis toolkit. The central construct of the method is the 
representational dissimilarity matrix (RDM), which can be generated for datasets 
from different modalities (neuroimaging, behavior, and computational models) and 
directly correlated in order to evaluate their second-order similarity. Given 
the inherent noisiness of neuroimaging signals it is important to evaluate the 
reliability of neuroimaging RDMs in order to determine whether these comparisons 
are meaningful. Recently, multivariate noise normalization (NNM) has been 
proposed as a widely applicable method for boosting signal estimates for RSA, 
regardless of choice of dissimilarity metrics, based on evidence that the 
analysis improves the within-subject reliability of RDMs (Guggenmos et al. 2018; 
Walther et al. 2016). We revisited this issue with three fMRI datasets and 
evaluated the impact of NNM on within- and between-subject reliability and RSA 
effect sizes using multiple dissimilarity metrics. We also assessed its impact 
across regions of interest from the same dataset, its interaction with spatial 
smoothing, and compared it to GLMdenoise, which has also been proposed as a 
method that improves signal estimates for RSA (Charest et al. 2018). We found 
that across these tests the impact of NNM was highly variable, as also seems to 
be the case for other analysis choices. Overall, we suggest being conservative 
before adding steps and complexities to the (pre)processing pipeline for RSA.

Copyright © 2021 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2021.118686
PMID: 34728244 [Indexed for MEDLINE]


49. Front Psychiatry. 2021 Oct 11;12:729457. doi: 10.3389/fpsyt.2021.729457. 
eCollection 2021.

Individualizing Representational Similarity Analysis.

Levine SM(1), Schwarzbach JV(2).

Author information:
(1)Institute of Cognitive and Clinical Neuroscience, Central Institute of Mental 
Health, Medical Faculty Mannheim, Heidelberg University, Mannheim, Germany.
(2)Department of Psychiatry and Psychotherapy, University of Regensburg, 
Regensburg, Germany.

Representational similarity analysis (RSA) is a popular multivariate analysis 
technique in cognitive neuroscience that uses functional neuroimaging to 
investigate the informational content encoded in brain activity. As RSA is 
increasingly being used to investigate more clinically-geared questions, the 
focus of such translational studies turns toward the importance of individual 
differences and their optimization within the experimental design. In this 
perspective, we focus on two design aspects: applying individual vs. averaged 
behavioral dissimilarity matrices to multiple participants' neuroimaging data 
and ensuring the congruency between tasks when measuring behavioral and neural 
representational spaces. Incorporating these methods permits the detection of 
individual differences in representational spaces and yields a better-defined 
transfer of information from representational spaces onto multivoxel patterns. 
Such design adaptations are prerequisites for optimal translation of RSA to the 
field of precision psychiatry.

Copyright © 2021 Levine and Schwarzbach.

DOI: 10.3389/fpsyt.2021.729457
PMCID: PMC8542717
PMID: 34707520

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


50. Cortex. 2021 Nov;144:109-132. doi: 10.1016/j.cortex.2021.08.007. Epub 2021 Sep 
24.

The role of stimulus-based cues and conceptual information in processing facial 
expressions of emotion.

Murray T(1), O'Brien J(2), Sagiv N(2), Garrido L(3).

Author information:
(1)Psychology Department, School of Biological and Behavioural Sciences, Queen 
Mary University London, United Kingdom. Electronic address: T.Murray@qmul.ac.uk.
(2)Centre for Cognitive Neuroscience, Department of Life Sciences, Brunel 
University London, United Kingdom.
(3)Department of Psychology, City, University of London, United Kingdom.

Face shape and surface textures are two important cues that aid in the 
perception of facial expressions of emotion. Additionally, this perception is 
also influenced by high-level emotion concepts. Across two studies, we use 
representational similarity analysis to investigate the relative roles of shape, 
surface, and conceptual information in the perception, categorisation, and 
neural representation of facial expressions. In Study 1, 50 participants 
completed a perceptual task designed to measure the perceptual similarity of 
expression pairs, and a categorical task designed to measure the confusability 
between expression pairs when assigning emotion labels to a face. We used 
representational similarity analysis and constructed three models of the 
similarities between emotions using distinct information. Two models were based 
on stimulus-based cues (face shapes and surface textures) and one model was 
based on emotion concepts. Using multiple linear regression, we found that 
behaviour during both tasks was related with the similarity of emotion concepts. 
The model based on face shapes was more related with behaviour in the perceptual 
task than in the categorical, and the model based on surface textures was more 
related with behaviour in the categorical than the perceptual task. In Study 2, 
30 participants viewed facial expressions while undergoing fMRI, allowing for 
the measurement of brain representational geometries of facial expressions of 
emotion in three core face-responsive regions (the Fusiform Face Area, Occipital 
Face Area, and Superior Temporal Sulcus), and a region involved in theory of 
mind (Medial Prefrontal Cortex). Across all four regions, the representational 
distances between facial expression pairs were related to the similarities of 
emotion concepts, but not to either of the stimulus-based cues. Together, these 
results highlight the important top-down influence of high-level emotion 
concepts both in behavioural tasks and in the neural representation of facial 
expressions.

Copyright © 2021 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cortex.2021.08.007
PMID: 34666297 [Indexed for MEDLINE]


51. Neuropsychologia. 2021 Dec 10;163:108048. doi: 
10.1016/j.neuropsychologia.2021.108048. Epub 2021 Oct 12.

Behavioral and neural representations en route to intuitive action 
understanding.

Tarhan L(1), De Freitas J(1), Konkle T(2).

Author information:
(1)Department of Psychology, Harvard University, USA.
(2)Department of Psychology, Harvard University, USA. Electronic address: 
talia_konkle@harvard.edu.

When we observe another person's actions, we process many kinds of information - 
from how their body moves to the intention behind their movements. What kinds of 
information underlie our intuitive understanding about how similar actions are 
to each other? To address this question, we measured the intuitive similarities 
among a large set of everyday action videos using multi-arrangement experiments, 
then used a modeling approach to predict this intuitive similarity space along 
three hypothesized properties. We found that similarity in the actors' inferred 
goals predicted the intuitive similarity judgments the best, followed by 
similarity in the actors' movements, with little contribution from the videos' 
visual appearance. In opportunistic fMRI analyses assessing brain-behavior 
correlations, we found suggestive evidence for an action processing hierarchy, 
in which these three kinds of action similarities are reflected in the structure 
of brain responses along a posterior-to-anterior gradient on the lateral surface 
of the visual cortex. Altogether, this work joins existing literature suggesting 
that humans are naturally tuned to process others' intentions, and that the 
visuo-motor cortex computes the perceptual precursors of the higher-level 
representations over which intuitive action perception operates.

Copyright © 2021 The Author(s). Published by Elsevier Ltd.. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2021.108048
PMCID: PMC8649031
PMID: 34653497 [Indexed for MEDLINE]


52. Curr Biol. 2021 Dec 6;31(23):5192-5203.e4. doi: 10.1016/j.cub.2021.09.043. Epub 
2021 Oct 12.

Visual and auditory brain areas share a representational structure that supports 
emotion perception.

Sievers B(1), Parkinson C(2), Kohler PJ(3), Hughes JM(4), Fogelson SV(5), 
Wheatley T(6).

Author information:
(1)Department of Psychology, Harvard University, Cambridge, MA 02138, USA; 
Department of Psychological and Brain Sciences, Dartmouth College, Hanover, NH 
03755, USA. Electronic address: beau@beausievers.com.
(2)Department of Psychology, University of California, Los Angeles, Los Angeles, 
CA 90095, USA; Brain Research Institute, University of California, Los Angeles, 
Los Angeles, CA 90095, USA.
(3)Department of Psychology, York University, Toronto, ON, Canada; Centre for 
Vision Research, York University, Toronto, ON, Canada.
(4)Wayne, NJ, USA.
(5)Brooklyn, NY, USA.
(6)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH 03755, USA; Santa Fe Institute, Santa Fe, NM 87501, USA. Electronic address: 
thalia.p.wheatley@dartmouth.edu.

Emotionally expressive music and dance occur together across the world. This may 
be because features shared across the senses are represented the same way even 
in different sensory brain areas, putting music and movement in directly 
comparable terms. These shared representations may arise from a general need to 
identify environmentally relevant combinations of sensory features, particularly 
those that communicate emotion. To test the hypothesis that visual and auditory 
brain areas share a representational structure, we created music and animation 
stimuli with crossmodally matched features expressing a range of emotions. 
Participants confirmed that each emotion corresponded to a set of features 
shared across music and movement. A subset of participants viewed both music and 
animation during brain scanning, revealing that representations in auditory and 
visual brain areas were similar to one another. This shared representation 
captured not only simple stimulus features but also combinations of features 
associated with emotion judgments. The posterior superior temporal cortex 
represented both music and movement using this same structure, suggesting 
supramodal abstraction of sensory content. Further exploratory analysis revealed 
that early visual cortex used this shared representational structure even when 
stimuli were presented auditorily. We propose that crossmodally shared 
representations support mutually reinforcing dynamics across auditory and visual 
brain areas, facilitating crossmodal comparison. These shared representations 
may help explain why emotions are so readily perceived and why some dynamic 
emotional expressions can generalize across cultural contexts.

Copyright © 2021. Published by Elsevier Inc.

DOI: 10.1016/j.cub.2021.09.043
PMID: 34644547 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of interests The authors declare no 
competing interests.


53. Neuroimage. 2021 Dec 1;244:118565. doi: 10.1016/j.neuroimage.2021.118565. Epub 
2021 Sep 17.

Neural dynamics underlying the acquisition of distinct auditory category 
structures.

Feng G(1), Gan Z(2), Yi HG(3), Ell SW(4), Roark CL(5), Wang S(6), Wong PCM(7), 
Chandrasekaran B(8).

Author information:
(1)Department of Linguistics and Modern Languages, The Chinese University of 
Hong Kong, Shatin, N.T., Hong Kong SAR, China; Brain and Mind Institute, The 
Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China. Electronic 
address: g.feng@cuhk.edu.hk.
(2)Department of Linguistics and Modern Languages, The Chinese University of 
Hong Kong, Shatin, N.T., Hong Kong SAR, China; Key Laboratory of Brain, 
Cognition and Education Sciences, Ministry of Education, China, School of 
Psychology, Center for Studies of Psychological Application, and Guangdong Key 
Laboratory of Mental Health and Cognitive Science, South China Normal 
University, Guangzhou 510631, China.
(3)Department of Neurological Surgery, University of California, San Francisco, 
CA 94158, United States.
(4)Department of Psychology, Graduate School of Biomedical Sciences and 
Engineering, University of Maine, 5742 Little Hall, Room 301, Orono, ME 
04469-5742, United States.
(5)Department of Communication Science and Disorders, School of Health and 
Rehabilitation Sciences, University of Pittsburgh, Pittsburgh, PA 15260, United 
States; Center for the Neural Basis of Cognition, Pittsburgh, PA 15232, United 
States.
(6)Key Laboratory of Brain, Cognition and Education Sciences, Ministry of 
Education, China, School of Psychology, Center for Studies of Psychological 
Application, and Guangdong Key Laboratory of Mental Health and Cognitive 
Science, South China Normal University, Guangzhou 510631, China.
(7)Department of Linguistics and Modern Languages, The Chinese University of 
Hong Kong, Shatin, N.T., Hong Kong SAR, China; Brain and Mind Institute, The 
Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China.
(8)Department of Communication Science and Disorders, School of Health and 
Rehabilitation Sciences, University of Pittsburgh, Pittsburgh, PA 15260, United 
States; Center for the Neural Basis of Cognition, Pittsburgh, PA 15232, United 
States. Electronic address: b.chandra@pitt.edu.

Despite the multidimensional and temporally fleeting nature of auditory signals 
we quickly learn to assign novel sounds to behaviorally relevant categories. The 
neural systems underlying the learning and representation of novel auditory 
categories are far from understood. Current models argue for a rigid 
specialization of hierarchically organized core regions that are fine-tuned to 
extracting and mapping relevant auditory dimensions to meaningful categories. 
Scaffolded within a dual-learning systems approach, we test a competing 
hypothesis: the spatial and temporal dynamics of emerging auditory-category 
representations are not driven by the underlying dimensions but are constrained 
by category structure and learning strategies. To test these competing models, 
we used functional Magnetic Resonance Imaging (fMRI) to assess representational 
dynamics during the feedback-based acquisition of novel non-speech auditory 
categories with identical dimensions but differing category structures: 
rule-based (RB) categories, hypothesized to involve an explicit sound-to-rule 
mapping network, and information integration (II) based categories, involving 
pre-decisional integration of dimensions via a procedural-based sound-to-reward 
mapping network. Adults were assigned to either the RB (n = 30, 19 females) or 
II (n = 30, 22 females) learning tasks. Despite similar behavioral learning 
accuracies, learning strategies derived from computational modeling and 
involvements of corticostriatal systems during feedback processing differed 
across tasks. Spatiotemporal multivariate representational similarity analysis 
revealed an emerging representation within an auditory sensory-motor pathway 
exclusively for the II learning task, prominently involving the superior 
temporal gyrus (STG), inferior frontal gyrus (IFG), and posterior precentral 
gyrus. In contrast, the RB learning task yielded distributed neural 
representations within regions involved in cognitive-control and attentional 
processes that emerged at different time points of learning. Our results 
unequivocally demonstrate that auditory learners' neural systems are highly 
flexible and show distinct spatial and temporal patterns that are not 
dimension-specific but reflect underlying category structures and learning 
strategies.

Copyright © 2021 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2021.118565
PMCID: PMC8785192
PMID: 34543762 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest Patrick C. M. 
Wong is a founder of a company in Hong Kong supported by a Hong Kong SAR 
government startup scheme for universities.


54. Neuroimage. 2021 Dec 1;244:118574. doi: 10.1016/j.neuroimage.2021.118574. Epub 
2021 Sep 8.

Complementing canonical fMRI with functional Quantitative Susceptibility Mapping 
(fQSM) in modern neuroimaging research.

Lancione M(1), Costagli M(2), Handjaras G(3), Tosetti M(4), Ricciardi E(5), 
Pietrini P(5), Cecchetti L(3).

Author information:
(1)MoMiLab, IMT School for Advanced Studies Lucca, Piazza San Francesco, 19, 
Lucca 55100, Italy; IMAGO7 Foundation, Pisa, Italy. Electronic address: 
marta.lancione@imtlucca.it.
(2)Laboratory of Medical Physics and Magnetic Resonance, IRCCS Fondazione Stella 
Maris, Pisa, Italy; Department of Neuroscience, Rehabilitation, Ophthalmology, 
Genetics, Maternal and Child Sciences (DINOGMI), University of Genoa, Genoa, 
Italy.
(3)Social and Affective Neuroscience (SANe) Group, MoMiLab, IMT School for 
Advanced Studies Lucca, Lucca, Italy.
(4)IMAGO7 Foundation, Pisa, Italy; Laboratory of Medical Physics and Magnetic 
Resonance, IRCCS Fondazione Stella Maris, Pisa, Italy.
(5)MoMiLab, IMT School for Advanced Studies Lucca, Piazza San Francesco, 19, 
Lucca 55100, Italy.

Functional Quantitative Susceptibility Mapping (fQSM) allows for the 
quantitative measurement of time-varying magnetic susceptibility across cortical 
and subcortical brain structures with a potentially higher spatial specificity 
than conventional fMRI. While the usefulness of fQSM with General Linear Model 
and "On/Off" paradigms has been assessed, little is known about the potential 
applications and limitations of this technique in more sophisticated 
experimental paradigms and analyses, such as those currently used in modern 
neuroimaging. To thoroughly characterize fQSM activations, here we used 7T MRI, 
tonotopic mapping, as well as univariate (i.e., GLM and population Receptive 
Field) and multivariate (Representational Similarity Analysis; RSA) analyses. 
Although fQSM detected less tone-responsive voxels than fMRI, they were more 
consistently localized in gray matter. Also, the majority of active gray matter 
voxels exhibited negative fQSM response, signaling the expected oxyhemoglobin 
increase, whereas positive fQSM activations were mainly in white matter. Though 
fMRI- and fQSM-based tonotopic maps were overall comparable, the representation 
of frequency tunings in tone-sensitive regions was significantly more balanced 
for fQSM. Lastly, RSA revealed that frequency information from the auditory 
cortex could be successfully retrieved by using either methods. Overall, fQSM 
produces complementary results to conventional fMRI, as it captures small-scale 
variations in the activation pattern which inform multivariate measures. 
Although positive fQSM responses deserve further investigation, they do not 
impair the interpretation of contrasts of interest. The quantitative nature of 
fQSM, its spatial specificity and the possibility to simultaneously acquire 
canonical fMRI support the use of this technique for longitudinal and 
multicentric studies and pre-surgical mapping.

Copyright © 2021. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2021.118574
PMID: 34508897 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare no conflict of interest.


55. Neuroimage. 2021 Nov;243:118545. doi: 10.1016/j.neuroimage.2021.118545. Epub 
2021 Aug 31.

Decoding the difference between explicit and implicit body expression 
representation in high level visual, prefrontal and inferior parietal cortex.

Marrazzo G(1), Vaessen MJ(1), de Gelder B(2).

Author information:
(1)Department of Cognitive Neuroscience, Faculty of Psychology and Neuroscience, 
Maastricht University, Limburg 6200 MD, Maastricht, the Netherlands.
(2)Department of Cognitive Neuroscience, Faculty of Psychology and Neuroscience, 
Maastricht University, Limburg 6200 MD, Maastricht, the Netherlands; Department 
of Computer Science, University College London, London WC1E 6BT, United Kingdom. 
Electronic address: b.degelder@maastrichtuniversity.nl.

Recent studies provide an increasing understanding of how visual objects 
categories like faces or bodies are represented in the brain and also raised the 
question whether a category based or more dynamic network inspired models are 
more powerful. Two important and so far sidestepped issues in this debate are, 
first, how major category attributes like the emotional expression directly 
influence category representation and second, whether category and attribute 
representation are sensitive to task demands. This study investigated the impact 
of a crucial category attribute like emotional expression on category area 
activity and whether this varies with the participants' task. Using (fMRI) we 
measured BOLD responses while participants viewed whole body expressions and 
performed either an explicit (emotion) or an implicit (shape) recognition task. 
Our results based on multivariate methods show that the type of task is the 
strongest determinant of brain activity and can be decoded in EBA, VLPFC and 
IPL. Brain activity was higher for the explicit task condition in VLPFC and was 
not emotion specific. This pattern suggests that during explicit recognition of 
the body expression, body category representation may be strengthened, and 
emotion and action related activity suppressed. Taken together these results 
stress the importance of the task and of the role of category attributes for 
understanding the functional organization of high level visual cortex.

Copyright © 2021. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2021.118545
PMID: 34478822 [Indexed for MEDLINE]


56. J Neurosci. 2021 Oct 6;41(40):8375-8389. doi: 10.1523/JNEUROSCI.0677-21.2021. 
Epub 2021 Aug 19.

Perceptual and Semantic Representations at Encoding Contribute to True and False 
Recognition of Objects.

Naspi L(1), Hoffman P(2), Devereux B(3), Morcom AM(4).

Author information:
(1)School of Philosophy, Psychology and Language Sciences, University of 
Edinburgh, Edinburgh, EH8 9JZ, United Kingdom Loris.Naspi@ed.ac.uk.
(2)School of Philosophy, Psychology and Language Sciences, University of 
Edinburgh, Edinburgh, EH8 9JZ, United Kingdom.
(3)School of Electronics, Electrical Engineering and Computer Science, Queen's 
University Belfast, Belfast, BT9 5BN, United Kingdom.
(4)School of Psychology, University of Sussex, Falmer, BN1 9QH, United Kingdom.

When encoding new episodic memories, visual and semantic processing is proposed 
to make distinct contributions to accurate memory and memory distortions. Here, 
we used fMRI and preregistered representational similarity analysis to uncover 
the representations that predict true and false recognition of unfamiliar 
objects. Two semantic models captured coarse-grained taxonomic categories and 
specific object features, respectively, while two perceptual models embodied 
low-level visual properties. Twenty-eight female and male participants encoded 
images of objects during fMRI scanning, and later had to discriminate studied 
objects from similar lures and novel objects in a recognition memory test. Both 
perceptual and semantic models predicted true memory. When studied objects were 
later identified correctly, neural patterns corresponded to low-level visual 
representations of these object images in the early visual cortex, lingual, and 
fusiform gyri. In a similar fashion, alignment of neural patterns with 
fine-grained semantic feature representations in the fusiform gyrus also 
predicted true recognition. However, emphasis on coarser taxonomic 
representations predicted forgetting more anteriorly in the anterior ventral 
temporal cortex, left inferior frontal gyrus and, in an exploratory analysis, 
left perirhinal cortex. In contrast, false recognition of similar lure objects 
was associated with weaker visual analysis posteriorly in early visual and left 
occipitotemporal cortex. The results implicate multiple perceptual and semantic 
representations in successful memory encoding and suggest that fine-grained 
semantic as well as visual analysis contributes to accurate later recognition, 
while processing visual image detail is critical for avoiding false recognition 
errors.SIGNIFICANCE STATEMENT People are able to store detailed memories of many 
similar objects. We offer new insights into the encoding of these specific 
memories by combining fMRI with explicit models of how image properties and 
object knowledge are represented in the brain. When people processed 
fine-grained visual properties in occipital and posterior temporal cortex, they 
were more likely to recognize the objects later and less likely to falsely 
recognize similar objects. In contrast, while object-specific feature 
representations in fusiform gyrus predicted accurate memory, coarse-grained 
categorical representations in frontal and temporal regions predicted 
forgetting. The data provide the first direct tests of theoretical assumptions 
about encoding true and false memories, suggesting that semantic representations 
contribute to specific memories as well as errors.

Copyright © 2021 the authors.

DOI: 10.1523/JNEUROSCI.0677-21.2021
PMCID: PMC8496201
PMID: 34413205 [Indexed for MEDLINE]


57. Soc Cogn Affect Neurosci. 2021 Jul 31;17(3):311-22. doi: 10.1093/scan/nsab093. 
Online ahead of print.

Developmental Differences in Affective Representation Between Prefrontal and 
Subcortical Structures.

Mitchell WJ(1), Tepfer LJ(2), Henninger NM(3), Perlman SB(4), Murty VP(1), 
Helion C(1).

Author information:
(1)Department of Psychology, Weiss Hall, Temple University, 1701 N 13th St. 
Philadelphia, PA 19122, USA.
(2)Department of Psychological and Brain Sciences, Moore Hall, Dartmouth 
College, 3 Maynard St, Hanover, NH, 03755, USA.
(3)Klein College of Media and Communication, Annenberg Hall, Temple University, 
2020 N. 13th St. Philadelphia, PA, 19122, USA.
(4)Department of Psychiatry, Washington University of St. Louis, 660 S Euclid 
Ave, St. Louis, MO, 63110, USA.

Developmental studies have identified differences in prefrontal and subcortical 
affective structures between children and adults, which correspond with observed 
cognitive and behavioral maturations from relatively simplistic emotional 
experiences and expressions to more nuanced, complex ones. However, 
developmental changes in the neural representation of emotions have not yet been 
well explored. It stands to reason that adults and children may demonstrate 
observable differences in the representation of affect within key neurological 
structures implicated in affective cognition. Forty-five participants (25 
children; 20 adults) passively viewed positive, negative, and neutral clips from 
popular films while undergoing functional magnetic resonance imaging (fMRI). 
Using representational similarity analysis (RSA) to measure variability in 
neural pattern similarity, we found developmental differences between children 
and adults in the amygdala, nucleus accumbens (NAcc), and ventromedial 
prefrontal cortex (vmPFC), such that children generated less pattern similarity 
within subcortical structures relative to the vmPFC; a phenomenon not replicated 
among their older counterparts. Furthermore, children generated valence-specific 
differences in representational patterns across regions; these valence-specific 
patterns were not found in adults. These results may suggest that affective 
representations grow increasingly dissimilar over development as individuals 
mature from visceral affective responses to more evaluative analyses.

© The Author(s) 2021. Published by Oxford University Press.

DOI: 10.1093/scan/nsab093
PMCID: PMC8881632
PMID: 34331538


58. J Vis. 2021 Jul 6;21(7):5. doi: 10.1167/jov.21.7.5.

A self-supervised deep neural network for image completion resembles early 
visual cortex fMRI activity patterns for occluded scenes.

Svanera M(1)(2), Morgan AT(1)(3), Petro LS(1)(4), Muckli L(1)(5).

Author information:
(1)Centre for Cognitive Neuroimaging, Institute of Neuroscience and Psychology, 
University of Glasgow, UK.
(2)michele.svanera@glasgow.ac.uk.
(3)andrew.morgan@glasgow.ac.uk.
(4)lucy.petro@glasgow.ac.uk.
(5)lars.muckli@glasgow.ac.uk.

The promise of artificial intelligence in understanding biological vision relies 
on the comparison of computational models with brain data with the goal of 
capturing functional principles of visual information processing. Convolutional 
neural networks (CNN) have successfully matched the transformations in 
hierarchical processing occurring along the brain's feedforward visual pathway, 
extending into ventral temporal cortex. However, we are still to learn if CNNs 
can successfully describe feedback processes in early visual cortex. Here, we 
investigated similarities between human early visual cortex and a CNN with 
encoder/decoder architecture, trained with self-supervised learning to fill 
occlusions and reconstruct an unseen image. Using representational similarity 
analysis (RSA), we compared 3T functional magnetic resonance imaging (fMRI) data 
from a nonstimulated patch of early visual cortex in human participants viewing 
partially occluded images, with the different CNN layer activations from the 
same images. Results show that our self-supervised image-completion network 
outperforms a classical object-recognition supervised network (VGG16) in terms 
of similarity to fMRI data. This work provides additional evidence that optimal 
models of the visual system might come from less feedforward architectures 
trained with less supervision. We also find that CNN decoder pathway activations 
are more similar to brain processing compared to encoder activations, suggesting 
an integration of mid- and low/middle-level features in early visual cortex. 
Challenging an artificial intelligence model to learn natural image 
representations via self-supervised learning and comparing them with brain data 
can help us to constrain our understanding of information processing, such as 
neuronal predictive coding.

DOI: 10.1167/jov.21.7.5
PMCID: PMC8288063
PMID: 34259828 [Indexed for MEDLINE]


59. J Neurosci. 2021 Sep 1;41(35):7388-7402. doi: 10.1523/JNEUROSCI.2956-20.2021. 
Epub 2021 Jun 23.

A Representational Similarity Analysis of Cognitive Control during Color-Word 
Stroop.

Freund MC(1), Bugg JM(2), Braver TS(2)(3)(4).

Author information:
(1)Department of Psychological & Brain Sciences, Washington University in St. 
Louis, St. Louis, Missouri 63130 m.freund@wustl.edu.
(2)Department of Psychological & Brain Sciences, Washington University in St. 
Louis, St. Louis, Missouri 63130.
(3)Department of Radiology, Washington University in St. Louis School of 
Medicine, St. Louis, Missouri 63110.
(4)Department of Neuroscience, Washington University in St. Louis School of 
Medicine, St. Louis, Missouri 63110.

Progress in understanding the neural bases of cognitive control has been 
supported by the paradigmatic color-word Stroop task, in which a target response 
(color name) must be selected over a more automatic, yet potentially 
incongruent, distractor response (word). For this paradigm, models have 
postulated complementary coding schemes: dorsomedial frontal cortex (DMFC) is 
proposed to evaluate the demand for control via incongruency-related coding, 
whereas dorsolateral PFC (DLPFC) is proposed to implement control via goal and 
target-related coding. Yet, mapping these theorized schemes to measured neural 
activity within this task has been challenging. Here, we tested for these coding 
schemes relatively directly, by decomposing an event-related color-word Stroop 
task via representational similarity analysis. Three neural coding models were 
fit to the similarity structure of multivoxel patterns of human fMRI activity, 
acquired from 65 healthy, young-adult males and females. Incongruency coding was 
predominant in DMFC, whereas both target and incongruency coding were present 
with indistinguishable strength in DLPFC. In contrast, distractor information 
was strongly encoded within early visual cortex. Further, these coding schemes 
were differentially related to behavior: individuals with stronger DLPFC (and 
lateral posterior parietal cortex) target coding, but weaker DMFC incongruency 
coding, exhibited less behavioral Stroop interference. These results highlight 
the utility of the representational similarity analysis framework for 
investigating neural mechanisms of cognitive control and point to several 
promising directions to extend the Stroop paradigm.SIGNIFICANCE STATEMENT How 
the human brain enables cognitive control - the ability to override behavioral 
habits to pursue internal goals - has been a major focus of neuroscience 
research. This ability has been frequently investigated by using the Stroop 
color-word naming task. With the Stroop as a test-bed, many theories have 
proposed specific neuroanatomical dissociations, in which medial and lateral 
frontal brain regions underlie cognitive control by encoding distinct types of 
information. Yet providing a direct confirmation of these claims has been 
challenging. Here, we demonstrate that representational similarity analysis, 
which estimates and models the similarity structure of brain activity patterns, 
can successfully establish the hypothesized functional dissociations within the 
Stroop task. Representational similarity analysis may provide a useful approach 
for investigating cognitive control mechanisms.

Copyright © 2021 the authors.

DOI: 10.1523/JNEUROSCI.2956-20.2021
PMCID: PMC8412987
PMID: 34162756 [Indexed for MEDLINE]


60. Neuroimage. 2021 Oct 1;239:118271. doi: 10.1016/j.neuroimage.2021.118271. Epub 
2021 Jun 19.

Using distance on the Riemannian manifold to compare representations in brain 
and in models.

Shahbazi M(1), Shirali A(1), Aghajan H(1), Nili H(2).

Author information:
(1)Department of Electrical Engineering, Sharif University of Technology, 
Tehran, Iran.
(2)Wellcome Centre for Integrative Neuroimaging, University of Oxford, United 
Kingdom. Electronic address: hamed.nili@ndcn.ox.ac.uk.

Representational similarity analysis (RSA) summarizes activity patterns for a 
set of experimental conditions into a matrix composed of pairwise comparisons 
between activity patterns. Two examples of such matrices are the 
condition-by-condition inner product and correlation matrix. These 
representational matrices reside on the manifold of positive semidefinite 
matrices, called the Riemannian manifold. We hypothesize that representational 
similarities would be more accurately quantified by considering the underlying 
manifold of the representational matrices. Thus, we introduce the distance on 
the Riemannian manifold as a metric for comparing representations. Analyzing 
simulated and real fMRI data and considering a wide range of metrics, we show 
that the Riemannian distance is least susceptible to sampling bias, results in 
larger intra-subject reliability, and affords searchlight mapping with high 
sensitivity and specificity. Furthermore, we show that the Riemannian distance 
can be used for measuring multi-dimensional connectivity. This measure captures 
both univariate and multivariate connectivity and is also more sensitive to 
nonlinear regional interactions compared to the state-of-the-art measures. 
Applying our proposed metric to neural network representations of natural 
images, we demonstrate that it also possesses outstanding performance in 
quantifying similarity in models. Taken together, our results lend credence to 
the proposition that RSA should consider the manifold of the representational 
matrices to summarize response patterns in the brain and in models.

Copyright © 2021. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2021.118271
PMID: 34157410 [Indexed for MEDLINE]


61. J Neurophysiol. 2021 Aug 1;126(2):464-476. doi: 10.1152/jn.00695.2020. Epub 2021 
Jun 16.

Mental travel in the person domain.

Hayman M(1)(2), Arzy S(1)(2).

Author information:
(1)Neuropsychiatry Lab, Department of Medical Neurosciences, Faculty of 
Medicine, Hebrew University of Jerusalem, Jerusalem, Israel.
(2)Department of Neurology, Hadassah Hebrew University Medical School, 
Jerusalem, Israel.

"Mental travel" is a cognitive concept embodying the human capacity to 
intentionally disengage from the here and now, and mentally experience the world 
from different perspectives. We explored how individuals mentally "travel" to 
the point of view (POV) of other people in varying levels of personal closeness 
and from these perspectives process these people's social network. Under fMRI, 
participants were asked to "project" themselves to the POVs of four different 
people: a close other, a nonclose other, a famous-person, and their own-self, 
and rate the level of affiliation (closeness) to different individuals in the 
respective social network. Participants were always faster making judgments from 
their own POV compared with other POVs (self-projection effect) and for people 
who were personally closer to their adopted POV (social-distance effect). Brain 
activity at the medial prefrontal and anterior cingulate cortex in the self-POV 
was higher, compared with all other conditions. Activity at the right 
temporoparietal junction and medial parietal cortex was found to distinguish 
between the personally related (self, close, and nonclose others) and unrelated 
(famous-person) people. No difference was found between mental travel to the 
POVs of close and nonclose others. Regardless of POV, the precuneus, anterior 
cingulate cortex, prefrontal cortex, and temporoparietal junction distinguished 
between close and distant individuals within the different social networks. 
Representational similarity analysis implicated the left retrosplenial cortex as 
crucial for social distance processing across all POVs. These distinctions 
suggest several constraints regarding our ability to adopt others' POV and 
process not only ours but also other people's social networks and stress the 
importance of proximity in social cognition.NEW & NOTEWORTHY Mental-travel, the 
ability to mentally imagine oneself in a different place and time, is a 
fundamental cognitive concept. Investigation of mental-travel in the social 
domain under fMRI revealed that a network of brain regions, largely overlapping 
the default-mode-network, is responsible for "traveling" to points of view of 
different others; moreover, this network distinguishes between closer and 
less-close others, suggesting that mental-travel is a rich dynamical process, 
encompassing individuals in different proximities and these individuals' social 
network.

DOI: 10.1152/jn.00695.2020
PMID: 34133237 [Indexed for MEDLINE]


62. Brain Cogn. 2021 Aug;152:105757. doi: 10.1016/j.bandc.2021.105757. Epub 2021 Jun 
12.

Neural correlates of the production effect: An fMRI study.

Bailey LM(1), Bodner GE(2), Matheson HE(3), Stewart BM(1), Roddick K(1), O'Neil 
K(1), Simmons M(1), Lambert AM(4), Krigolson OE(5), Newman AJ(1), Fawcett JM(6).

Author information:
(1)Dalhousie University, Department of Psychology and Neuroscience, Halifax, NS 
B3H 4R2, Canada.
(2)Flinders University, College of Education, Psychology and Social Work, 
Adelaide, SA 5001, Australia.
(3)University of Northern British Columbia, Psychology Department Prince George, 
BC V2N 4Z9, Canada.
(4)University of Calgary, Department of Psychology, Calgary, AB T2N 1N4, Canada.
(5)University of Victoria, School of Exercise Science, Victoria, BC V8W 2Y2, 
Canada.
(6)Memorial University of Newfoundland, Department of Psychology, St. John's, NL 
A1B 3X9, Canada. Electronic address: jfawcett@mun.ca.

Recognition memory is improved for items produced at study (e.g., by reading 
them aloud) relative to a non-produced control condition (e.g., silent reading). 
This production effect is typically attributed to the extra elements in the 
production task (e.g., motor activation, auditory perception) enhancing item 
distinctiveness. To evaluate this claim, the present study examined the neural 
mechanisms underlying the production effect. Prior to a recognition memory test, 
different words within a study list were read either aloud, silently, or while 
saying "check" (as a sensorimotor control condition). Production improved 
recognition, and aloud words yielded higher rates of both recollection and 
familiarity judgments than either silent or control words. During encoding, fMRI 
revealed stronger activation in regions associated with motor, somatosensory, 
and auditory processing for aloud items than for either silent or control items. 
These activations were predictive of recollective success for aloud items at 
test. Together, our findings are compatible with a distinctiveness-based account 
of the production effect, while also pointing to the possible role of other 
processing differences during the aloud trials as compared to silent and 
control.

Copyright © 2021 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.bandc.2021.105757
PMID: 34130081 [Indexed for MEDLINE]


63. Neuroscience. 2021 Aug 10;469:46-58. doi: 10.1016/j.neuroscience.2021.06.002. 
Epub 2021 Jun 11.

Weighted RSA: An Improved Framework on the Perception of Audio-visual Affective 
Speech in Left Insula and Superior Temporal Gyrus.

Xu J(1), Dong H(2), Li N(1), Wang Z(1), Guo F(3), Wei J(4), Dang J(5).

Author information:
(1)College of Intelligence and Computing, Tianjin Key Lab of Cognitive Computing 
and Application, Tianjin University, Tianjin, China.
(2)College of Intelligence and Computing, Tianjin Key Lab of Cognitive Computing 
and Application, Tianjin University, Tianjin, China; State Grid Tianjin Electric 
Power Company, China.
(3)School of Computer Science and Engineering, Central South University, 
Changsha 410083, China. Electronic address: guofeieileen@163.com.
(4)College of Intelligence and Computing, Tianjin Key Lab of Cognitive Computing 
and Application, Tianjin University, Tianjin, China. Electronic address: 
jianguo@tju.edu.cn.
(5)College of Intelligence and Computing, Tianjin Key Lab of Cognitive Computing 
and Application, Tianjin University, Tianjin, China; School of Information 
Science, Japan Advanced Institute of Science and Technology, Japan.

Being able to accurately perceive the emotion expressed by the facial or verbal 
expression from others is critical to successful social interaction. However, 
only few studies examined the multimodal interactions on speech emotion, and 
there is no consistence in studies on the speech emotion perception. It remains 
unclear, how the speech emotion of different valence is perceived on the 
multimodal stimuli by our human brain. In this paper, we conducted a functional 
magnetic resonance imaging (fMRI) study with an event-related design, using 
dynamic facial expressions and emotional speech stimuli to express different 
emotions, in order to explore the perception mechanism of speech emotion in 
audio-visual modality. The representational similarity analysis (RSA), 
whole-brain searchlight analysis, and conjunction analysis of emotion were used 
to interpret the representation of speech emotion in different aspects. 
Significantly, a weighted RSA approach was creatively proposed to evaluate the 
contribution of each candidate model to the best fitted model and provided a 
supplement to RSA. The results of weighted RSA indicated that the fitted models 
were superior to all candidate models and the weights could be used to explain 
the representation of ROIs. The bilateral amygdala has been shown to be 
associated with the processing of both positive and negative emotions except 
neutral emotion. It is indicated that the left posterior insula and the left 
anterior superior temporal gyrus (STG) play important roles in the perception of 
multimodal speech emotion.

Copyright © 2021 IBRO. Published by Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuroscience.2021.06.002
PMID: 34119576 [Indexed for MEDLINE]


64. Neuroimage. 2021 Sep;238:118258. doi: 10.1016/j.neuroimage.2021.118258. Epub 
2021 Jun 9.

The representational structure of mental states generalizes across target people 
and stimulus modalities.

Weaverdyck ME(1), Thornton MA(2), Tamir DI(3).

Author information:
(1)Department of Psychology, Princeton University, Princeton, NJ 08544, United 
States. Electronic address: mweaverdyck@ucla.edu.
(2)Department of Psychology, Princeton University, Princeton, NJ 08544, United 
States.
(3)Department of Psychology, Princeton University, Princeton, NJ 08544, United 
States; Princeton Neuroscience Institute, Princeton University, Princeton, NJ 
08544, United States.

Each individual experiences mental states in their own idiosyncratic way, yet 
perceivers can accurately understand a huge variety of states across unique 
individuals. How do they accomplish this feat? Do people think about their own 
anger in the same ways as another person's anger? Is reading about someone's 
anxiety the same as seeing it? Here, we test the hypothesis that a common 
conceptual core unites mental state representations across contexts. Across 
three studies, participants judged the mental states of multiple targets, 
including a generic other, the self, a socially close other, and a socially 
distant other. Participants viewed mental state stimuli in multiple modalities, 
including written scenarios and images. Using representational similarity 
analysis, we found that brain regions associated with social cognition expressed 
stable neural representations of mental states across both targets and 
modalities. Together, these results suggest that people use stable models of 
mental states across different people and contexts.

Copyright © 2021. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2021.118258
PMCID: PMC8327621
PMID: 34118394 [Indexed for MEDLINE]


65. Neuroimage. 2021 Aug 15;237:118220. doi: 10.1016/j.neuroimage.2021.118220. Epub 
2021 May 28.

The unique role of parietal cortex in action observation: Functional 
organization for communicative and manipulative actions.

Urgen BA(1), Orban GA(2).

Author information:
(1)Department of Psychology, Bilkent University, 06800, Bilkent, Ankara, Turkey; 
Interdisciplinary Neuroscience Program, Bilkent University, 06800, Bilkent, 
Ankara, Turkey; National Magnetic Resonance Research Center (UMRAM) and Aysel 
Sabuncu Brain Research Center, Bilkent University, 06800, Bilkent, Ankara, 
Turkey. Electronic address: burcu.urgen@bilkent.edu.tr.
(2)Department of Medicine and Surgery, Neuroscience Unit, University of Parma, 
Italy. Electronic address: guy.orban@kuleuven.be.

Action observation is supported by a network of regions in occipito-temporal, 
parietal, and premotor cortex in primates. Recent research suggests that the 
parietal node has regions dedicated to different action classes including 
manipulation, interpersonal interactions, skin displacement, locomotion, and 
climbing. The goals of the current study consist of: 1) extending this work with 
new classes of actions that are communicative and specific to humans, 2) 
investigating how parietal cortex differs from the occipito-temporal and 
premotor cortex in representing action classes. Human subjects underwent fMRI 
scanning while observing three action classes: indirect communication, direct 
communication, and manipulation, plus two types of control stimuli, static 
controls which were static frames from the video clips, and dynamic controls 
consisting of temporally-scrambled optic flow information. Using univariate 
analysis, MVPA, and representational similarity analysis, our study presents 
several novel findings. First, we provide further evidence for the anatomical 
segregation in parietal cortex of different action classes: We have found a new 
site that is specific for representing human-specific indirect communicative 
actions in cytoarchitectonic parietal area PFt. Second, we found that the 
discriminability between action classes was higher in parietal cortex than the 
other two levels suggesting the coding of action identity information at this 
level. Finally, our results advocate the use of the control stimuli not just for 
univariate analysis of complex action videos but also when using multivariate 
techniques.

Copyright © 2021. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2021.118220
PMCID: PMC8285591
PMID: 34058335 [Indexed for MEDLINE]


66. Psychophysiology. 2021 Aug;58(8):e13834. doi: 10.1111/psyp.13834. Epub 2021 May 
5.

The contributions of the left hippocampus and bilateral inferior parietal lobule 
to form-meaning associative learning.

Qu J(1)(2)(3)(4), Hu L(1)(2)(3)(4), Liu X(1)(2)(3)(4), Dong J(1)(2)(3)(4), Yang 
R(1)(2)(3)(4), Mei L(1)(2)(3)(4).

Author information:
(1)Key Laboratory of Brain, Cognition and Education Sciences, Ministry of 
Education, Guangzhou, China.
(2)School of Psychology, South China Normal University, Guangzhou, China.
(3)Center for Studies of Psychological Application, South China Normal 
University, Guangzhou, China.
(4)Guangdong Key Laboratory of Mental Health and Cognitive Science, South China 
Normal University, Guangzhou, China.

Existing studies have identified crucial roles for the hippocampus and a 
distributed set of cortical regions (e.g., the inferior parietal cortex) in 
learning novel words. Nevertheless, researchers have not clearly determined how 
the hippocampus and cortical regions dynamically interact during novel word 
learning, especially during form-meaning associative learning. As a method to 
address this question, we used an online learning paradigm and representational 
similarity analysis to explore the contributions of the hippocampus and 
neocortex to form-meaning associative learning. Twenty-nine native Chinese 
college students were recruited to learn 30 form-meaning pairs, which were 
repeated 7 times during fMRI scan. Form-meaning associative learning elicited 
activations in a wide neural network including regions required for word 
processing (i.e., the bilateral inferior frontal gyrus and the occipitotemporal 
cortex), regions required for encoding (i.e., the bilateral parahippocampus and 
hippocampus), and regions required for cognitive control (i.e., the anterior 
cingulate cortex and dorsolateral prefrontal cortex). More importantly, our 
study revealed the differential roles of the left hippocampus and bilateral 
inferior parietal lobule (IPL) in form-meaning associative learning. 
Specifically, higher pattern similarity in the bilateral IPL in the early 
learning phase (repetitions 1 to 3) was related to better learning performance, 
while higher pattern similarity in the left hippocampus in the late learning 
phase (repetitions 5 to 7) was associated with better learning performance. 
These findings indicate that the hippocampus and cortical regions (e.g., the 
IPL) contribute to form-meaning learning in different stages.

© 2021 Society for Psychophysiological Research.

DOI: 10.1111/psyp.13834
PMID: 33949705 [Indexed for MEDLINE]


67. Neuroimage. 2021 Aug 15;237:118108. doi: 10.1016/j.neuroimage.2021.118108. Epub 
2021 May 1.

Where there is no object formation, there is no perceptual organization: 
Evidence from the configural superiority effect.

Zhang J(1), Yang X(2), Jin Z(2), Li L(3).

Author information:
(1)MOE Key Lab for Neuroinformation, The Clinical Hospital of Chengdu Brain 
Science Institute, University of Electronic Science and Technology of China, 
China. Electronic address: jjzhang@uestc.edu.cn.
(2)MOE Key Lab for Neuroinformation, The Clinical Hospital of Chengdu Brain 
Science Institute, University of Electronic Science and Technology of China, 
China.
(3)MOE Key Lab for Neuroinformation, The Clinical Hospital of Chengdu Brain 
Science Institute, University of Electronic Science and Technology of China, 
China. Electronic address: liling@uestc.edu.cn.

Object formation is considered the aim of perceptual organization, but such a 
proposition has been neglected in empirical studies. In the current study, we 
investigated the role of object formation in configural superiority. 
Essentially, discrimination on bar orientations was enhanced by adding a right 
angle to each of the bars. Such facilitation is due to the emergent feature (EF) 
of closure formed by combining the bars with right angles. To study object 
formation, visual stimuli were generated by random dot stereograms to form 
objects or holes in 3D. Behaviorally, we found that the EF of closure 
facilitated oddball discrimination on objects, as demonstrated by previous 
studies, but did not facilitate oddball discrimination on holes with the same 
shape as objects. Multivariate pattern analysis of functional magnetic resonance 
imaging (fMRI) data showed that the EF of closure increased the object 
classification accuracy compared to the holes in the lateral occipital cortex 
(LOC), where object information is encoded, but not in the early visual cortex 
(EVC). The neural representations of objects and holes with and without EFs were 
further investigated using representational similarity analysis. The results 
demonstrate that in the LOC, the neural representations of objects with EFs 
showed a greater difference than those of the other three, that is, objects 
without EFs and holes with or without EFs. However, the uniqueness of objects 
with EFs was not observed in the EVC. Thus, our results suggest that the EF of 
closure, which leads to the configural superiority effect, only emerges for 
objects but not for holes, and only in the LOC but not the EVC. Our study 
provides the first empirical evidence suggesting that object formation plays an 
indispensable role in perceptual organization.

Copyright © 2021. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2021.118108
PMID: 33940152 [Indexed for MEDLINE]


68. Neuroimage. 2021 Aug 15;237:118107. doi: 10.1016/j.neuroimage.2021.118107. Epub 
2021 Apr 30.

Speech-evoked brain activity is more robust to competing speech when it is 
spoken by someone familiar.

Holmes E(1), Johnsrude IS(2).

Author information:
(1)The Brain and Mind Institute, University of Western Ontario, London, Ontario, 
N6A 3K7, Canada. Electronic address: emma.holmes@ucl.ac.uk.
(2)The Brain and Mind Institute, University of Western Ontario, London, Ontario, 
N6A 3K7, Canada; School of Communication Sciences and Disorders, University of 
Western Ontario, London, Ontario, London, N6G 1H1, Canada.

When speech is masked by competing sound, people are better at understanding 
what is said if the talker is familiar compared to unfamiliar. The benefit is 
robust, but how does processing of familiar voices facilitate intelligibility? 
We combined high-resolution fMRI with representational similarity analysis to 
quantify the difference in distributed activity between clear and masked speech. 
We demonstrate that brain representations of spoken sentences are less affected 
by a competing sentence when they are spoken by a friend or partner than by 
someone unfamiliar-effectively, showing a cortical signal-to-noise ratio (SNR) 
enhancement for familiar voices. This effect correlated with the familiar-voice 
intelligibility benefit. We functionally parcellated auditory cortex, and found 
that the most prominent familiar-voice advantage was manifest along the 
posterior superior and middle temporal gyri. Overall, our results demonstrate 
that experience-driven improvements in intelligibility are associated with 
enhanced multivariate pattern activity in posterior temporal cortex.

Copyright © 2021. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2021.118107
PMID: 33933598 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of interests The authors declare no 
competing interests.


69. J Neurosci. 2021 Jun 2;41(22):4897-4909. doi: 10.1523/JNEUROSCI.2641-20.2021. 
Epub 2021 Apr 26.

Brain Coding of Social Network Structure.

Peer M(1)(2)(3), Hayman M(4)(2), Tamir B(4), Arzy S(1)(2).

Author information:
(1)Department of Medical Neurosciences, Faculty of Medicine, Hebrew University 
of Jerusalem, Jerusalem 91120, Israel michael.peer@mail.huji.ac.il 
shahar.arzy@ekmd.huji.ac.il.
(2)Department of Neurology, Hadassah Hebrew University Medical School, Jerusalem 
91120, Israel.
(3)Department of Psychology, University of Pennsylvania, Philadelphia, 
Pennsylvania 19104.
(4)Department of Medical Neurosciences, Faculty of Medicine, Hebrew University 
of Jerusalem, Jerusalem 91120, Israel.

Humans have large social networks, with hundreds of interacting individuals. How 
does the brain represent the complex connectivity structure of these networks? 
Here we used social media (Facebook) data to objectively map participants' 
real-life social networks. We then used representational similarity analysis 
(RSA) of functional magnetic resonance imaging (fMRI) activity patterns to 
investigate the neural coding of these social networks as participants reflected 
on each individual. We found coding of social network distances in the 
default-mode network (medial prefrontal, medial parietal, and lateral parietal 
cortices). When using partial correlation RSA to control for other factors that 
can be correlated to social distance (personal affiliation, personality traits. 
and visual appearance, as subjectively rated by the participants), we found that 
social network distance information was uniquely coded in the retrosplenial 
complex, a region involved in spatial processing. In contrast, information on 
individuals' personal affiliation to the participants and personality traits was 
found in the medial parietal and prefrontal cortices, respectively. These 
findings demonstrate a cortical division between representations of 
non-self-referenced (allocentric) social network structure, self-referenced 
(egocentric) social distance, and trait-based social knowledge.SIGNIFICANCE 
STATEMENT Each of us has a social network composed of hundreds of individuals, 
with different characteristics and different relations among them. How does our 
brain represent this complexity? To find out, we mapped participants' social 
connections using Facebook data and then asked them to think about individuals 
from their network while undergoing functional MRI scanning. We found that the 
position of individuals within the social network, as well as their affiliation 
to the participant, are mapped in the retrosplenial complex, a region involved 
in spatial processing. Individuals' personality traits were coded in another 
region, the medial prefrontal cortex. Our findings demonstrate a neural 
dissociation among different aspects of social knowledge and suggest a link 
between spatial and social cognitive mapping.

Copyright © 2021 the authors.

DOI: 10.1523/JNEUROSCI.2641-20.2021
PMCID: PMC8260169
PMID: 33903220 [Indexed for MEDLINE]


70. eNeuro. 2021 May 25;8(3):ENEURO.0362-20.2021. doi: 10.1523/ENEURO.0362-20.2021. 
Print 2021 May-Jun.

Representational Content of Oscillatory Brain Activity during Object 
Recognition: Contrasting Cortical and Deep Neural Network Hierarchies.

Reddy L(1)(2), Cichy RM(3), VanRullen R(4)(2).

Author information:
(1)Artificial and Natural Intelligence Toulouse Institute, Université de 
Toulouse 3, Toulouse 31052, France leila.reddy@cnrs.fr.
(2)Centre National de la Recherche Scientifique, Centre de Recherche Cerveau et 
Cognition (CerCo), Toulouse 31052, France.
(3)Department of Education and Psychology, Freie Universität Berlin, Berlin 
14195, Germany.
(4)Artificial and Natural Intelligence Toulouse Institute, Université de 
Toulouse 3, Toulouse 31052, France.

Numerous theories propose a key role for brain oscillations in visual 
perception. Most of these theories postulate that sensory information is encoded 
in specific oscillatory components (e.g., power or phase) of specific frequency 
bands. These theories are often tested with whole-brain recording methods of low 
spatial resolution (EEG or MEG), or depth recordings that provide a local, 
incomplete view of the brain. Opportunities to bridge the gap between local 
neural populations and whole-brain signals are rare. Here, using 
representational similarity analysis (RSA) in human participants we explore 
which MEG oscillatory components (power and phase, across various frequency 
bands) correspond to low or high-level visual object representations, using 
brain representations from fMRI, or layer-wise representations in seven recent 
deep neural networks (DNNs), as a template for low/high-level object 
representations. The results showed that around stimulus onset and offset, most 
transient oscillatory signals correlated with low-level brain patterns (V1). 
During stimulus presentation, sustained β (∼20 Hz) and γ (>60 Hz) power best 
correlated with V1, while oscillatory phase components correlated with IT 
representations. Surprisingly, this pattern of results did not always correspond 
to low-level or high-level DNN layer activity. In particular, sustained β band 
oscillatory power reflected high-level DNN layers, suggestive of a feed-back 
component. These results begin to bridge the gap between whole-brain oscillatory 
signals and object representations supported by local neuronal activations.

Copyright © 2021 Reddy et al.

DOI: 10.1523/ENEURO.0362-20.2021
PMCID: PMC8152371
PMID: 33903182 [Indexed for MEDLINE]


71. Neuropsychologia. 2021 Jun 18;156:107857. doi: 
10.1016/j.neuropsychologia.2021.107857. Epub 2021 Apr 16.

Similar activation patterns in the bilateral dorsal inferior frontal gyrus for 
monolingual and bilingual contexts in second language production.

Liu X(1), Qu J(1), Li H(1), Yang R(1), Mei L(2).

Author information:
(1)Key Laboratory of Brain, Cognition and Education Sciences (South China Normal 
University), Ministry of Education, China; School of Psychology, South China 
Normal University, 510631, Guangzhou, China; Center for Studies of Psychological 
Application, South China Normal University, 510631, Guangzhou, China; Guangdong 
Key Laboratory of Mental Health and Cognitive Science, South China Normal 
University, 510631, Guangzhou, China.
(2)Key Laboratory of Brain, Cognition and Education Sciences (South China Normal 
University), Ministry of Education, China; School of Psychology, South China 
Normal University, 510631, Guangzhou, China; Center for Studies of Psychological 
Application, South China Normal University, 510631, Guangzhou, China; Guangdong 
Key Laboratory of Mental Health and Cognitive Science, South China Normal 
University, 510631, Guangzhou, China. Electronic address: mll830925@126.com.

Language production is a vital process of communication. Although many studies 
have devoted to the neural mechanisms of language production in bilinguals, they 
mainly focused on the mechanisms of cognitive control during language switching. 
Therefore, it is not clear how naming context influences the neural 
representations of linguistic information during language production in 
bilinguals. To address that question, the present study adopted representational 
similarity analysis (RSA) to investigate the neural pattern similarity (PS) 
between the monolingual and bilingual contexts separately for native and second 
languages. Consistent with previous findings, bilinguals behaviorally performed 
worse, and showed greater activation in brain regions for cognitive control 
including the anterior cingulate cortex and dorsolateral prefrontal cortex in 
the bilingual context relative to the monolingual context. More importantly, RSA 
revealed that bilinguals exhibited similar neural activation patterns in the 
bilateral dorsal inferior frontal gyrus between the monolingual and bilingual 
contexts in the production of the second language. Moreover, higher 
cross-context PS in the right inferior frontal gyrus was associated with smaller 
differences in naming speed of second language between the monolingual and 
bilingual contexts. These results suggest that similar linguistic 
representations are encoded for the monolingual and bilingual contexts in the 
production of non-dominant language.

Copyright © 2021 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2021.107857
PMID: 33857531 [Indexed for MEDLINE]


72. Nat Commun. 2021 Apr 6;12(1):2065. doi: 10.1038/s41467-021-22244-7.

Limits to visual representational correspondence between convolutional neural 
networks and the human brain.

Xu Y(1), Vaziri-Pashkam M(2).

Author information:
(1)Psychology Department, Yale University, New Haven, CT, USA. 
xucogneuro@gmail.com.
(2)Laboratory of Brain and Cognition, National Institute of Mental Health, 
Bethesda, MD, USA.

Erratum in
    Nat Commun. 2021 May 6;12(1):2740.

Convolutional neural networks (CNNs) are increasingly used to model human vision 
due to their high object categorization capabilities and general correspondence 
with human brain responses. Here we evaluate the performance of 14 different 
CNNs compared with human fMRI responses to natural and artificial images using 
representational similarity analysis. Despite the presence of some CNN-brain 
correspondence and CNNs' impressive ability to fully capture lower level visual 
representation of real-world objects, we show that CNNs do not fully capture 
higher level visual representations of real-world objects, nor those of 
artificial objects, either at lower or higher levels of visual representations. 
The latter is particularly critical, as the processing of both real-world and 
artificial visual stimuli engages the same neural circuits. We report similar 
results regardless of differences in CNN architecture, training, or the presence 
of recurrent processing. This indicates some fundamental differences exist in 
how the brain and CNNs represent visual information.

DOI: 10.1038/s41467-021-22244-7
PMCID: PMC8024324
PMID: 33824315 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


73. J Neurosci. 2021 Apr 21;41(16):3721-3730. doi: 10.1523/JNEUROSCI.1637-20.2021. 
Epub 2021 Mar 22.

Linking Amygdala Persistence to Real-World Emotional Experience and 
Psychological Well-Being.

Puccetti NA(1), Schaefer SM(2), van Reekum CM(3), Ong AD(4), Almeida DM(5), Ryff 
CD(6), Davidson RJ(2)(6), Heller AS(7).

Author information:
(1)Department of Psychology, University of Miami, Coral Gables, Florida 33124.
(2)Center for Healthy Minds, University of Wisconsin-Madison, Madison, Wisconsin 
53703.
(3)School of Psychology and Clinical Language Science, University of Reading, 
Reading RG6 6AL, United Kingdom.
(4)Department of Human Development, Cornell University, Ithaca, New York 14853.
(5)Department of Human Development and Family Studies and Center for Healthy 
Aging, The Pennsylvania State University, University Park, Pennsylvania 16802.
(6)Department of Psychology, University of Wisconsin-Madison, Madison, Wisconsin 
53706.
(7)Department of Psychology, University of Miami, Coral Gables, Florida 33124 
aheller@miami.edu.

Neural dynamics in response to affective stimuli are linked to momentary 
emotional experiences. The amygdala, in particular, is involved in subjective 
emotional experience and assigning value to neutral stimuli. Because amygdala 
activity persistence following aversive events varies across individuals, some 
may evaluate subsequent neutral stimuli more negatively than others. This may 
lead to more frequent and long-lasting momentary emotional experiences, which 
may also be linked to self-evaluative measures of psychological well-being 
(PWB). Despite extant links between daily affect and PWB, few studies have 
directly explored the links between amygdala persistence, daily affective 
experience, and PWB. To that end, we examined data from 52 human adults (67% 
female) in the Midlife in the United States study who completed measures of PWB, 
daily affect, and functional MRI (fMRI). During fMRI, participants viewed 
affective images followed by a neutral facial expression, permitting 
quantification of individual differences in the similarity of amygdala 
representations of affective stimuli and neutral facial expressions that follow. 
Using representational similarity analysis, neural persistence following 
aversive stimuli was operationalized as similarity between the amygdala 
activation patterns while encoding negative images and the neutral facial 
expressions shown afterward. Individuals demonstrating less persistent 
activation patterns in the left amygdala to aversive stimuli reported more 
positive and less negative affect in daily life. Further, daily positive affect 
served as an indirect link between left amygdala persistence and PWB. These 
results clarify important connections between individual differences in brain 
function, daily experiences of affect, and well-being.SIGNIFICANCE STATEMENT At 
the intersection of affective neuroscience and psychology, researchers have 
aimed to understand how individual differences in the neural processing of 
affective events map onto to real-world emotional experiences and evaluations of 
well-being. Using a longitudinal dataset from 52 adults in the Midlife in the 
United States (MIDUS) study, we provide an integrative model of affective 
functioning: less amygdala persistence following negative images predicts 
greater positive affect (PA) in daily life, which in turn predicts greater 
psychological well-being (PWB) seven years later. Thus, day-to-day experiences 
of PA comprise a promising intermediate step that links individual differences 
in neural dynamics to complex judgements of PWB.

Copyright © 2021 the authors.

DOI: 10.1523/JNEUROSCI.1637-20.2021
PMCID: PMC8055079
PMID: 33753544 [Indexed for MEDLINE]


74. J Neural Eng. 2021 Mar 25;18(4). doi: 10.1088/1741-2552/abecc3.

Towards semantic fMRI neurofeedback: navigating among mental states using 
real-time representational similarity analysis.

Russo AG(1)(2), Lührs M(3)(4), Di Salle F(2), Esposito F(2)(3)(5), Goebel 
R(3)(4).

Author information:
(1)Department of Political and Communication Sciences, University of Salerno, 
Fisciano (Salerno), Italy.
(2)Department of Medicine, Surgery and Dentistry, Scuola Medica Salernitana, 
University of Salerno, Baronissi (Salerno), Italy.
(3)Department of Cognitive Neuroscience, University of Maastricht, Maastricht, 
The Netherlands.
(4)Brain Innovation B.V., Maastricht, The Netherlands.
(5)Department of Advanced Medical and Surgical Sciences,University of Campania 
'Luigi Vanvitelli', Napoli,Italy.

Objective. Real-time functional magnetic resonance imaging neurofeedback 
(rt-fMRI-NF) is a non-invasive MRI procedure allowing examined participants to 
learn to self-regulate brain activity by performing mental tasks. A novel 
two-step rt-fMRI-NF procedure is proposed whereby the feedback display is 
updated in real-time based on high-level representations of experimental stimuli 
(e.g. objects to imagine) via real-time representational similarity analysis of 
multi-voxel patterns of brain activity.Approach. In a localizer session, the 
stimuli become associated with anchored points on a two-dimensional 
representational space where distances approximate between-pattern 
(dis)similarities. In the NF session, participants modulate their brain 
response, displayed as a movable point, to engage in a specific neural 
representation. The developed method pipeline is verified in a proof-of-concept 
rt-fMRI-NF study at 7 T involving a single healthy participant imagining 
concrete objects. Based on this data and artificial data sets with similar 
(simulated) spatio-temporal structure and variable (injected) signal and noise, 
the dependence on noise is systematically assessed.Main results. The participant 
in the proof-of-concept study exhibited robust activation patterns in the 
localizer session and managed to control the neural representation of a stimulus 
towards the selected target in the NF session. The offline analyses validated 
the rt-fMRI-NF results, showing that the rapid convergence to the target 
representation is noise-dependent.Significance. Our proof-of-concept study 
introduces a new NF method allowing the participant to navigate among different 
mental states. Compared to traditional NF designs (e.g. using a thermometer 
display to set the level of the neural signal), the proposed approach provides 
content-specific feedback to the participant and extra degrees of freedom to the 
experimenter enabling real-time control of the neural activity towards a target 
brain state without suggesting a specific mental strategy to the subject.

© 2021 IOP Publishing Ltd.

DOI: 10.1088/1741-2552/abecc3
PMID: 33684900 [Indexed for MEDLINE]


75. Cortex. 2021 May;138:72-89. doi: 10.1016/j.cortex.2021.01.020. Epub 2021 Feb 12.

Maintaining verbal short-term memory representations in non-perceptual parietal 
regions.

Yue Q(1), Martin RC(2).

Author information:
(1)Department of Psychological Sciences, Rice University, Houston, TX 77005, 
USA; Department of Psychology, Vanderbilt University, Nashville, TN 37240, USA. 
Electronic address: qiuhai.yue@vanderbilt.edu.
(2)Department of Psychological Sciences, Rice University, Houston, TX 77005, 
USA. Electronic address: rmartin@rice.edu.

Buffer accounts of verbal short-term memory (STM) assume dedicated buffers for 
maintaining different types of information (e.g., phonological, visual) whereas 
embedded processes accounts argue against the existence of buffers and claim 
that STM consists of the activated portion of long-term memory (LTM). We 
addressed this debate by determining whether STM recruits the same neural 
substrate as LTM, or whether additional regions are involved in short-term 
storage. Using fMRI with representational similarity analysis (RSA), we examined 
the representational correspondence of multi-voxel neural activation patterns 
with the theoretical predictions for the maintenance of both phonological and 
semantic codes in STM. We found that during the delay period of a phonological 
STM task, phonological representations could be decoded in the left 
supramarginal gyrus (SMG) but not the superior temporal gyrus (STG), a speech 
processing region, for word stimuli. Whereas the pattern in the SMG was specific 
to phonology, a different region in the left angular gyrus showed RSA decoding 
evidence for the retention of either phonological or semantic codes, depending 
on the task context. Taken together, the results provide clear support for a 
dedicated buffer account of phonological STM, although evidence for a semantic 
buffer is equivocal.

Copyright © 2021 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cortex.2021.01.020
PMID: 33677329 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest None declared.


76. J Neurosci. 2021 Mar 31;41(13):2980-2989. doi: 10.1523/JNEUROSCI.2489-20.2020. 
Epub 2021 Feb 9.

Expert Tool Users Show Increased Differentiation between Visual Representations 
of Hands and Tools.

Schone HR(1)(2), Maimon-Mor RO(3)(4), Baker CI(2), Makin TR(3)(5).

Author information:
(1)Institute of Cognitive Neuroscience, University College London, London, 
United Kingdom WC1N 3AZ hunter.schone@nih.gov.
(2)Laboratory of Brain and Cognition, National Institute of Mental Health, 
National Institutes of Health, Bethesda, Maryland 20892.
(3)Institute of Cognitive Neuroscience, University College London, London, 
United Kingdom WC1N 3AZ.
(4)WIN Centre, Nuffield Department of Clinical Neuroscience, University of 
Oxford, Oxford, United Kingdom OX3 9DU.
(5)Wellcome Trust Centre for Neuroimaging, University College London, London, 
United Kingdom WC1N 3AR.

The idea that when we use a tool we incorporate it into the neural 
representation of our body (embodiment) has been a major inspiration for 
philosophy, science, and engineering. While theoretically appealing, there is 
little direct evidence for tool embodiment at the neural level. Using functional 
magnetic resonance imaging (fMRI) in male and female human subjects, we 
investigated whether expert tool users (London litter pickers: n = 7) represent 
their expert tool more like a hand (neural embodiment) or less like a hand 
(neural differentiation), as compared with a group of tool novices (n = 12). 
During fMRI scans, participants viewed first-person videos depicting grasps 
performed by either a hand, litter picker, or a non-expert grasping tool. Using 
representational similarity analysis (RSA), differences in the representational 
structure of hands and tools were measured within occipitotemporal cortex (OTC). 
Contrary to the neural embodiment theory, we find that the experts group 
represent their own tool less like a hand (not more) relative to novices. Using 
a case-study approach, we further replicated this effect, independently, in five 
of the seven individual expert litter pickers, as compared with the novices. An 
exploratory analysis in left parietal cortex, a region implicated in visuomotor 
representations of hands and tools, also indicated that experts do not visually 
represent their tool more similar to hands, compared with novices. Together, our 
findings suggest that extensive tool use leads to an increased neural 
differentiation between visual representations of hands and tools. This evidence 
provides an important alternative framework to the prominent tool embodiment 
theory.SIGNIFICANCE STATEMENT It is commonly thought that tool use leads to the 
assimilation of the tool into the neural representation of the body, a process 
referred to as embodiment. Here, we demonstrate that expert tool users (London 
litter pickers) neurally represent their own tool less like a hand (not more), 
compared with novices. Our findings advance our current understanding for how 
experience shapes functional organization in high-order visual cortex. Further, 
this evidence provides an alternative framework to the prominent tool embodiment 
theory, suggesting instead that experience with tools leads to more distinct, 
separable hand and tool representations.

Copyright © 2021 Schone, Maimon-Mor et al.

DOI: 10.1523/JNEUROSCI.2489-20.2020
PMCID: PMC8018880
PMID: 33563728 [Indexed for MEDLINE]


77. J Neurosci. 2021 Mar 24;41(12):2762-2779. doi: 10.1523/JNEUROSCI.2034-19.2021. 
Epub 2021 Feb 5.

Semantic Knowledge of Famous People and Places Is Represented in Hippocampus and 
Distinct Cortical Networks.

Morton NW(1), Zippi EL(2), Noh SM(2), Preston AR(2)(3)(4).

Author information:
(1)Center for Learning & Memory neal.morton@austin.utexas.edu.
(2)Center for Learning & Memory.
(3)Department of Psychology.
(4)Department of Neuroscience, University of Texas at Austin, Austin, Texas 
78712.

Studies have found that anterior temporal lobe (ATL) is critical for detailed 
knowledge of object categories, suggesting that it has an important role in 
semantic memory. However, in addition to information about entities, such as 
people and objects, semantic memory also encompasses information about places. 
We tested predictions stemming from the PMAT model, which proposes there are 
distinct systems that support different kinds of semantic knowledge: an anterior 
temporal (AT) network, which represents information about entities; and a 
posterior medial (PM) network, which represents information about places. We 
used representational similarity analysis to test for activation of semantic 
features when human participants viewed pictures of famous people and places, 
while controlling for visual similarity. We used machine learning techniques to 
quantify the semantic similarity of items based on encyclopedic knowledge in the 
Wikipedia page for each item and found that these similarity models accurately 
predict human similarity judgments. We found that regions within the AT network, 
including ATL and inferior frontal gyrus, represented detailed semantic 
knowledge of people. In contrast, semantic knowledge of places was represented 
within PM network areas, including precuneus, posterior cingulate cortex, 
angular gyrus, and parahippocampal cortex. Finally, we found that hippocampus, 
which has been proposed to serve as an interface between the AT and PM networks, 
represented fine-grained semantic similarity for both individual people and 
places. Our results provide evidence that semantic knowledge of people and 
places is represented separately in AT and PM areas, whereas hippocampus 
represents semantic knowledge of both categories.SIGNIFICANCE STATEMENT Humans 
acquire detailed semantic knowledge about people (e.g., their occupation and 
personality) and places (e.g., their cultural or historical significance). While 
research has demonstrated that brain regions preferentially respond to pictures 
of people and places, less is known about whether these regions preferentially 
represent semantic knowledge about specific people and places. We used machine 
learning techniques to develop a model of semantic similarity based on 
information available from Wikipedia, validating the model against similarity 
ratings from human participants. Using our computational model, we found that 
semantic knowledge about people and places is represented in distinct anterior 
temporal and posterior medial brain networks, respectively. We further found 
that hippocampus, an important memory center, represented semantic knowledge for 
both types of stimuli.

Copyright © 2021 the authors.

DOI: 10.1523/JNEUROSCI.2034-19.2021
PMCID: PMC8018744
PMID: 33547163 [Indexed for MEDLINE]


78. J Neurosci. 2021 Mar 3;41(9):1952-1969. doi: 10.1523/JNEUROSCI.1449-20.2020. 
Epub 2021 Jan 15.

FFA and OFA Encode Distinct Types of Face Identity Information.

Tsantani M(1), Kriegeskorte N(2), Storrs K(3), Williams AL(4), McGettigan C(5), 
Garrido L(1).

Author information:
(1)Division of Psychology, Department of Life Sciences, Brunel University 
London, Uxbridge, UB8 3PH, United Kingdom maria.tsantani@gmail.com 
lucia.garrido@city.ac.uk.
(2)Zuckerman Mind Brain Behavior Institute, Columbia University, New York, New 
York 10027.
(3)Department of Experimental Psychology, Justus Liebig University, Giessen, 
35390, Germany.
(4)Division of Psychology, Department of Life Sciences, Brunel University 
London, Uxbridge, UB8 3PH, United Kingdom.
(5)Speech Hearing and Phonetic Sciences, University College London, London WC1N 
1PF, United Kingdom.

Faces of different people elicit distinct fMRI patterns in several 
face-selective regions of the human brain. Here we used representational 
similarity analysis to investigate what type of identity-distinguishing 
information is encoded in three face-selective regions: fusiform face area 
(FFA), occipital face area (OFA), and posterior superior temporal sulcus (pSTS). 
In a sample of 30 human participants (22 females, 8 males), we used fMRI to 
measure brain activity patterns elicited by naturalistic videos of famous face 
identities, and compared their representational distances in each region with 
models of the differences between identities. We built diverse candidate models, 
ranging from low-level image-computable properties (pixel-wise, GIST, and 
Gabor-Jet dissimilarities), through higher-level image-computable descriptions 
(OpenFace deep neural network, trained to cluster faces by identity), to complex 
human-rated properties (perceived similarity, social traits, and gender). We 
found marked differences in the information represented by the FFA and OFA. 
Dissimilarities between face identities in FFA were accounted for by differences 
in perceived similarity, Social Traits, Gender, and by the OpenFace network. In 
contrast, representational distances in OFA were mainly driven by differences in 
low-level image-based properties (pixel-wise and Gabor-Jet dissimilarities). Our 
results suggest that, although FFA and OFA can both discriminate between 
identities, the FFA representation is further removed from the image, encoding 
higher-level perceptual and social face information.SIGNIFICANCE STATEMENT 
Recent studies using fMRI have shown that several face-responsive brain regions 
can distinguish between different face identities. It is however unclear whether 
these different face-responsive regions distinguish between identities in 
similar or different ways. We used representational similarity analysis to 
investigate the computations within three brain regions in response to 
naturalistically varying videos of face identities. Our results revealed that 
two regions, the fusiform face area and the occipital face area, encode distinct 
identity information about faces. Although identity can be decoded from both 
regions, identity representations in fusiform face area primarily contained 
information about social traits, gender, and high-level visual features, whereas 
occipital face area primarily represented lower-level image features.

Copyright © 2021 the authors.

DOI: 10.1523/JNEUROSCI.1449-20.2020
PMCID: PMC7939092
PMID: 33452225 [Indexed for MEDLINE]


79. Front Neuroinform. 2020 Dec 23;14:563669. doi: 10.3389/fninf.2020.563669. 
eCollection 2020.

NeuroRA: A Python Toolbox of Representational Analysis From Multi-Modal Neural 
Data.

Lu Z(1)(2)(3), Ku Y(1)(2).

Author information:
(1)Guangdong Provincial Key Laboratory of Social Cognitive Neuroscience and 
Mental Health, Department of Psychology, Sun Yat-sen University, Guangzhou, 
China.
(2)Peng Cheng Laboratory, Shenzhen, China.
(3)Shanghai Key Laboratory of Brain Functional Genomics, Shanghai Changning-East 
China Normal University (ECNU) Mental Health Center, School of Psychology and 
Cognitive Science, East China Normal University, Shanghai, China.

In studies of cognitive neuroscience, multivariate pattern analysis (MVPA) is 
widely used as it offers richer information than traditional univariate 
analysis. Representational similarity analysis (RSA), as one method of MVPA, has 
become an effective decoding method based on neural data by calculating the 
similarity between different representations in the brain under different 
conditions. Moreover, RSA is suitable for researchers to compare data from 
different modalities and even bridge data from different species. However, 
previous toolboxes have been made to fit specific datasets. Here, we develop 
NeuroRA, a novel and easy-to-use toolbox for representational analysis. Our 
toolbox aims at conducting cross-modal data analysis from multi-modal neural 
data (e.g., EEG, MEG, fNIRS, fMRI, and other sources of 
neruroelectrophysiological data), behavioral data, and computer-simulated data. 
Compared with previous software packages, our toolbox is more comprehensive and 
powerful. Using NeuroRA, users can not only calculate the representational 
dissimilarity matrix (RDM), which reflects the representational similarity among 
different task conditions and conduct a representational analysis among 
different RDMs to achieve a cross-modal comparison. Besides, users can calculate 
neural pattern similarity (NPS), spatiotemporal pattern similarity (STPS), and 
inter-subject correlation (ISC) with this toolbox. NeuroRA also provides users 
with functions performing statistical analysis, storage, and visualization of 
results. We introduce the structure, modules, features, and algorithms of 
NeuroRA in this paper, as well as examples applying the toolbox in published 
datasets.

Copyright © 2020 Lu and Ku.

DOI: 10.3389/fninf.2020.563669
PMCID: PMC7787009
PMID: 33424573

Conflict of interest statement: The authors declare that the research was 
conducted in the absence of any commercial or financial relationships that could 
be construed as a potential conflict of interest.


80. Apert Neuro. 2021;1(4):10.52294/31bb5b68-2184-411b-8c00-a1dacb61e1da. doi: 
10.52294/31bb5b68-2184-411b-8c00-a1dacb61e1da. Epub 2022 Feb 16.

BrainIAK: The Brain Imaging Analysis Kit.

Kumar M(1), Anderson MJ(2), Antony JW(1), Baldassano C(3), Brooks PP(1), Cai 
MB(4), Chen PC(5), Ellis CT(6), Henselman-Petrusek G(1), Huberdeau D(6), 
Hutchinson JB(7), Li YP(7), Lu Q(8), Manning JR(9), Mennen AC(1), Nastase SA(1), 
Richard H(10), Schapiro AC(11), Schuck NW(12)(13), Shvartsman M(5), Sundaram 
N(2), Suo D(14), Turek JS(15), Turner D(1), Vo VA(15), Wallace G(1), Wang Y(2), 
Williams JA(1)(8), Zhang H(5), Zhu X(15), Capotă M(15), Cohen JD(1)(8), Hasson 
U(1)(8), Li K(14), Ramadge PJ(16), Turk-Browne NB(6), Willke TL(15), Norman 
KA(1)(8).

Author information:
(1)Princeton Neuroscience Institute, Princeton University, Princeton, NJ.
(2)Work done while at Parallel Computing Lab, Intel Corporation, Santa Clara, 
CA.
(3)Department of Psychology, Columbia University, NY, NY.
(4)International Research Center for Neurointelligence (WPI-IRCN), UTIAS, The 
University of Tokyo, Japan.
(5)Work done while at Princeton Neuroscience Institute, Princeton University, 
Princeton, NJ.
(6)Department of Psychology, Yale University, New Haven, CT.
(7)Department of Psychology, University of Oregon, Eugene, OR.
(8)Department of Psychology, Princeton University, Princeton, NJ.
(9)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH.
(10)Parietal Team, Inria, Neurospin, CEA, Université Paris-Saclay, France.
(11)Department of Psychology, University of Pennsylvania, Philadelphia, PA.
(12)Max Planck Research Group NeuroCode, Max Planck Institute for Human 
Development, Berlin, Germany.
(13)Max Planck UCL Centre for Computational Psychiatry and Ageing Research, 
Berlin, Germany.
(14)Department of Computer Science, Princeton University, Princeton, NJ.
(15)Brain-Inspired Computing Lab, Intel Corporation, Hillsboro, OR.
(16)Department of Electrical Engineering, and the Center for Statistics and 
Machine Learning, Princeton University, Princeton, NJ.

Functional magnetic resonance imaging (fMRI) offers a rich source of data for 
studying the neural basis of cognition. Here, we describe the Brain Imaging 
Analysis Kit (BrainIAK), an open-source, free Python package that provides 
computationally optimized solutions to key problems in advanced fMRI analysis. A 
variety of techniques are presently included in BrainIAK: intersubject 
correlation (ISC) and intersubject functional connectivity (ISFC), functional 
alignment via the shared response model (SRM), full correlation matrix analysis 
(FCMA), a Bayesian version of representational similarity analysis (BRSA), event 
segmentation using hidden Markov models, topographic factor analysis (TFA), 
inverted encoding models (IEMs), an fMRI data simulator that uses noise 
characteristics from real data (fmrisim), and some emerging methods. These 
techniques have been optimized to leverage the efficiencies of high-performance 
compute (HPC) clusters, and the same code can be se amlessly transferred from a 
laptop to a cluster. For each of the aforementioned techniques, we describe the 
data analysis problem that the technique is meant to solve and how it solves 
that problem; we also include an example Jupyter notebook for each technique and 
an annotated bibliography of papers that have used and/or described that 
technique. In addition to the sections describing various analysis techniques in 
BrainIAK, we have included sections describing the future applications of 
BrainIAK to real-time fMRI, tutorials that we have developed and shared online 
to facilitate learning the techniques in BrainIAK, computational innovations in 
BrainIAK, and how to contribute to BrainIAK. We hope that this manuscript helps 
readers to understand how BrainIAK might be useful in their research.

DOI: 10.52294/31bb5b68-2184-411b-8c00-a1dacb61e1da
PMCID: PMC9351935
PMID: 35939268


81. J Cogn Neurosci. 2021 Mar;33(3):445-462. doi: 10.1162/jocn_a_01654. Epub 2020 
Dec 7.

Tracking the Emergence of Location-based Spatial Representations in Human 
Scene-Selective Cortex.

Berens SC(1)(2), Joensen BH(1)(3)(4), Horner AJ(1)(5).

Author information:
(1)University of York.
(2)University of Sussex.
(3)UCL Institute of Cognitive Neuroscience.
(4)UCL Institute of Neurology.
(5)York Biomedical Research Institute.

Scene-selective regions of the human brain form allocentric representations of 
locations in our environment. These representations are independent of heading 
direction and allow us to know where we are regardless of our direction of 
travel. However, we know little about how these location-based representations 
are formed. Using fMRI representational similarity analysis and linear mixed 
models, we tracked the emergence of location-based representations in 
scene-selective brain regions. We estimated patterns of activity for two 
distinct scenes, taken before and after participants learnt they were from the 
same location. During a learning phase, we presented participants with two types 
of panoramic videos: (1) an overlap video condition displaying two distinct 
scenes (0° and 180°) from the same location and (2) a no-overlap video 
displaying two distinct scenes from different locations (which served as a 
control condition). In the parahippocampal cortex (PHC) and retrosplenial cortex 
(RSC), representations of scenes from the same location became more similar to 
each other only after they had been shown in the overlap condition, suggesting 
the emergence of viewpoint-independent location-based representations. Whereas 
these representations emerged in the PHC regardless of task performance, RSC 
representations only emerged for locations where participants could behaviorally 
identify the two scenes as belonging to the same location. The results suggest 
that we can track the emergence of location-based representations in the PHC and 
RSC in a single fMRI experiment. Further, they support computational models that 
propose the RSC plays a key role in transforming viewpoint-independent 
representations into behaviorally relevant representations of specific 
viewpoints.

DOI: 10.1162/jocn_a_01654
PMCID: PMC8658499
PMID: 33284080 [Indexed for MEDLINE]


82. Personal Neurosci. 2020 Nov 10;3:e12. doi: 10.1017/pen.2020.13. eCollection 
2020.

Mapping neural activity patterns to contextualized fearful facial expressions 
onto callous-unemotional (CU) traits: intersubject representational similarity 
analysis reveals less variation among high-CU adolescents.

Rhoads SA(1), Cardinale EM(1), O'Connell K(2), Palmer AL(3), VanMeter JW(4), 
Marsh AA(1).

Author information:
(1)Department of Psychology, Georgetown University, Washington DC 20057, USA.
(2)Interdisciplinary Program in Neuroscience, Georgetown University, Washington 
DC 20057, USA.
(3)Independent Scholar.
(4)Department of Neurology, Georgetown University Medical Center, Washington DC 
20057, USA.

Callous-unemotional (CU) traits are early-emerging personality features 
characterized by deficits in empathy, concern for others, and remorse following 
social transgressions. One of the interpersonal deficits most consistently 
associated with CU traits is impaired behavioral and neurophysiological 
responsiveness to fearful facial expressions. However, the facial expression 
paradigms traditionally employed in neuroimaging are often ambiguous with 
respect to the nature of threat (i.e., is the perceiver the threat, or is 
something else in the environment?). In the present study, 30 adolescents with 
varying CU traits viewed fearful facial expressions cued to three different 
contexts ("afraid for you," "afraid of you," "afraid for self") while undergoing 
functional magnetic resonance imaging (fMRI). Univariate analyses found that 
mean right amygdala activity during the "afraid for self" context was negatively 
associated with CU traits. With the goal of disentangling idiosyncratic 
stimulus-driven neural responses, we employed intersubject representational 
similarity analysis to link intersubject similarities in multivoxel neural 
response patterns to contextualized fearful expressions with differential 
intersubject models of CU traits. Among low-CU adolescents, neural response 
patterns while viewing fearful faces were most consistently similar early in the 
visual processing stream and among regions implicated in affective responding, 
but were more idiosyncratic as emotional face information moved up the cortical 
processing hierarchy. By contrast, high-CU adolescents' neural response patterns 
consistently aligned along the entire cortical hierarchy (but diverged among 
low-CU youths). Observed patterns varied across contexts, suggesting that 
interpretations of fearful expressions depend to an extent on neural response 
patterns and are further shaped by levels of CU traits.

© The Author(s) 2020.

DOI: 10.1017/pen.2020.13
PMCID: PMC7681174
PMID: 33283146

Conflict of interest statement: Authors have nothing to disclose.


83. J Neurosci. 2021 Feb 24;41(8):1699-1715. doi: 10.1523/JNEUROSCI.1237-20.2020. 
Epub 2020 Nov 6.

Right Temporoparietal Junction Underlies Avoidance of Moral Transgression in 
Autism Spectrum Disorder.

Hu Y(1)(2)(3), Pereira AM(4), Gao X(3), Campos BM(4), Derrington E(2)(5), 
Corgnet B(6), Zhou X(1)(3)(7), Cendes F(4), Dreher JC(8)(5).

Author information:
(1)Key Laboratory of Applied Brain and Cognitive Sciences, School of Business 
and Management, Shanghai International Studies University, Shanghai 201620, 
People's Republic of China.
(2)Institut des Sciences Cognitives Marc Jeannerod, CNRS, Neuroeconomics Lab 
69675 Bron, France.
(3)School of Psychological and Cognitive Sciences, Peking University, Beijing 
100871, People's Republic of China.
(4)Neuroimaging Laboratory, School of Medical Sciences, The Brazilian Institute 
of Neuroscience and Neurotechnology, University of Campinas (UNICAMP), Campinas 
13083-970, Brazil.
(5)Université Claude Bernard Lyon 1, 69100 Villeurbanne, France.
(6)EmLyon, 69130 Ecully, France.
(7)PKU-IDG/McGovern Institute for Brain Research, Peking University, Beijing 
100871, People's Republic of China.
(8)Institut des Sciences Cognitives Marc Jeannerod, CNRS, Neuroeconomics Lab 
69675 Bron, France dreher@isc.cnrs.fr.

Autism spectrum disorder (ASD) is characterized by a core difference in 
theory-of-mind (ToM) ability, which extends to alterations in moral judgment and 
decision-making. Although the function of the right temporoparietal junction 
(rTPJ), a key neural marker of ToM and morality, is known to be atypical in 
autistic individuals, the neurocomputational mechanisms underlying its specific 
changes in moral decision-making remain unclear. Here, we addressed this 
question by using a novel fMRI task together with computational modeling and 
representational similarity analysis (RSA). ASD participants and healthy control 
subjects (HCs) decided in public or private whether to incur a personal cost for 
funding a morally good cause (Good Context) or receive a personal gain for 
benefiting a morally bad cause (Bad Context). Compared with HC, individuals with 
ASD were much more likely to reject the opportunity to earn ill gotten money by 
supporting a bad cause than were HCs. Computational modeling revealed that this 
resulted from heavily weighing benefits for themselves and the bad cause, 
suggesting that ASD participants apply a rule of refusing to serve a bad cause 
because they evaluate the negative consequences of their actions more severely. 
Moreover, RSA revealed a reduced rTPJ representation of the information specific 
to moral contexts in ASD participants. Together, these findings indicate the 
contribution of rTPJ in representing information concerning moral rules and 
provide new insights for the neurobiological basis underpinning moral behaviors 
illustrated by a specific difference of rTPJ in ASD participants.SIGNIFICANCE 
STATEMENT Previous investigations have found an altered pattern of moral 
behaviors in individuals with autism spectrum disorder (ASD), which is closely 
associated with functional changes in the right temporoparietal junction (rTPJ). 
However, the specific neurocomputational mechanisms at play that drive the 
altered function of the rTPJ in moral decision-making remain unclear. Here, we 
show that ASD individuals are more inflexible when following a moral rule 
although an immoral action can benefit themselves, and experience an increased 
concern about their ill-gotten gains and the moral cost. Moreover, a selectively 
reduced rTPJ representation of information concerning moral rules was observed 
in ASD participants. These findings deepen our understanding of the 
neurobiological roots that underlie atypical moral behaviors in ASD individuals.

Copyright © 2021 the authors.

DOI: 10.1523/JNEUROSCI.1237-20.2020
PMCID: PMC8115877
PMID: 33158960 [Indexed for MEDLINE]


84. Cogn Neurosci. 2021 Jan;12(1):28-39. doi: 10.1080/17588928.2020.1839039. Epub 
2020 Nov 1.

Supracategorical fear information revealed by aversively conditioning multiple 
categories.

Levine SM(1)(2), Kumpf M(2), Rupprecht R(2), Schwarzbach JV(2).

Author information:
(1)Department of Cognitive and Clinical Neuroscience, Central Institute of 
Mental Health, Medical Faculty Mannheim, Heidelberg University , Mannheim, 
Germany.
(2)Department of Psychiatry and Psychotherapy, University of Regensburg , 
Regensburg, Germany.

Fear-generalization is a critical function for survival, in which an organism 
extracts information from a specific instantiation of a threat (e.g., the 
western diamondback rattlesnake in my front yard on Sunday) and learns to fear - 
and accordingly respond to - pertinent higher-order information (e.g., snakes 
live in my yard). Previous work investigating fear-conditioning in humans has 
used functional magnetic resonance imaging (fMRI) to demonstrate that activity 
patterns representing stimuli from an aversively-conditioned category (CS+) are 
more similar to each other than those of a neutral category (CS-). Here we used 
fMRI and multiple aversively-conditioned categories to ask whether we would find 
only similarity increases within the CS+ categories or also similarity increases 
between the CS+ categories. Using representational similarity analysis, we 
correlated several models to activity patterns underlying different brain 
regions and found that, following fear-conditioning, between-category and 
within-category similarity increased for the CS+ categories in the insula, 
superior frontal gyrus (SFG), and the right temporal pole. When specifically 
investigating fear-generalization, these between- and within-category effects 
were detected in the SFG. These results advance prior pattern-based neuroimaging 
work by exploring the effect of aversively-conditioning multiple categories and 
indicate an extended role for such regions in potentially representing 
supracategorical information during fear-learning.

DOI: 10.1080/17588928.2020.1839039
PMID: 33135598 [Indexed for MEDLINE]


85. Hum Brain Mapp. 2021 Mar;42(4):893-907. doi: 10.1002/hbm.25266. Epub 2020 Oct 
28.

Language distance in orthographic transparency affects cross-language pattern 
similarity between native and non-native languages.

Dong J(1)(2)(3)(4), Li A(1)(2)(3)(4), Chen C(5), Qu J(1)(2)(3)(4), Jiang 
N(1)(2)(3)(4), Sun Y(1)(2)(3)(4), Hu L(1)(2)(3)(4), Mei L(1)(2)(3)(4).

Author information:
(1)Key Laboratory of Brain, Cognition and Education Sciences (South China Normal 
University), Ministry of Education, Guangzhou, China.
(2)School of Psychology, South China Normal University, Guangzhou, China.
(3)Center for Studies of Psychological Application, South China Normal 
University, Guangzhou, China.
(4)Guangdong Key Laboratory of Mental Health and Cognitive Science, South China 
Normal University, Guangzhou, China.
(5)Department of Psychological Science, University of California, Irvine, 
California, USA.

How native and non-native languages are represented in the brain is one of the 
most important questions in neurolinguistics. Much research has found that the 
similarity in neural activity of native and non-native languages are influenced 
by factors such as age of acquisition, language proficiency, and language 
exposure in the non-native language. Nevertheless, it is still unclear how the 
similarity between native and non-native languages in orthographic transparency, 
a key factor that affects the cognitive and neural mechanisms of phonological 
access, modulates the cross-language similarity in neural activation and which 
brain regions show the modulatory effects of language distance in orthographic 
transparency. To address these questions, the present study used 
representational similarity analysis (RSA) to precisely estimate the neural 
pattern similarity between native language and two non-native languages in 
Uyghur-Chinese-English trilinguals, whose third language (i.e., English) was 
more similar to the native language (i.e., Uyghur) in orthography than to their 
second language (i.e., Chinese). Behavioral results revealed that subjects 
responded faster to words in the non-native language with more similar 
orthography to their native language in the word naming task. More importantly, 
RSA revealed greater neural pattern similarity between Uyghur and English than 
between Uyghur and Chinese in select brain areas for phonological processing, 
especially in the left hemisphere. Further analysis confirmed that those brain 
regions represented phonological information. These results provide direct 
neuroimaging evidence for the modulatory effect of language distance in 
orthographic transparency on cross-language pattern similarity between native 
and non-native languages during word reading.

© 2020 The Authors. Human Brain Mapping published by Wiley Periodicals LLC.

DOI: 10.1002/hbm.25266
PMCID: PMC7856648
PMID: 33112483 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


86. Neuroinformatics. 2021 Jul;19(3):417-431. doi: 10.1007/s12021-020-09494-4. Epub 
2020 Oct 15.

Deep Representational Similarity Learning for Analyzing Neural Signatures in 
Task-based fMRI Dataset.

Yousefnezhad M(1)(2), Sawalha J(2), Selvitella A(3), Zhang D(4).

Author information:
(1)College of Computer Science and Technology, Nanjing University of Aeronautics 
and Astronautics, Nanjing, 211106, China.
(2)Department of Computing Science and The Department of Psychiatry, University 
of Alberta, Edmonton, T6G 2R3, AB, Canada.
(3)Department of Mathematical Sciences, Purdue University Fort Wayne, 2101 E 
Coliseum Blvd, Fort Wayne, IN, 46805, USA.
(4)College of Computer Science and Technology, Nanjing University of Aeronautics 
and Astronautics, Nanjing, 211106, China. dqzhang@nuaa.edu.cn.

Similarity analysis is one of the crucial steps in most fMRI studies. 
Representational Similarity Analysis (RSA) can measure similarities of neural 
signatures generated by different cognitive states. This paper develops Deep 
Representational Similarity Learning (DRSL), a deep extension of RSA that is 
appropriate for analyzing similarities between various cognitive tasks in fMRI 
datasets with a large number of subjects, and high-dimensionality - such as 
whole-brain images. Unlike the previous methods, DRSL is not limited by a linear 
transformation or a restricted fixed nonlinear kernel function - such as 
Gaussian kernel. DRSL utilizes a multi-layer neural network for mapping neural 
responses to linear space, where this network can implement a customized 
nonlinear transformation for each subject separately. Furthermore, utilizing a 
gradient-based optimization in DRSL can significantly reduce runtime of analysis 
on large datasets because it uses a batch of samples in each iteration rather 
than all neural responses to find an optimal solution. Empirical studies on 
multi-subject fMRI datasets with various tasks - including visual stimuli, 
decision making, flavor, and working memory - confirm that the proposed method 
achieves superior performance to other state-of-the-art RSA algorithms.

DOI: 10.1007/s12021-020-09494-4
PMID: 33057876 [Indexed for MEDLINE]


87. Neuroimage. 2021 Jan 1;224:117408. doi: 10.1016/j.neuroimage.2020.117408. Epub 
2020 Oct 10.

Distinct fronto-temporal substrates of distributional and taxonomic similarity 
among words: evidence from RSA of BOLD signals.

Carota F(1), Nili H(2), Pulvermüller F(3), Kriegeskorte N(4).

Author information:
(1)Max-Planck-Institute for Psycholinguistics, Wundtlaan 1, Nijmegen, the 
Netherlands; Donders Centre for Cognitive NeuroImaging, Radboud University, 
Kapittelweg 29, 6525 EN Nijmegen, the Netherlands; MRC Cognition and Brain 
Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, United Kingdom; Berlin School 
of Mind and Brain, Humboldt Universität zu Berlin, Berlin, Germany; Brain 
Language Laboratory, Department of Philosophy and Humanities, WE4, Freie 
Universität Berlin, Berlin, Germany. Electronic address: 
francesca.carota@mpi.nl.
(2)MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, 
United Kingdom; Department of Experimental Psychology, University of Oxford, 
Tinbergen Building, 9 South Parks Road, Oxford OX1 3UD, United Kingdom.
(3)MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, 
United Kingdom; Berlin School of Mind and Brain, Humboldt Universität zu Berlin, 
Berlin, Germany; Brain Language Laboratory, Department of Philosophy and 
Humanities, WE4, Freie Universität Berlin, Berlin, Germany.
(4)MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, 
United Kingdom; Cognitive Imaging at the Zuckerman Mind Brain Behavior 
Institute, Columbia University, Jerome L. Greene Science Center, 3227 Broadway, 
L3-064, 9834 New York, NY 10027, United States.

A class of semantic theories defines concepts in terms of statistical 
distributions of lexical items, basing meaning on vectors of word co-occurrence 
frequencies. A different approach emphasizes abstract hierarchical taxonomic 
relationships among concepts. However, the functional relevance of these 
different accounts and how they capture information-encoding of lexical meaning 
in the brain still remains elusive. We investigated to what extent 
distributional and taxonomic models explained word-elicited neural responses 
using cross-validated representational similarity analysis (RSA) of functional 
magnetic resonance imaging (fMRI) and model comparisons. Our findings show that 
the brain encodes both types of semantic information, but in distinct cortical 
regions. Posterior middle temporal regions reflected lexical-semantic similarity 
based on hierarchical taxonomies, in coherence with the action-relatedness of 
specific semantic word categories. In contrast, distributional semantics best 
predicted the representational patterns in left inferior frontal gyrus (LIFG, BA 
47). Both representations coexisted in the angular gyrus supporting semantic 
binding and integration. These results reveal that neuronal networks with 
distinct cortical distributions across higher-order association cortex encode 
different representational properties of word meanings. Taxonomy may shape 
long-term lexical-semantic representations in memory consistently with the 
sensorimotor details of semantic categories, whilst distributional knowledge in 
the LIFG (BA 47) may enable semantic combinatorics in the context of language 
use. Our approach helps to elucidate the nature of semantic representations 
essential for understanding human language.

Copyright © 2020. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2020.117408
PMID: 33049407 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest None declared.


88. J Neurosci. 2020 Oct 21;40(43):8396-8408. doi: 10.1523/JNEUROSCI.2800-19.2020. 
Epub 2020 Oct 5.

Comparative Brain Imaging Reveals Analogous and Divergent Patterns of Species 
and Face Sensitivity in Humans and Dogs.

Bunford N(1)(2), Hernández-Pérez R(3)(4)(5), Farkas EB(3)(4), Cuaya LV(3)(4)(5), 
Szabó D(3), Szabó ÁG(6), Gácsi M(3)(7), Miklósi Á(3)(7), Andics A(1)(4)(7).

Author information:
(1)Department of Ethology, Institute of Biology, Eötvös Loránd University, 
Budapest 1117, Hungary attila.andics@ttk.elte.hu bunford.nora@ttk.hu.
(2)Lendület Developmental and Translational Neuroscience Research Group, 
Institute of Cognitive Neuroscience and Psychology, Research Centre for Natural 
Sciences, Budapest 1117, Hungary.
(3)Department of Ethology, Institute of Biology, Eötvös Loránd University, 
Budapest 1117, Hungary.
(4)MTA-ELTE Lendület Neuroethology of Communication Research Group, Eötvös 
Loránd University, Budapest 1117, Hungary.
(5)Instituto de Neurobiología, Universidad Nacional Autónoma de México, Santiago 
de Querétaro 3001, Mexico.
(6)Department of Neuroradiology, Medical Imaging Centre, Semmelweis University, 
Budapest 1083, Hungary.
(7)MTA-ELTE Comparative Ethology Research Group, Budapest 1117, Hungary.

Conspecific-preference in social perception is evident for multiple sensory 
modalities and in many species. There is also a dedicated neural network for 
face processing in primates. However, the evolutionary origin and the relative 
role of neural species sensitivity and face sensitivity in visuo-social 
processing are largely unknown. In this comparative study, species sensitivity 
and face sensitivity to identical visual stimuli (videos of human and dog faces 
and occiputs) were examined using functional magnetic resonance imaging in dogs 
(n = 20; 45% female) and humans (n = 30; 50% female). In dogs, the bilateral mid 
suprasylvian gyrus showed conspecific-preference, no regions exhibited 
face-preference, and the majority of the visually-responsive cortex showed 
greater conspecific-preference than face-preference. In humans, 
conspecific-preferring regions (the right amygdala/hippocampus and the posterior 
superior temporal sulcus) also showed face-preference, and much of the 
visually-responsive cortex showed greater face-preference than 
conspecific-preference. Multivariate pattern analyses (MVPAs) identified 
species-sensitive regions in both species, but face-sensitive regions only in 
humans. Across-species representational similarity analyses (RSAs) revealed 
stronger correspondence between dog and human response patterns for 
distinguishing conspecific from heterospecific faces than other contrasts. 
Results unveil functional analogies in dog and human visuo-social processing of 
conspecificity but suggest that cortical specialization for face perception may 
not be ubiquitous across mammals.SIGNIFICANCE STATEMENT To explore the 
evolutionary origins of human face-preference and its relationship to 
conspecific-preference, we conducted the first comparative and noninvasive 
visual neuroimaging study of a non-primate and a primate species, dogs and 
humans. Conspecific-preferring brain regions were observed in both species, but 
face-preferring brain regions were observed only in humans. In dogs, an 
overwhelming majority of visually-responsive cortex exhibited greater 
conspecific-preference than face-preference, whereas in humans, much of the 
visually-responsive cortex showed greater face-preference than 
conspecific-preference. Together, these findings unveil functional analogies and 
differences in the organizing principles of visuo-social processing across two 
phylogenetically distant mammal species.

Copyright © 2020 Bunford, Hernández-Pérez et al.

DOI: 10.1523/JNEUROSCI.2800-19.2020
PMCID: PMC7577605
PMID: 33020215 [Indexed for MEDLINE]


89. Cereb Cortex. 2021 Jan 5;31(2):974-992. doi: 10.1093/cercor/bhaa269.

Visual and Semantic Representations Predict Subsequent Memory in Perceptual and 
Conceptual Memory Tests.

Davis SW(1)(2), Geib BR(1), Wing EA(1), Wang WC(1), Hovhannisyan M(2), Monge 
ZA(1), Cabeza R(1).

Author information:
(1)Center for Cognitive Neuroscience, Duke University, Durham, NC 27708, USA.
(2)Department of Neurology, Duke University School of Medicine, Durham, NC 
27708, USA.

It is generally assumed that the encoding of a single event generates multiple 
memory representations, which contribute differently to subsequent episodic 
memory. We used functional magnetic resonance imaging (fMRI) and 
representational similarity analysis to examine how visual and semantic 
representations predicted subsequent memory for single item encoding (e.g., 
seeing an orange). Three levels of visual representations corresponding to 
early, middle, and late visual processing stages were based on a deep neural 
network. Three levels of semantic representations were based on normative 
observed ("is round"), taxonomic ("is a fruit"), and encyclopedic features ("is 
sweet"). We identified brain regions where each representation type predicted 
later perceptual memory, conceptual memory, or both (general memory). 
Participants encoded objects during fMRI, and then completed both a word-based 
conceptual and picture-based perceptual memory test. Visual representations 
predicted subsequent perceptual memory in visual cortices, but also facilitated 
conceptual and general memory in more anterior regions. Semantic 
representations, in turn, predicted perceptual memory in visual cortex, 
conceptual memory in the perirhinal and inferior prefrontal cortex, and general 
memory in the angular gyrus. These results suggest that the contribution of 
visual and semantic representations to subsequent memory effects depends on a 
complex interaction between representation, test type, and storage location.

© The Author(s) 2020. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhaa269
PMCID: PMC8485078
PMID: 32935833 [Indexed for MEDLINE]


90. J Neurosci. 2020 Sep 30;40(40):7724-7738. doi: 10.1523/JNEUROSCI.0594-20.2020. 
Epub 2020 Aug 31.

Hierarchical Representation of Multistep Tasks in Multiple-Demand and Default 
Mode Networks.

Wen T(1), Duncan J(2)(3), Mitchell DJ(2).

Author information:
(1)Medical Research Council, Cognition and Brain Sciences Unit, University of 
Cambridge, Cambridge CB2 7EF, United Kingdom tanya.wen@duke.edu.
(2)Medical Research Council, Cognition and Brain Sciences Unit, University of 
Cambridge, Cambridge CB2 7EF, United Kingdom.
(3)Department of Experimental Psychology, University of Oxford, Radcliffe 
Observatory, Oxford OX2 6GG, United Kingdom.

Task episodes consist of sequences of steps that are performed to achieve a 
goal. We used fMRI to examine neural representation of task identity, component 
items, and sequential position, focusing on two major cortical systems-the 
multiple-demand (MD) and default mode networks (DMN). Human participants (20 
males, 22 females) learned six tasks each consisting of four steps. Inside the 
scanner, participants were cued which task to perform and then sequentially 
identified the target item of each step in the correct order. Univariate time 
course analyses indicated that intra-episode progress was tracked by a tonically 
increasing global response, plus an increasing phasic step response specific to 
MD regions. Inter-episode boundaries evoked a widespread response at episode 
onset, plus a marked offset response specific to DMN regions. Representational 
similarity analysis (RSA) was used to examine representation of task identity 
and component steps. Both networks represented the content and position of 
individual steps, however the DMN preferentially represented task identity while 
the MD network preferentially represented step-level information. Thus, although 
both MD and DMN networks are sensitive to step-level and episode-level 
information in the context of hierarchical task performance, they exhibit 
dissociable profiles in terms of both temporal dynamics and representational 
content. The results suggest collaboration of multiple brain regions in control 
of multistep behavior, with MD regions particularly involved in processing the 
detail of individual steps, and DMN adding representation of broad task 
context.SIGNIFICANCE STATEMENT Achieving one's goals requires knowing what to do 
and when. Tasks are typically hierarchical, with smaller steps nested within 
overarching goals. For effective, flexible behavior, the brain must represent 
both levels. We contrast response time courses and information content of two 
major cortical systems-the multiple-demand (MD) and default mode networks 
(DMN)-during multistep task episodes. Both networks are sensitive to step-level 
and episode-level information, but with dissociable profiles. Intra-episode 
progress is tracked by tonically increasing global responses, plus MD-specific 
increasing phasic step responses. Inter-episode boundaries evoke widespread 
responses at episode onset, plus DMN-specific offset responses. Both networks 
represent content and position of individual steps; however, the DMN and MD 
networks favor task identity and step-level information, respectively.

Copyright © 2020 Wen et al.

DOI: 10.1523/JNEUROSCI.0594-20.2020
PMCID: PMC7531550
PMID: 32868460 [Indexed for MEDLINE]


91. J Neurophysiol. 2020 Sep 1;124(3):728-739. doi: 10.1152/jn.00546.2019. Epub 2020 
Jul 29.

Primary motor cortical activity during unimanual movements with increasing 
demand on precision.

Barany DA(1), Revill KP(2), Caliban A(1), Vernon I(1), Shukla A(1), Sathian 
K(3)(4), Buetefisch CM(1)(5)(6).

Author information:
(1)Department of Neurology, Emory University, Atlanta, Georgia.
(2)Department of Psychology, Emory University, Atlanta, Georgia.
(3)Departments of Neurology and Neural & Behavioral Sciences, Milton S. Hershey 
Medical Center and Penn State College of Medicine, Hershey, Pennsylvania.
(4)Department of Psychology, College of Liberal Arts, The Pennsylvania State 
University, University Park, Pennsylvania.
(5)Department of Rehabilitation Medicine, Emory University, Atlanta, Georgia.
(6)Department of Radiology, Emory University, Atlanta, Georgia.

In functional magnetic resonance imaging (fMRI) studies, performance of 
unilateral hand movements is associated with primary motor cortex activity 
ipsilateral to the moving hand (M1ipsi), in addition to contralateral activity 
(M1contra). The magnitude of M1ipsi activity increases with the demand on 
precision of the task. However, it is unclear how demand-dependent increases in 
M1ipsi recruitment relate to the control of hand movements. To address this 
question, we used fMRI to measure blood oxygenation level-dependent (BOLD) 
activity during performance of a task that varied in demand on precision. 
Participants (n = 23) manipulated an MRI-compatible joystick with their right or 
left hand to move a cursor into targets of different sizes (small, medium, 
large, extra large). Performance accuracy, movement time, and number of velocity 
peaks scaled with target size, whereas reaction time, maximum velocity, and 
initial direction error did not. In the univariate analysis, BOLD activation in 
M1contra and M1ipsi was higher for movements to smaller targets. 
Representational similarity analysis, corrected for mean activity differences, 
revealed multivoxel BOLD activity patterns during movements to small targets 
were most similar to those for medium targets and least similar to those for 
extra-large targets. Only models that varied with demand (target size, 
performance accuracy, and number of velocity peaks) correlated with the BOLD 
dissimilarity patterns, though differently for right and left hands. Across 
individuals, M1contra and M1ipsi similarity patterns correlated with each other. 
Together, these results suggest that increasing demand on precision in a 
unimanual motor task increases M1 activity and modulates M1 activity 
patterns.NEW & NOTEWORTHY Contralateral primary motor cortex (M1) predominantly 
controls unilateral hand movements, but the role of ipsilateral M1 is unclear. 
We used functional magnetic resonance imaging (fMRI) to investigate how M1 
activity is modulated by unimanual movements at different levels of demand on 
precision. Our results show that task characteristics related to demand on 
precision influence bilateral M1 activity, suggesting that in addition to 
contralateral M1, ipsilateral M1 plays a key role in controlling hand movements 
to meet performance precision requirements.

DOI: 10.1152/jn.00546.2019
PMCID: PMC7509291
PMID: 32727264 [Indexed for MEDLINE]

Conflict of interest statement: No conflicts of interest, financial or 
otherwise, are declared by the authors.


92. Cogn Neurosci. 2020 Jul-Oct;11(4):194-204. doi: 10.1080/17588928.2020.1792868. 
Epub 2020 Jul 28.

The dynamic and task-dependent representational transformation between the motor 
and sensory systems during speech production.

Zhang W(1)(2)(3), Liu Y(4), Wang X(5), Tian X(1)(2)(3).

Author information:
(1)Division of Arts and Sciences, New York University Shanghai , Shanghai, 
China.
(2)Shanghai Key Laboratory of Brain Functional Genomics (Ministry of Education), 
School of Psychology and Cognitive Science, East China Normal University , 
Shanghai, China.
(3)NYU-ECNU Institute of Brain and Cognitive Science, New York University 
Shanghai , Shanghai, China.
(4)Department of Educational Sciences, Tianjin Normal University , Tianjin, 
China.
(5)Department of Computer Science, Fudan University , Shanghai, China.

The motor and sensory systems work collaboratively to fulfill cognitive tasks, 
such as speech. For example, it has been hypothesized that neural signals 
generated in the motor system can transfer directly to the sensory system along 
a neural pathway (termed as motor-to-sensory transformation). Previous studies 
have demonstrated that the motor-to-sensory transformation is crucial for speech 
production. However, it is still unclear how neural representation dynamically 
evolves among distinct neural systems and how such representational 
transformation depends on task demand and the degrees of motor involvement. 
Using three speech tasks - overt articulation, silent articulation, and imagined 
articulation, the present fMRI study systematically investigated the 
representational formats and their dynamics in the motor-to-sensory 
transformation. Frontal-parietal-temporal neural pathways were observed in all 
three speech tasks in univariate analyses. The extent of the motor-to-sensory 
transformation network differed when the degrees of motor engagement varied 
among tasks. The representational similarity analysis (RSA) revealed that 
articulatory and acoustic information was represented in motor and auditory 
regions, respectively, in all three tasks. Moreover, articulatory information 
was cross-represented in the somatosensory and auditory regions in overt and 
silent articulation tasks. These results provided evidence for the dynamics and 
task-dependent transformation between representational formats in the 
motor-to-sensory transformation.

DOI: 10.1080/17588928.2020.1792868
PMID: 32720845 [Indexed for MEDLINE]


93. Proc Natl Acad Sci U S A. 2020 Jul 14;117(28):16678-16689. doi: 
10.1073/pnas.2004258117. Epub 2020 Jun 29.

Proximal threats promote enhanced acquisition and persistence of reactive 
fear-learning circuits.

Faul L(1), Stjepanović D(1)(2), Stivers JM(1), Stewart GW(1), Graner JL(1), 
Morey RA(3), LaBar KS(4)(3).

Author information:
(1)Department of Psychology & Neuroscience, Duke University, Durham, NC 27708.
(2)Centre for Youth Substance Abuse Research, The University of Queensland, St 
Lucia, QLD 4072, Australia.
(3)Department of Psychiatry and Behavioral Sciences, Duke University Medical 
Center, Durham, NC 27710.
(4)Department of Psychology & Neuroscience, Duke University, Durham, NC 27708; 
klabar@duke.edu.

Physical proximity to a traumatic event increases the severity of accompanying 
stress symptoms, an effect that is reminiscent of evolutionarily configured fear 
responses based on threat imminence. Despite being widely adopted as a model 
system for stress and anxiety disorders, fear-conditioning research has not yet 
characterized how threat proximity impacts the mechanisms of fear acquisition 
and extinction in the human brain. We used three-dimensional (3D) virtual 
reality technology to manipulate the egocentric distance of conspecific threats 
while healthy adult participants navigated virtual worlds during functional 
magnetic resonance imaging (fMRI). Consistent with theoretical predictions, 
proximal threats enhanced fear acquisition by shifting conditioned learning from 
cognitive to reactive fear circuits in the brain and reducing amygdala-cortical 
connectivity during both fear acquisition and extinction. With an analysis of 
representational pattern similarity between the acquisition and extinction 
phases, we further demonstrate that proximal threats impaired extinction 
efficacy via persistent multivariate representations of conditioned learning in 
the cerebellum, which predicted susceptibility to later fear reinstatement. 
These results show that conditioned threats encountered in close proximity are 
more resistant to extinction learning and suggest that the canonical neural 
circuitry typically associated with fear learning requires additional 
consideration of a more reactive neural fear system to fully account for this 
effect.

DOI: 10.1073/pnas.2004258117
PMCID: PMC7369317
PMID: 32601212 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interest.


94. Sci Rep. 2020 Jun 2;10(1):8931. doi: 10.1038/s41598-020-65906-0.

General and feature-based semantic representations in the semantic network.

Liuzzi AG(1), Aglinskas A(2), Fairhall SL(3).

Author information:
(1)Center for Mind/Brain Sciences, University of Trento, Trento, 38068, Italy. 
antonietta.liuzzi@unitn.it.
(2)Department of Psychology, Boston College, Boston, 02467, USA.
(3)Center for Mind/Brain Sciences, University of Trento, Trento, 38068, Italy.

How semantic representations are manifest over the brain remains a topic of 
active debate. A semantic representation may be determined by specific semantic 
features (e.g. sensorimotor information), or may abstract away from specific 
features and represent generalized semantic characteristics (general semantic 
representation). Here we tested whether nodes of the semantic system code for a 
general semantic representation and/or possess representational spaces linked to 
particular semantic features. In an fMRI study, eighteen participants performed 
a typicality judgment task with written words ﻿drawn from sixteen different 
categories. Multivariate pattern analysis (MVPA) and representational similarity 
analysis (RSA) were adopted to investigate the sensitivity of the brain regions 
to semantic content and the type of semantic representation coded (general or 
feature-based). We replicated previous findings of sensitivity to general 
semantic similarity in posterior middle/inferior temporal gyrus (pMTG/ITG) and 
precuneus (PC) and additionally observed general semantic representations in 
ventromedial prefrontal cortex (PFC). Finally, two brain regions of the semantic 
network were sensitive to semantic features: the left pMTG/ITG was sensitive to 
haptic perception and the left ventral temporal cortex (VTC) to size. This 
finding supports the involvement of both general semantic representation and 
feature-based representations in the brain's semantic system.

DOI: 10.1038/s41598-020-65906-0
PMCID: PMC7265368
PMID: 32488152

Conflict of interest statement: The authors declare no competing interests.


95. Neuroimage. 2020 Aug 15;217:116909. doi: 10.1016/j.neuroimage.2020.116909. Epub 
2020 May 6.

Individual-specific and shared representations during episodic memory encoding 
and retrieval.

Xiao X(1), Zhou Y(2), Liu J(2), Ye Z(2), Yao L(3), Zhang J(3), Chen C(4), Xue 
G(5).

Author information:
(1)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute of Brain Research, Beijing Normal University, Beijing, 100875, PR 
China; School of Informatics, Beijing Normal University, Beijing, 100875, PR 
China.
(2)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute of Brain Research, Beijing Normal University, Beijing, 100875, PR 
China.
(3)School of Informatics, Beijing Normal University, Beijing, 100875, PR China.
(4)Department of Psychological Science, University of California, Irvine, 92697, 
USA.
(5)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute of Brain Research, Beijing Normal University, Beijing, 100875, PR 
China. Electronic address: gxue@bnu.edu.cn.

Although human memories seem unique to each individual, they are shared to a 
great extent across individuals. Previous studies have examined, separately, 
subject-specific and cross-subject shared representations during memory encoding 
and retrieval, but how shared memories are formed from individually encoded 
representations is not clearly understood. Using a unique fMRI design involving 
memory encoding and retrieval, and representational similarity analysis to link 
representations from different individuals, brain regions, and processing 
stages, the current study revealed that distributed brain regions showed both 
subject-specific and shared neural representations during both memory encoding 
and retrieval. Furthermore, different brain regions showed stage-specific 
representational strength, with the visual cortex showing greater unique and 
shared representations during encoding, whereas the left angular gyrus showing 
greater unique and shared representations during retrieval. The neural 
representations during encoding were transformed during retrieval, as shown by 
smaller cross-subject encoding-retrieval similarity (ERS) than cross-subject 
similarity either during encoding or during retrieval. This cross-subject and 
cross-stage similarity was found both within and across regions, with strong 
pattern similarity between the encoded representation in VVC and the retrieved 
representation in the angular gyrus. Simulation analysis further suggested that 
these patterns could be achieved by incorporating stage-specific 
representational strength, and cross-region reinstatement from encoding to 
retrieval, but not by a common transformation from encoding to retrieval across 
subjects. Together, our results shed light on how memory representations are 
encoded and transformed to maintain individual characteristics and at the same 
time to create shared representations to facilitate interpersonal communication.

Copyright © 2020 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2020.116909
PMID: 32387627 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of copeting interest The authors 
declare no conflict of interest.


96. Neuroimage. 2020 Aug 15;217:116892. doi: 10.1016/j.neuroimage.2020.116892. Epub 
2020 May 1.

Representation of associative and affective semantic similarity of abstract 
words in the lateral temporal perisylvian language regions.

Meersmans K(1), Bruffaerts R(2), Jamoulle T(1), Liuzzi AG(3), De Deyne S(4), 
Storms G(5), Dupont P(1), Vandenberghe R(6).

Author information:
(1)Laboratory for Cognitive Neurology, Department of Neurosciences, KU Leuven, 
Belgium.
(2)Laboratory for Cognitive Neurology, Department of Neurosciences, KU Leuven, 
Belgium; Neurology Department, University Hospitals Leuven, Leuven, Belgium.
(3)Centre for Mind/Brain Sciences, Trento, Italy.
(4)Computational Cognitive Science Lab, University of Melbourne, Australia.
(5)Laboratory of Experimental Psychology, KU Leuven, Belgium.
(6)Laboratory for Cognitive Neurology, Department of Neurosciences, KU Leuven, 
Belgium; Neurology Department, University Hospitals Leuven, Leuven, Belgium. 
Electronic address: rik.vandenberghe@uzleuven.be.

The examination of semantic cognition has traditionally identified word 
concreteness as well as valence as two of the principal dimensions in the 
representation of conceptual knowledge. More recently, corpus-based vector space 
models as well as graph-theoretical analysis of large-scale task-related 
behavioural responses have revolutionized our insight into how the meaning of 
words is structured. In this fMRI study, we apply representational similarity 
analysis to investigate the conceptual representation of abstract words. Brain 
activity patterns were related to a cued-association based graph as well as to a 
vector-based co-occurrence model of word meaning. Twenty-six subjects (19 
females and 7 males) performed an overt repetition task during fMRI. First, we 
performed a searchlight classification procedure to identify regions where 
activity is discriminable between abstract and concrete words. These regions 
were left inferior frontal gyrus, the upper and lower bank of the superior 
temporal sulcus bilaterally, posterior middle temporal gyrus and left fusiform 
gyrus. Representational Similarity Analysis demonstrated that for abstract 
words, the similarity of activity patterns in the cortex surrounding the 
superior temporal sulcus bilaterally and in the left anterior superior temporal 
gyrus reflects the similarity in word meaning. These effects were strongest for 
semantic similarity derived from the cued association-based graph and for 
affective similarity derived from either of the two models. The latter effect 
was mainly driven by positive valence words. This research highlights the close 
neurobiological link between the information structure of abstract and affective 
word content and the similarity in activity pattern in the lateral and anterior 
temporal language system.

Copyright © 2020 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2020.116892
PMID: 32371118 [Indexed for MEDLINE]


97. Soc Cogn Affect Neurosci. 2020 Jun 23;15(4):487-509. doi: 10.1093/scan/nsaa057.

Tools of the Trade Multivoxel pattern analysis in fMRI: a practical introduction 
for social and affective neuroscientists.

Weaverdyck ME(1), Lieberman MD(1), Parkinson C(1)(2).

Author information:
(1)Department of Psychology, University of California, Los Angeles, CA 90095, 
USA.
(2)Brain Research Institute, University of California, Los Angeles, CA 90095, 
USA.

The family of neuroimaging analytical techniques known as multivoxel pattern 
analysis (MVPA) has dramatically increased in popularity over the past decade, 
particularly in social and affective neuroscience research using functional 
magnetic resonance imaging (fMRI). MVPA examines patterns of neural responses, 
rather than analyzing single voxel- or region-based values, as is customary in 
conventional univariate analyses. Here, we provide a practical introduction to 
MVPA and its most popular variants (namely, representational similarity analysis 
(RSA) and decoding analyses, such as classification using machine learning) for 
social and affective neuroscientists of all levels, particularly those new to 
such methods. We discuss how MVPA differs from traditional mass-univariate 
analyses, the benefits MVPA offers to social neuroscientists, experimental 
design and analysis considerations, step-by-step instructions for how to 
implement specific analyses in one's own dataset and issues that are currently 
facing research using MVPA methods.

© The Author(s) 2020. Published by Oxford University Press.

DOI: 10.1093/scan/nsaa057
PMCID: PMC7308652
PMID: 32364607 [Indexed for MEDLINE]


98. Neuroimage. 2020 Aug 1;216:116851. doi: 10.1016/j.neuroimage.2020.116851. Epub 
2020 Apr 12.

Intersubject representational similarity analysis reveals individual variations 
in affective experience when watching erotic movies.

Chen PA(1), Jolly E(2), Cheong JH(2), Chang LJ(3).

Author information:
(1)Department of Psychology, National Taiwan University, Taipei, Taiwan.
(2)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH, 03755, USA.
(3)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH, 03755, USA. Electronic address: luke.j.chang@dartmouth.edu.

We spend much of our lives pursuing or avoiding affective experiences. However, 
surprisingly little is known about how these experiences are represented in the 
brain and if they are shared across individuals. Here, we explored variations in 
the construction of an affective experience during a naturalistic viewing 
paradigm based on subjective preferences in sociosexual desire and self-control 
using intersubject representational similarity analysis (IS-RSA). We found that 
when watching erotic movies, intersubject variations in sociosexual desire 
preferences of 26 heterosexual males were associated with similarly structured 
fluctuations in the cortico-striatal reward, default mode, and mentalizing 
networks. In contrast, variations in the self-control preferences were 
associated with shared dynamics in the fronto-parietal executive control and 
cingulo-insular salience networks. Importantly, these results were specific to 
the affective experience, as we did not observe any relationship with variation 
in preferences when individuals watched neutral movies. Moreover, these results 
appear to require multivariate representations of preferences as we did not 
observe any significant associations using single scalar summary scores. Our 
findings indicate that multidimensional variations in individual preferences can 
be used to uncover unique dimensions of an affective experience, and that IS-RSA 
can provide new insights into the neural processes underlying psychological 
experiences elicited through naturalistic experimental designs.

Copyright © 2020. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2020.116851
PMCID: PMC7955800
PMID: 32294538 [Indexed for MEDLINE]


99. Neuroimage. 2020 Jul 15;215:116837. doi: 10.1016/j.neuroimage.2020.116837. Epub 
2020 Apr 11.

Auditory and tactile frequency representations are co-embedded in 
modality-defined cortical sensory systems.

Rahman MS(1), Barnes KA(2), Crommett LE(1), Tommerdahl M(3), Yau JM(4).

Author information:
(1)Department of Neuroscience, Baylor College of Medicine, Houston, One Baylor 
Plaza, Houston, TX, 77030, USA.
(2)Department of Neuroscience, Baylor College of Medicine, Houston, One Baylor 
Plaza, Houston, TX, 77030, USA; Department of Behavioral and Social Sciences, 
San Jacinto College - South, Houston, 13735 Beamer Rd, S13.269, Houston, TX, 
77089, USA.
(3)Department of Biomedical Engineering, University of North Carolina at Chapel 
Hill, CB No. 7575, Chapel Hill, NC, 27599, USA.
(4)Department of Neuroscience, Baylor College of Medicine, Houston, One Baylor 
Plaza, Houston, TX, 77030, USA. Electronic address: jeffrey.yau@bcm.edu.

Sensory information is represented and elaborated in hierarchical cortical 
systems that are thought to be dedicated to individual sensory modalities. This 
traditional view of sensory cortex organization has been challenged by recent 
evidence of multimodal responses in primary and association sensory areas. 
Although it is indisputable that sensory areas respond to multiple modalities, 
it remains unclear whether these multimodal responses reflect selective 
information processing for particular stimulus features. Here, we used fMRI 
adaptation to identify brain regions that are sensitive to the temporal 
frequency information contained in auditory, tactile, and audiotactile stimulus 
sequences. A number of brain regions distributed over the parietal and temporal 
lobes exhibited frequency-selective temporal response modulation for both 
auditory and tactile stimulus events, as indexed by repetition suppression 
effects. A smaller set of regions responded to crossmodal adaptation sequences 
in a frequency-dependent manner. Despite an extensive overlap of multimodal 
frequency-selective responses across the parietal and temporal lobes, 
representational similarity analysis revealed a cortical "regional landscape" 
that clearly reflected distinct somatosensory and auditory processing systems 
that converged on modality-invariant areas. These structured relationships 
between brain regions were also evident in spontaneous signal fluctuation 
patterns measured at rest. Our results reveal that multimodal processing in 
human cortex can be feature-specific and that multimodal frequency 
representations are embedded in the intrinsically hierarchical organization of 
cortical sensory systems.

Copyright © 2020 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2020.116837
PMCID: PMC7292761
PMID: 32289461 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest MT discloses 
that he is a cofounder of Cortical Metrics, which built and provided the tactile 
stimulator used in these experiments, and he receives royalties through this. 
The remaining authors declare no competing financial interests.


100. Neuroimage. 2020 Jul 15;215:116780. doi: 10.1016/j.neuroimage.2020.116780. Epub 
2020 Apr 8.

fMRI representational similarity analysis reveals graded preferences for 
chromatic and achromatic stimulus contrast across human visual cortex.

Goddard E(1), Mullen KT(2).

Author information:
(1)McGill Vision Research, Department of Ophthalmology & Visual Sciences, McGill 
University, Montreal, QC, H3G1A4, Canada.
(2)McGill Vision Research, Department of Ophthalmology & Visual Sciences, McGill 
University, Montreal, QC, H3G1A4, Canada. Electronic address: 
kathy.mullen@mcgill.ca.

Human visual cortex is partitioned into different functional areas that, from 
lower to higher, become increasingly selective and responsive to complex feature 
dimensions. Here we use a Representational Similarity Analysis (RSA) of 
fMRI-BOLD signals to make quantitative comparisons across LGN and multiple 
visual areas of the low-level stimulus information encoded in the patterns of 
voxel responses. Our stimulus set was picked to target the four functionally 
distinct subcortical channels that input visual cortex from the LGN: two 
achromatic sinewave stimuli that favor the responses of the high-temporal 
magnocellular and high-spatial parvocellular pathways, respectively, and two 
chromatic stimuli isolating the L/M-cone opponent and S-cone opponent pathways, 
respectively. Each stimulus type had three spatial extents to sample both foveal 
and para-central visual field. With the RSA, we compare quantitatively the 
response specializations for individual stimuli and combinations of stimuli in 
each area and how these change across visual cortex. First, our results 
replicate the known response preferences for motion/flicker in the dorsal visual 
areas. In addition, we identify two distinct gradients along the ventral visual 
stream. In the early visual areas (V1-V3), the strongest differential 
representation is for the achromatic high spatial frequency stimuli, suitable 
for form vision, and a very weak differentiation of chromatic versus achromatic 
contrast. Emerging in ventral occipital areas (V4, VO1 and VO2), however, is an 
increasingly strong separation of the responses to chromatic versus achromatic 
contrast and a decline in the high spatial frequency representation. These 
gradients provide new insight into how visual information is transformed across 
the visual cortex.

Copyright © 2020. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2020.116780
PMID: 32276074 [Indexed for MEDLINE]


101. Neuroimage. 2020 Jul 15;215:116828. doi: 10.1016/j.neuroimage.2020.116828. Epub 
2020 Apr 7.

Idiosynchrony: From shared responses to individual differences during 
naturalistic neuroimaging.

Finn ES(1), Glerean E(2), Khojandi AY(3), Nielson D(4), Molfese PJ(3), 
Handwerker DA(3), Bandettini PA(3).

Author information:
(1)Section on Functional Imaging Methods, Laboratory of Brain and Cognition, 
National Institute of Mental Health, Bethesda, MD, USA. Electronic address: 
emily.finn@nih.gov.
(2)Department of Neuroscience and Biomedical Engineering, Aalto University, 
Espoo, Finland.
(3)Section on Functional Imaging Methods, Laboratory of Brain and Cognition, 
National Institute of Mental Health, Bethesda, MD, USA.
(4)Mood Brain & Development Unit, National Institute of Mental Health, Bethesda, 
MD, USA.

Two ongoing movements in human cognitive neuroscience have researchers shifting 
focus from group-level inferences to characterizing single subjects, and 
complementing tightly controlled tasks with rich, dynamic paradigms such as 
movies and stories. Yet relatively little work combines these two, perhaps 
because traditional analysis approaches for naturalistic imaging data are geared 
toward detecting shared responses rather than between-subject variability. Here, 
we review recent work using naturalistic stimuli to study individual 
differences, and advance a framework for detecting structure in idiosyncratic 
patterns of brain activity, or "idiosynchrony". Specifically, we outline the 
emerging technique of inter-subject representational similarity analysis 
(IS-RSA), including its theoretical motivation and an empirical demonstration of 
how it recovers brain-behavior relationships during movie watching using data 
from the Human Connectome Project. We also consider how stimulus choice may 
affect the individual signal and discuss areas for future research. We argue 
that naturalistic neuroimaging paradigms have the potential to reveal meaningful 
individual differences above and beyond those observed during traditional tasks 
or at rest.

Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2020.116828
PMCID: PMC7298885
PMID: 32276065 [Indexed for MEDLINE]


102. Brain Topogr. 2020 May;33(3):285-287. doi: 10.1007/s10548-020-00766-5. Epub 2020 
Apr 6.

Investigating Emotional Similarity: A Comment on Riberto, Pobric, and Talmi 
(2019).

Levine SM(1)(2), Wackerle A(3).

Author information:
(1)Department of Cognitive and Clinical Neuroscience, Central Institute of 
Mental Health, Medical Faculty Mannheim, Heidelberg University, Square J5, 
Mannheim, 68159, Germany. seth.levine@zi-mannheim.de.
(2)Department of Psychiatry and Psychotherapy, University of Regensburg, 
Universitätsstaße 84, Regensburg, 93053, Germany. seth.levine@zi-mannheim.de.
(3)Department of Psychiatry and Psychotherapy, University of Regensburg, 
Universitätsstaße 84, Regensburg, 93053, Germany.

Comment in
    Brain Topogr. 2020 May;33(3):288.

A recent review of the neuroimaging literature on emotional similarity brought 
to light some of the drawbacks of the latest studies. The authors discussed 
important methodological considerations for future work in this field, which 
predominantly involved stimulus selection. In general, we feel that their 
suggestions are valuable, but we hold that, depending on the specific scientific 
question(s) under investigation (e.g., individual differences), some of the 
suggestions may not meaningfully contribute to the scope of the study and might 
even introduce artificial constraints that could reduce the researchers' ability 
to discover effects of interest. Here we indicate one way to potentially 
circumvent such stimulus-related issues in neuroimaging studies and furthermore 
present a few scenarios in which additional controlling of the stimulus set may 
not be necessary or possible when investigating individual differences. This 
commentary serves to supplement the important methodological points raised by 
the authors by providing a caveat in potentially applying such points to all 
future experiments investigating emotional similarity.

DOI: 10.1007/s10548-020-00766-5
PMID: 32253572 [Indexed for MEDLINE]


103. Cogn Neurosci. 2020 Jul;11(3):111-121. doi: 10.1080/17588928.2020.1742678. Epub 
2020 Apr 6.

Dynamic activity patterns in the anterior temporal lobe represents object 
semantics.

Clarke A(1).

Author information:
(1)Department of Psychology, University of Cambridge , Cambridge, UK.

The anterior temporal lobe (ATL) is considered a crucial area for the 
representation of transmodal concepts. Recent evidence suggests that specific 
regions within the ATL support the representation of individual object concepts, 
as shown by studies combining multivariate analysis methods and explicit 
measures of semantic knowledge. This research looks to further our understanding 
by probing conceptual representations at a spatially and temporally resolved 
neural scale. Representational similarity analysis was applied to human 
intracranial recordings from anatomically defined lateral to medial ATL 
sub-regions. Neural similarity patterns were tested against semantic similarity 
measures, where semantic similarity was defined by a hybrid corpus-based and 
feature-based approach. Analyses show that the perirhinal cortex, in the medial 
ATL, significantly related to semantic effects around 200 to 400 ms, and were 
greater than more lateral ATL regions. Further, semantic effects were present in 
low frequency (theta and alpha) oscillatory phase signals. These results provide 
converging support that more medial regions of the ATL support the 
representation of basic-level visual object concepts within the first 400 ms, 
and provide a bridge between prior fMRI and MEG work by offering detailed 
evidence for the presence of conceptual representations within the ATL.

DOI: 10.1080/17588928.2020.1742678
PMCID: PMC7446031
PMID: 32249714 [Indexed for MEDLINE]

Conflict of interest statement: No potential conflict of interest was reported 
by the author.


104. Soc Cogn Affect Neurosci. 2020 May 19;15(3):273-284. doi: 10.1093/scan/nsaa045.

Pattern similarity and connectivity of hippocampal-neocortical regions support 
empathy for pain.

Wagner IC(1), Rütgen M(1), Lamm C(1).

Author information:
(1)Social, Cognitive and Affective Neuroscience Unit, Department of Cognition, 
Emotion, and Methods in Psychology, Faculty of Psychology, University of Vienna, 
Liebiggasse 5, Vienna 1010, Austria.

Empathy is thought to engage mental simulation, which in turn is known to rely 
on hippocampal-neocortical processing. Here, we tested how 
hippocampal-neocortical pattern similarity and connectivity contributed to pain 
empathy. Using this approach, we analyzed a data set of 102 human participants 
who underwent functional MRI while painful and non-painful electrical 
stimulation was delivered to themselves or to a confederate. As hypothesized, 
results revealed increased pattern similarity between first-hand pain and pain 
empathy (compared to non-painful control conditions) within the hippocampus, 
retrosplenial cortex, the temporo-parietal junction and anterior insula. While 
representations in these regions were unaffected by confederate similarity, 
pattern similarity in the dorsal medial prefrontal cortex was increased the more 
dissimilar the other individual was perceived. Hippocampal-neocortical 
connectivity during first-hand pain and pain empathy engaged largely distinct 
but neighboring primary motor regions, and empathy-related hippocampal coupling 
with the fusiform gyrus positively scaled with trait measures of perspective 
taking. These findings suggest that shared representations and mental simulation 
might contribute to pain empathy via hippocampal-neocortical pattern similarity 
and connectivity, partially affected by personality traits and the similarity of 
the observed individual.

© The Author(s) 2020. Published by Oxford University Press.

DOI: 10.1093/scan/nsaa045
PMCID: PMC7235961
PMID: 32248233 [Indexed for MEDLINE]


105. Neuropsychologia. 2020 May;142:107416. doi: 
10.1016/j.neuropsychologia.2020.107416. Epub 2020 Mar 12.

Divergence in cortical representations of threat generalization in affective 
versus perceptual circuitry in childhood: Relations with anxiety.

Glenn DE(1), Fox NA(2), Pine DS(3), Peters MAK(4), Michalska KJ(5).

Author information:
(1)Department of Psychology, University of California Riverside, Riverside, CA, 
92521, USA.
(2)Department of Human Development and Quantitative Methodology, University of 
Maryland, College Park, MD, 20740, USA.
(3)The National Institute of Mental Health, Emotion and Development Branch, 
Bethesda, MD, 20814, USA.
(4)Department of Psychology, University of California Riverside, Riverside, CA, 
92521, USA; Department of Bioengineering, University of California Riverside, 
Riverside, CA, 92521, USA. Electronic address: mpeters@engr.ucr.edu.
(5)Department of Psychology, University of California Riverside, Riverside, CA, 
92521, USA. Electronic address: kalina.michalska@ucr.edu.

Children at risk for anxiety display elevated threat sensitivity and may 
inaccurately classify safe stimuli as threatening, a process known as 
overgeneralization. Little is known about whether such overgeneralization might 
stem from altered sensory representations of stimuli resembling threat, 
especially in youth. Here we implement representational similarity analysis of 
fMRI data to examine the similarity of neural representations of threat versus 
ambiguous or safe stimuli in threat and perceptual neurocircuitry among children 
at varying levels of anxiety traits. Three weeks after completing threat 
conditioning and extinction, children underwent an fMRI extinction recall task, 
during which they viewed the extinguished threat cue (CS+), safety cue (CS-) and 
generalization stimuli (GS) consisting of CS-/CS+ blends. Multivoxel BOLD signal 
patterns were measured in seven regions of interest: four affective areas 
(ventromedial prefrontal cortex (vmPFC), anterior insular cortex (AIC), 
dorsomedial prefrontal cortex (dmPFC), and amygdala) and three perceptual areas 
(inferior temporal cortex (ITC) and visual areas V1 and V4). Compared to low 
anxious children, children with high trait anxiety evidenced less neural pattern 
differentiation between the CS+ and similar GS, particularly in the vmPFC. 
Together, these results demonstrate the utility of multivariate neuroimaging 
approaches in arbitrating the relative contributions of perceptual versus 
affective sources to threat generalization.

Copyright © 2020. Published by Elsevier Ltd.

DOI: 10.1016/j.neuropsychologia.2020.107416
PMCID: PMC7658962
PMID: 32173623 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest All authors 
report no biomedical financial interests or potential conflicts of interest.


106. Neuroimage. 2020 Jul 1;214:116716. doi: 10.1016/j.neuroimage.2020.116716. Epub 
2020 Mar 6.

The "Inferior Temporal Numeral Area" distinguishes numerals from other character 
categories during passive viewing: A representational similarity analysis.

Yeo DJ(1), Pollack C(2), Merkley R(3), Ansari D(4), Price GR(5).

Author information:
(1)Department of Psychology & Human Development, Peabody College, Vanderbilt 
University, 230 Appleton Place, Nashville, TN, 37203, USA; Division of 
Psychology, School of Social Sciences, Nanyang Technological University, 48 
Nanyang Avenue, 639818, Singapore.
(2)Lynch School of Education, Boston College, Campion Hall, 140 Commonwealth 
Ave, Chestnut Hill, MA, 02467, USA.
(3)Brain and Mind Institute, and Department of Psychology, University of Western 
Ontario, Westminster Hall, London, ON, N6A 3K7, Canada; Institute of Cognitive 
Science, 2201 Dunton Tower, Carleton University, 1125 Colonel By Drive, Ottawa, 
ON, K1S 5B6, Canada.
(4)Brain and Mind Institute, and Department of Psychology, University of Western 
Ontario, Westminster Hall, London, ON, N6A 3K7, Canada.
(5)Department of Psychology & Human Development, Peabody College, Vanderbilt 
University, 230 Appleton Place, Nashville, TN, 37203, USA. Electronic address: 
gavin.price@vanderbilt.edu.

A region in the posterior inferior temporal gyrus (pITG) is thought to be 
specialized for processing Arabic numerals, but fMRI studies that compared 
passive viewing of numerals to other character types (e.g., letters and novel 
characters) have not found evidence of numeral preference in the pITG. However, 
recent studies showed that the engagement of the pITG is modulated by attention 
and task contexts, suggesting that passive viewing paradigms may be ill-suited 
for examining numeral specialization in the pITG. It is possible, however, that 
even if the strengths of responses to different category types are similar, the 
distributed response patterns (i.e., neural representations) in a candidate 
numeral-preferring pITG region ("pITG-numerals") may reveal categorical 
distinctions, even during passive viewing. Using representational similarity 
analyses with three datasets that share the same task paradigm and stimulus sets 
(total N ​= ​88), we tested whether the neural representations of digits, 
letters, and novel characters in pITG-numerals were organized according to 
visual form and/or conceptual categories (e.g., familiar versus novel, numbers 
versus others). Small-scale frequentist and Bayesian meta-analyses of our 
dataset-specific findings revealed that the organization of neural 
representations in pITG-numerals is unlikely to be described by differences in 
abstract shape, but can be described by a categorical "digits versus letters" 
distinction, or even a "digits versus others" distinction (suggesting greater 
numeral sensitivity). Evidence of greater numeral sensitivity during passive 
viewing suggest that pITG-numerals is likely part of a neural pathway that has 
been developed for automatic processing of objects with potential numerical 
relevance. Given that numerals and letters do not differ categorically in terms 
of shape, categorical distinction in pITG-numerals during passive viewing must 
reflect ontogenetic differentiation of symbol set representations based on 
repeated usage of numbers and letters in differing task contexts.

Copyright © 2020 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2020.116716
PMID: 32151762 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest We wish to 
confirm that there are no known conflicts of interest associated with this 
publication and there has been no significant financial support for this work 
that could have influenced its outcome.


107. J Neurosci. 2020 Mar 25;40(13):2727-2736. doi: 10.1523/JNEUROSCI.1849-19.2020. 
Epub 2020 Feb 14.

Distance and Direction Codes Underlie Navigation of a Novel Semantic Space in 
the Human Brain.

Viganò S(1), Piazza M(2).

Author information:
(1)Center for Mind/Brain Sciences, University of Trento, 38068 Rovereto (Tn), 
Italy simone.vigano@unitn.it.
(2)Center for Mind/Brain Sciences, University of Trento, 38068 Rovereto (Tn), 
Italy.

A recent proposal posits that humans might use the same neuronal machinery to 
support the representation of both spatial and nonspatial information, 
organizing concepts and memories using spatial codes. This view predicts that 
the same neuronal coding schemes characterizing navigation in the physical space 
(tuned to distance and direction) should underlie navigation of abstract 
semantic spaces, even if they are categorical and labeled by symbols. We 
constructed an artificial semantic environment by parsing a bidimensional 
audiovisual object space into four labeled categories. Before and after a 
nonspatial symbolic categorization training, 25 adults (15 females) were 
presented with pseudorandom sequences of objects and words during a functional 
MRI session. We reasoned that subsequent presentations of stimuli (either 
objects or words) referring to different categories implied implicit movements 
in the novel semantic space, and that such movements subtended specific 
distances and directions. Using whole-brain fMRI adaptation and searchlight 
model-based representational similarity analysis, we found evidence of both 
distance-based and direction-based responses in brain regions typically involved 
in spatial navigation: the medial prefrontal cortex and the right entorhinal 
cortex (EHC). After training, both regions encoded the distances between 
concepts, making it possible to recover a faithful bidimensional representation 
of the semantic space directly from their multivariate activity patterns, 
whereas the right EHC also exhibited a periodic modulation as a function of 
traveled direction. Our results indicate that the brain regions and coding 
schemes supporting relations and movements between spatial locations in mammals 
are "recycled" in humans to represent a bidimensional multisensory conceptual 
space during a symbolic categorization task.SIGNIFICANCE STATEMENT The 
hippocampal formation and the medial prefrontal cortex of mammals represent the 
surrounding physical space by encoding distances and directions between 
locations. Recent works suggested that humans use the same neural machinery to 
organize their memories as points of an internal map of experiences. We asked 
whether the same brain regions and neural codes supporting spatial navigation 
are recruited when humans use language to organize their knowledge of the world 
in categorical semantic representations. Using fMRI, we show that the medial 
prefrontal cortex and the entorhinal portion of the hippocampal formation 
represent the distances and the movement directions between concepts of a novel 
audiovisual semantic space, and that it was possible to reconstruct, from neural 
data, their relationships in memory.

Copyright © 2020 the authors.

DOI: 10.1523/JNEUROSCI.1849-19.2020
PMCID: PMC7096136
PMID: 32060171 [Indexed for MEDLINE]


108. Neuroimage. 2020 Aug 1;216:116617. doi: 10.1016/j.neuroimage.2020.116617. Epub 
2020 Feb 10.

A naturalistic viewing paradigm using 360° panoramic video clips and real-time 
field-of-view changes with eye-gaze tracking.

Kim HC(1), Jin S(2), Jo S(1), Lee JH(3).

Author information:
(1)Department of Brain and Cognitive Engineering, Korea University, Seoul, South 
Korea.
(2)Department of Computer Science, Korea University, Seoul, South Korea.
(3)Department of Brain and Cognitive Engineering, Korea University, Seoul, South 
Korea. Electronic address: jonghwan_lee@korea.ac.kr.

The naturalistic viewing of a video clip enables participants to obtain more 
information from the clip compared to conventional viewing of a static image. 
Because changing the field-of-view (FoV) allows new visual information to be 
obtained, we were motivated to investigate whether naturalistic viewing with 
varying FoV based on active eye movement can enhance the viewing experience of 
natural stimuli, such as those found in a video clip with a 360° FoV in an MRI 
scanner. To this end, we developed a novel naturalistic viewing paradigm based 
on real-time eye-gaze tracking while participants were watching a 360° panoramic 
video during fMRI acquisition. The gaze position of the participants was 
recorded using an eye-tracking computer and then transmitted to a stimulus 
presentation computer via a TCP/IP connection. The identified gaze position was 
then used to alter the participants' FoV of the video clip in real-time, so the 
participants could change their FoV to fully explore the 360° video clip 
(referred to in this paper as active viewing). The gaze position of one 
participant while watching a video was used to change the FoV of the same video 
clip for a paired participant (referred to as yoked or passive viewing). Four 
360° panoramic videos were used as stimuli, divided into categories based on the 
brightness level (i.e., bright vs. dark) and location (i.e., nature vs. city). 
Each of the subjects participated in the active viewing of one of the two nature 
videos and one of the two city videos and then engaged in the passive viewing of 
the other video in each category, followed by conventional viewing with a fixed 
FoV (referred to as fixed viewing) after each of the active or passive viewings. 
Forty-eight healthy volunteers participated in the study, and data from 42 of 
these participants were used in the analysis. Representational similarity 
analysis (RSA) was conducted in a multiple regression framework using 
representational dissimilarity matrix (RDM) codes to accommodate all of the 
information regarding neuronal activations from fMRI analysis and the 
participants' subjective ratings of their viewing experience with the four video 
clips and with the two contrasting viewing conditions (i.e., "active-fixed" and 
"passive-fixed"). It was found that the participants' naturalistic viewing 
experience of the video clips was substantially more immersive with active 
viewing than with passive and fixed viewing. The RSA using the RDM codes 
revealed the brain regions associated with the viewing experience, including eye 
movement and spatial navigation in the superior frontal area (of Brodmann's area 
6) and the inferior/superior parietal areas, respectively. Brain regions 
potentially associated with cognitive and affective processing during the 
viewing of the video, such as the default-mode networks and insular/Rolandic 
operculum areas, were also identified. To the best of our knowledge, this is the 
first study that has used the participants' eye movements to interactively 
change their FoV for 360° panoramic video clips in real-time. Our method of 
utilizing the MRI environment can be further extended to other environments such 
as electroencephalography and behavioral research. It would also be feasible to 
apply our method to virtual reality and/or augmented reality systems to maximize 
user experience based on their eye movement.

Copyright © 2020 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2020.116617
PMID: 32057996 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
have no conflicts of interest regarding this study, including financial, 
consultant, institutional, or other relationships. The sponsors had no 
involvement in the study design, data collection, analysis or interpretation of 
the data, manuscript preparation, or the decision to submit for publication.


109. Soc Cogn Affect Neurosci. 2019 Nov 1;14(11):1243-1253. doi: 10.1093/scan/nsz099.

A Guide to Representational Similarity Analysis for Social Neuroscience.

Popal H(1), Wang Y(2), Olson IR(1).

Author information:
(1)Department of Psychology, Temple University, Philadelphia, PA.
(2)Beijing Normal University.

Representational similarity analysis (RSA) is a computational technique that 
uses pairwise comparisons of stimuli to reveal their representation in 
higher-order space. In the context of neuroimaging, mass-univariate analyses and 
other multivariate analyses can provide information on what and where 
information is represented but have limitations in their ability to address how 
information is represented. Social neuroscience is a field that can particularly 
benefit from incorporating RSA techniques to explore hypotheses regarding the 
representation of multidimensional data, how representations can predict 
behavior, how representations differ between groups and how multimodal data can 
be compared to inform theories. The goal of this paper is to provide a practical 
as well as theoretical guide to implementing RSA in social neuroscience studies.

© The Author(s) 2020. Published by Oxford University Press.

DOI: 10.1093/scan/nsz099
PMCID: PMC7057283
PMID: 31989169 [Indexed for MEDLINE]


110. J Neurosci. 2020 Feb 26;40(9):1920-1930. doi: 10.1523/JNEUROSCI.1766-19.2020. 
Epub 2020 Jan 23.

Cortical Overlap and Cortical-Hippocampal Interactions Predict Subsequent True 
and False Memory.

Wing EA(1)(2), Geib BR(3), Wang WC(3)(4), Monge Z(3), Davis SW(5), Cabeza R(3).

Author information:
(1)Center for Cognitive Neuroscience, Duke University, Durham, North Carolina 
27708, ewing@research.baycrest.org.
(2)Rotman Research Institute, Baycrest, Toronto, Ontario M6A 2E1, Canada.
(3)Center for Cognitive Neuroscience, Duke University, Durham, North Carolina 
27708.
(4)Department of Psychology, University of California Berkeley, Berkeley, 
California 94720, and.
(5)Department of Neurology, Duke University School of Medicine, Durham, North 
Carolina 27708.

The declarative memory system allows us to accurately recognize a countless 
number of items and events, particularly those strengthened by repeated 
exposure. However, increased familiarity due to repetition can also lead to 
false recognition of related but new items, particularly when mechanisms 
supporting fine-grain mnemonic discrimination fail. The hippocampus is thought 
to be particularly important in separating overlapping cortical inputs during 
encoding so that similar experiences can be differentiated. In the current study 
of male and female human subjects, we examine how neural pattern similarity 
between repeated exemplars of a given concept (e.g., apple) influences true and 
false memory for target or lure images. Consistent with past work, we found that 
subsequent true recognition was related to pattern similarity between concept 
exemplars and the entire encoding set (global encoding similarity), particularly 
in ventral visual stream. In addition, memory for an individual target exemplar 
(a specific apple) could be predicted solely by the degree of pattern overlap 
between the other exemplars (different apple pictures) of that concept 
(concept-specific encoding similarity). Critically, subsequent false memory for 
lures was mitigated when high concept-specific similarity in cortical areas was 
accompanied by differentiated hippocampal representations of the corresponding 
exemplars. Furthermore, both true and false memory entailed the reinstatement of 
concept-related information at varying levels of specificity. These results link 
both true and false memory to a measure of concept strength expressed in the 
overlap of cortical representations, and importantly, illustrate how the 
hippocampus serves to separate concurrent cortical overlap in the service of 
detailed memory.SIGNIFICANCE STATEMENT In some instances, the same processes 
that help promote memory for a general idea or concept can also hinder more 
detailed memory judgments, which may involve differentiating between closely 
related items. The current study shows that increased overlap in cortical 
representations for conceptually-related pictures is associated with increased 
recognition of repeated concept pictures. Whether similar lure items were 
falsely remembered as old further depended on the hippocampus, where the 
presence of more distinct representations protected against later false memory. 
This work suggests that the differentiability of brain patterns during 
perception is related to the differentiability of items in memory, but that 
fine-grain discrimination depends on the interaction between cortex and 
hippocampus.

Copyright © 2020 the authors.

DOI: 10.1523/JNEUROSCI.1766-19.2020
PMCID: PMC7046457
PMID: 31974208 [Indexed for MEDLINE]


111. Front Neurosci. 2020 Jan 8;13:1348. doi: 10.3389/fnins.2019.01348. eCollection 
2019.

A Comparison of Functional Networks Derived From Representational Similarity, 
Functional Connectivity, and Univariate Analyses.

Pillet I(1), Op de Beeck H(1), Lee Masson H(1).

Author information:
(1)Laboratory of Biological Psychology, Department of Brain and Cognition, 
Leuven Brain Institute, KU Leuven, Leuven, Belgium.

The invention of representational similarity analysis [RSA, following 
multi-voxel pattern analysis (MVPA)] has allowed cognitive neuroscientists to 
identify the representational structure of multiple brain regions, moving beyond 
functional localization. By comparing these structures, cognitive 
neuroscientists can characterize how brain areas form functional networks. 
Univariate analysis (UNIVAR) and functional connectivity analysis (FCA) are two 
other popular methods to identify functional networks. Despite their popularity, 
few studies have examined the relationship between networks from RSA with those 
from UNIVAR and FCA. Thus, the aim of the current study is to examine the 
similarities between neural networks derived from RSA with those from UNIVAR and 
FCA to explore how these methods relate to each other. We analyzed the data of a 
previously published study with the three methods and compared the results by 
performing (partial) correlation and multiple regression analysis. Our findings 
reveal that neural networks resulting from RSA, UNIVAR, and FCA methods are 
highly similar to each other even after ruling out the effect of anatomical 
proximity between the network nodes. Nevertheless, the neural network from each 
method shows unique organization that cannot be explained by any of the other 
methods. Thus, we conclude that the RSA, UNIVAR and FCA methods provide similar 
but not identical information on how brain regions are organized in functional 
networks.

Copyright © 2020 Pillet, Op de Beeck and Lee Masson.

DOI: 10.3389/fnins.2019.01348
PMCID: PMC6960203
PMID: 31969801


112. Cortex. 2020 Apr;125:44-59. doi: 10.1016/j.cortex.2019.12.012. Epub 2020 Jan 3.

People represent mental states in terms of rationality, social impact, and 
valence: Validating the 3d Mind Model.

Thornton MA(1), Tamir DI(2).

Author information:
(1)Department of Psychology and Princeton Neuroscience Institute, Princeton 
University, Princeton, NJ, USA. Electronic address: 
mark.allen.thornton@gmail.com.
(2)Department of Psychology and Princeton Neuroscience Institute, Princeton 
University, Princeton, NJ, USA.

Humans can experience a wide variety of different thoughts and feelings in the 
course of everyday life. To successfully navigate the social world, people need 
to perceive, understand, and predict others' mental states. Previous research 
suggests that people use three dimensions to represent mental states: 
rationality, social impact, and valence. This 3d Mind Model allows people to 
efficiently "see" the state of another person's mind by considering whether that 
state is rational or emotional, more or less socially impactful, and positive or 
negative. In the current investigation, we validate this model using neural, 
behavioral, and linguistic evidence. First, we examine the robustness of the 3d 
Mind Model by conducting a mega-analysis of four fMRI studies in which 
participants considered others' mental states. We find evidence that 
rationality, social impact, and valence each contribute to explaining the neural 
representation of mental states. Second, we test whether the 3d Mind Model 
offers the optimal combination of dimensions for describing neural 
representations of mental state. Results reveal that the 3d Mind Model achieve 
the best performance among a large set of candidate dimensions. Indeed, it 
offers a highly explanatory account of mental state representation, explaining 
over 80% of reliable neural variance. Finally, we demonstrate that all three 
dimensions of the model likewise capture convergent behavioral and linguistic 
measures of mental state representation. Together, these findings provide strong 
support for the 3d Mind Model, indicating that is it is a robust and 
generalizable account of how people think about mental states.

Copyright © 2019 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cortex.2019.12.012
PMCID: PMC7093241
PMID: 31962230 [Indexed for MEDLINE]


113. PLoS Comput Biol. 2020 Jan 15;16(1):e1007549. doi: 10.1371/journal.pcbi.1007549. 
eCollection 2020 Jan.

BrainIAK tutorials: User-friendly learning materials for advanced fMRI analysis.

Kumar M(1), Ellis CT(2), Lu Q(1), Zhang H(3), Capotă M(4), Willke TL(4), Ramadge 
PJ(1)(3), Turk-Browne NB(2), Norman KA(1)(5).

Author information:
(1)Princeton Neuroscience Institute, Princeton University, Princeton, New 
Jersey, United States of America.
(2)Department of Psychology, Yale University, New Haven, Connecticut, United 
States of America.
(3)Center for Statistics and Machine Learning, Princeton University, Princeton, 
New Jersey, United States of America.
(4)Brain-Inspired Computing Lab, Intel Corporation, Hillsboro, Oregon, United 
States of America.
(5)Department of Psychology, Princeton University, Princeton, New Jersey, United 
States of America.

Advanced brain imaging analysis methods, including multivariate pattern analysis 
(MVPA), functional connectivity, and functional alignment, have become powerful 
tools in cognitive neuroscience over the past decade. These tools are 
implemented in custom code and separate packages, often requiring different 
software and language proficiencies. Although usable by expert researchers, 
novice users face a steep learning curve. These difficulties stem from the use 
of new programming languages (e.g., Python), learning how to apply 
machine-learning methods to high-dimensional fMRI data, and minimal 
documentation and training materials. Furthermore, most standard fMRI analysis 
packages (e.g., AFNI, FSL, SPM) focus on preprocessing and univariate analyses, 
leaving a gap in how to integrate with advanced tools. To address these needs, 
we developed BrainIAK (brainiak.org), an open-source Python software package 
that seamlessly integrates several cutting-edge, computationally efficient 
techniques with other Python packages (e.g., Nilearn, Scikit-learn) for file 
handling, visualization, and machine learning. To disseminate these powerful 
tools, we developed user-friendly tutorials (in Jupyter format; 
https://brainiak.org/tutorials/) for learning BrainIAK and advanced fMRI 
analysis in Python more generally. These materials cover techniques including: 
MVPA (pattern classification and representational similarity analysis); 
parallelized searchlight analysis; background connectivity; full correlation 
matrix analysis; inter-subject correlation; inter-subject functional 
connectivity; shared response modeling; event segmentation using hidden Markov 
models; and real-time fMRI. For long-running jobs or large memory needs we 
provide detailed guidance on high-performance computing clusters. These 
notebooks were successfully tested at multiple sites, including as problem sets 
for courses at Yale and Princeton universities and at various workshops and 
hackathons. These materials are freely shared, with the hope that they become 
part of a pool of open-source software and educational materials for 
large-scale, reproducible fMRI analysis and accelerated discovery.

DOI: 10.1371/journal.pcbi.1007549
PMCID: PMC6961866
PMID: 31940340 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


114. Neuropsychologia. 2020 Feb 17;138:107340. doi: 
10.1016/j.neuropsychologia.2020.107340. Epub 2020 Jan 11.

Object parsing in the left lateral occipitotemporal cortex: Whole shape, part 
shape, and graspability.

Wu W(1), Wang X(2), Wei T(1), He C(1), Bi Y(3).

Author information:
(1)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brain Research, Beijing Normal University, Beijing, 100875, China; 
Beijing Key Laboratory of Brain Imaging and Connectomics, Beijing Normal 
University, Beijing, 100875, China.
(2)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brain Research, Beijing Normal University, Beijing, 100875, China; 
Beijing Key Laboratory of Brain Imaging and Connectomics, Beijing Normal 
University, Beijing, 100875, China. Electronic address: 
wangxiaoying@mail.bnu.edu.cn.
(3)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brain Research, Beijing Normal University, Beijing, 100875, China; 
Beijing Key Laboratory of Brain Imaging and Connectomics, Beijing Normal 
University, Beijing, 100875, China. Electronic address: ybi@bnu.edu.cn.

Small and manipulable objects (tools) preferentially evoke a network of brain 
regions relative to other objects, including the lateral occipitotemporal cortex 
(LOTC), which is assumed to process tool shape information. Given the 
correlation between various object properties, the exact type of information 
being represented in the LOTC remains debated. In three fMRI experiments, we 
examined the effects of multiple levels of shape (whole vs. object parts) and 
motor-related (grasping; manipulation) information. Combining representational 
similarity analysis and commonality analysis allowed us to partition the unique 
and shared effects of correlated dimensions. We found that grasping manner (for 
pickup), not the overall object shape or manner of manipulation, uniquely 
explained the LOTC neural activity pattern (Experiments 1 and 2). Experiment 3 
tested tools composed of two parts to understand better how grasping manner was 
computed from object visual inputs. Support vector machine analysis revealed 
that the LOTC activity could decode different shapes of the tools' handle parts 
but not the tools' head parts. Together, these results suggest that the LOTC 
parses tool shapes by how it maps onto grasping programs; such parsing is not 
fully based on the whole-object shape but rather an interaction between the 
whole (where to grasp) and its parts (distinguishing the shape for the grasping 
part for specific grasping manners).

Copyright © 2020 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2020.107340
PMID: 31935393 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
declare no competing financial interests.


115. Neuroimage. 2020 Apr 1;209:116531. doi: 10.1016/j.neuroimage.2020.116531. Epub 
2020 Jan 10.

Spatio-temporal dynamics of face perception.

Muukkonen I(1), Ölander K(2), Numminen J(3), Salmela VR(4).

Author information:
(1)Department of Psychology and Logopedics, University of Helsinki, Finland. 
Electronic address: ilkka.muukkonen@helsinki.fi.
(2)Department of Psychology and Logopedics, University of Helsinki, Finland.
(3)Helsinki Medical Imaging Centre at Töölö Hospital, Helsinki University 
Hospital, Finland.
(4)Department of Psychology and Logopedics, University of Helsinki, Finland; Ami 
Centre, Aalto Neuroimaging, Aalto University, Finland.

The temporal and spatial neural processing of faces has been investigated 
rigorously, but few studies have unified these dimensions to reveal the 
spatio-temporal dynamics postulated by the models of face processing. We used 
support vector machine decoding and representational similarity analysis to 
combine information from different locations (fMRI), time windows (EEG), and 
theoretical models. By correlating representational dissimilarity matrices 
(RDMs) derived from multiple pairwise classifications of neural responses to 
different facial expressions (neutral, happy, fearful, angry), we found early 
EEG time windows (starting around 130 ​ms) to match fMRI data from primary 
visual cortex (V1), and later time windows (starting around 190 ​ms) to match 
data from lateral occipital, fusiform face complex, and 
temporal-parietal-occipital junction (TPOJ). According to model comparisons, the 
EEG classification results were based more on low-level visual features than 
expression intensities or categories. In fMRI, the model comparisons revealed 
change along the processing hierarchy, from low-level visual feature coding in 
V1 to coding of intensity of expressions in the right TPOJ. The results 
highlight the importance of a multimodal approach for understanding the 
functional roles of different brain regions in face processing.

Copyright © 2020 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2020.116531
PMID: 31931156 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
declare no conflicting interests.


116. Neuroimage. 2020 Apr 1;209:116497. doi: 10.1016/j.neuroimage.2019.116497. Epub 
2019 Dec 30.

Acute stress alters neural patterns of value representation for others.

Tomova L(1), Saxe R(2), Klöbl M(3), Lanzenberger R(3), Lamm C(4).

Author information:
(1)Department of Brain and Cognitive Sciences, Massachusetts Institute of 
Technology, Cambridge, 02139, Massachusetts, USA; Social, Cognitive and 
Affective Neuroscience Unit, Department of Basic Psychological Research and 
Research Methods, University of Vienna, Austria. Electronic address: 
tomova@mit.edu.
(2)Department of Brain and Cognitive Sciences, Massachusetts Institute of 
Technology, Cambridge, 02139, Massachusetts, USA.
(3)Department of Psychiatry and Psychotherapy, Medical University of Vienna, 
Austria.
(4)Social, Cognitive and Affective Neuroscience Unit, Department of Basic 
Psychological Research and Research Methods, University of Vienna, Austria; 
Vienna Cognitive Science Hub, University of Vienna, Austria.

Acute stress is often evoked during social interactions, by feelings of threat 
or negative evaluation by other people. We also constantly interact with others 
while under stress - in the workplace or in private alike. However, it is not 
clear how stress affects social interactions. For one, individuals could become 
more selfish and focused on their own goals. On the other hand, individuals 
might also become more focused on affiliating with potential social partners, in 
order to secure their support. There is, indeed, accumulating behavioral 
evidence that prosocial behaviors increase rather than decrease under stress. 
Here, we tested the underlying brain processes of such findings, by assessing 
the effects of stress on the neural representations of (monetary) value for self 
and other. Participants (N ​= ​30; male, 18-40 years) played a gambling task for 
themselves and for another participant while undergoing functional magnetic 
resonance imaging (fMRI). Each participant played the gambling task twice: once 
immediately following acute stress induction, and once in a control session. We 
compared neural patterns of value representation in the dorsomedial prefrontal 
cortex (dmPFC), ventromedial prefrontal cortex (vmPFC) and striatum using 
representational similarity analysis (RSA). We found that under stress, dmPFC 
and striatum showed higher dissimilarity between neural patterns underlying high 
and low value for the other. Dissimilarity of neural patterns underlying high 
and low value for the self was unaffected by stress. These findings suggest that 
participants track the magnitude of possible rewards for others more under 
stress, suggesting increased prosocial orientation.

Copyright © 2019 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.116497
PMID: 31899285 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest All authors 
declare no competing financial interests or potential conflicts of interest in 
relation to the work described. RL received conference speaker honorarium within 
the last three years from Shire, support from Siemens Healthcare regarding 
clinical research using PET/MR, and he is shareholder of BM Health GmbH since 
2019.


117. Neurobiol Lang (Camb). 2020;1(4):381-401. doi: 10.1162/nol_a_00018. Epub 2020 
Oct 1.

Neural Components of Reading Revealed by Distributed and Symbolic Computational 
Models.

Staples R(1), Graves WW(1).

Author information:
(1)Department of Psychology, Rutgers University, 101 Warren St., Newark, NJ 
07102.

Determining how the cognitive components of reading - orthographic, 
phonological, and semantic representations - are instantiated in the brain has 
been a longstanding goal of psychology and human cognitive neuroscience. The two 
most prominent computational models of reading instantiate different cognitive 
processes, implying different neural processes. Artificial neural network (ANN) 
models of reading posit non-symbolic, distributed representations. The 
dual-route cascaded (DRC) model instead suggests two routes of processing, one 
representing symbolic rules of spelling-sound correspondence, the other 
representing orthographic and phonological lexicons. These models are not 
adjudicated by behavioral data and have never before been directly compared in 
terms of neural plausibility. We used representational similarity analysis to 
compare the predictions of these models to neural data from participants reading 
aloud. Both the ANN and DRC model representations corresponded with neural 
activity. However, ANN model representations correlated to more reading-relevant 
areas of cortex. When contributions from the DRC model were statistically 
controlled, partial correlations revealed that the ANN model accounted for 
significant variance in the neural data. The opposite analysis, examining the 
variance explained by the DRC model with contributions from the ANN model 
factored out, revealed no correspondence to neural activity. Our results suggest 
that ANNs trained using distributed representations provide a better 
correspondence between cognitive and neural coding. Additionally, this framework 
provides a principled approach for comparing computational models of cognitive 
function to gain insight into neural representations.

DOI: 10.1162/nol_a_00018
PMCID: PMC9635488
PMID: 36339637

Conflict of interest statement: The authors have no conflicts of interest to 
declare.


118. Neuroimage. 2020 Apr 1;209:116499. doi: 10.1016/j.neuroimage.2019.116499. Epub 
2019 Dec 27.

Default network contributions to episodic and semantic processing during 
divergent creative thinking: A representational similarity analysis.

Beaty RE(1), Chen Q(2), Christensen AP(3), Kenett YN(4), Silvia PJ(3), Benedek 
M(5), Schacter DL(6).

Author information:
(1)Department of Psychology, Pennsylvania State University, USA. Electronic 
address: rebeaty@psu.edu.
(2)Department of Psychology, Pennsylvania State University, USA; School of 
Psychology, Southwest University, China.
(3)Department of Psychology, University of North Carolina at Greensboro, USA.
(4)Department of Psychology, University of Pennsylvania, USA.
(5)Department of Psychology, University of Graz, Austria.
(6)Department of Psychology and Center for Brain Science, Harvard University, 
USA.

Cognitive and neuroimaging evidence suggests that episodic and semantic 
memory-memory for autobiographical events and conceptual knowledge, 
respectively-support different aspects of creative thinking, with a growing 
number of studies reporting activation of brain regions within the default 
network during performance on creative thinking tasks. The present research 
sought to dissociate neural contributions of these memory processes by inducing 
episodic or semantic retrieval orientations prior to performance on a divergent 
thinking task during fMRI. We conducted a representational similarity analysis 
(RSA) to identify multivoxel patterns of neural activity that were similar 
across induction (episodic and semantic) and idea generation. At the behavioral 
level, we found that semantic induction was associated with increased idea 
originality, assessed via computational estimates of semantic distance between 
concepts. RSA revealed that multivoxel patterns during semantic induction and 
subsequent idea generation were more similar (compared to episodic induction) 
within the left angular gyrus (AG), posterior cingulate cortex (PCC), and left 
anterior inferior parietal lobe (IPL). Conversely, activity patterns during 
episodic induction and subsequent generation were more similar within left 
parahippocampal gyrus and right anterior IPL. Together, the findings point to 
dissociable contributions of episodic and semantic memory processes to creative 
cognition and suggest that distinct regions within the default network support 
specific memory-related processes during divergent thinking.

Copyright © 2019 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.116499
PMCID: PMC7056499
PMID: 31887423 [Indexed for MEDLINE]


119. Front Neurosci. 2019 Dec 3;13:1286. doi: 10.3389/fnins.2019.01286. eCollection 
2019.

Neural Representation of Parental Monitoring and Links to Adolescent Risk 
Taking.

Lee TH(1), Qu Y(2), Telzer EH(3).

Author information:
(1)Department of Psychology, Virginia Tech, Blacksburg, VA, United States.
(2)School of Education and Social Policy, Northwestern University, Evanston, IL, 
United States.
(3)Department of Psychology and Neuroscience, The University of North Carolina 
at Chapel Hill, Chapel Hill, NC, United States.

Decades of developmental research have demonstrated the positive role of 
parental monitoring during adolescence, a time during which youth seek 
exploration and show heightened risk taking. The present study employed a novel 
neural pattern similarity approach to identify neural patterns underpinning 
parental monitoring, with attention to implications for adolescent risk taking. 
Mothers (N = 23) underwent an fMRI scan during which they completed a 
risk-taking task and viewed the risk-taking behavior of their adolescent child. 
Using a representational similarity analysis, we examined the neural pattern 
similarity between mothers' anticipation of their child's risk taking and their 
own decisions. Higher parental monitoring was reflected in greater similarity 
between neural pattern of anticipating their adolescents' risk taking and 
experiencing their own safe outcomes. Moreover, greater neural pattern 
similarity between mothers' anticipation and their own safe outcomes was 
associated with lower risk-taking propensity in adolescents. Taken together, the 
present study provides preliminary evidence for the neural patterns underpinning 
parental monitoring, highlighting the importance of incorporating parents' brain 
as a window to understand parenting practices and adolescent risk taking.

Copyright © 2019 Lee, Qu and Telzer.

DOI: 10.3389/fnins.2019.01286
PMCID: PMC6901698
PMID: 31849594


120. Elife. 2019 Dec 5;8:e47686. doi: 10.7554/eLife.47686.

The representational space of observed actions.

Tucciarelli R(1), Wurm M(2), Baccolo E(2), Lingnau A(1)(2)(3).

Author information:
(1)Department of Psychology, Royal Holloway University of London, Egham, United 
Kingdom.
(2)Center for Mind/Brain Sciences (CIMeC), University of Trento, Rovereto, 
Italy.
(3)Institute of Psychology, University of Regensburg, Regensburg, Germany.

Categorizing and understanding other people's actions is a key human capability. 
Whereas there exists a growing literature regarding the organization of objects, 
the representational space underlying the organization of observed actions 
remains largely unexplored. Here we examined the organizing principles of a 
large set of actions and the corresponding neural representations. Using 
multiple regression representational similarity analysis of fMRI data, in which 
we accounted for variability due to major action components (body parts, scenes, 
movements, objects, sociality, transitivity) and three control models (distance 
between observer and actor, number of people, HMAX-C1), we found that the 
semantic dissimilarity structure was best captured by patterns of activation in 
the lateral occipitotemporal cortex (LOTC). Together, our results demonstrate 
that the organization of observed actions in the LOTC resembles the organizing 
principles used by participants to classify actions behaviorally, in line with 
the view that this region is crucial for accessing the meaning of actions.

© 2019, Tucciarelli et al.

DOI: 10.7554/eLife.47686
PMCID: PMC6894926
PMID: 31804177 [Indexed for MEDLINE]

Conflict of interest statement: RT, MW, EB, AL No competing interests declared


121. Elife. 2019 Nov 29;8:e49562. doi: 10.7554/eLife.49562.

Alpha/beta power decreases track the fidelity of stimulus-specific information.

Griffiths BJ(1)(2), Mayhew SD(1)(2), Mullinger KJ(1)(2)(3), Jorge J(4), Charest 
I(1)(2), Wimber M(1)(2), Hanslmayr S(1)(2).

Author information:
(1)School of Psychology, University of Birmingham, Birmingham, United Kingdom.
(2)Centre for Human Brain Health, University of Birmingham, Birmingham, United 
Kingdom.
(3)Sir Peter Mansfield Imaging Centre, School of Physics and Astronomy, 
University of Nottingham, Nottingham, United Kingdom.
(4)Laboratory for Functional and Metabolic Imaging, École Polytechnique Fédérale 
de Lausanne, Lausanne, Switzerland.

Massed synchronised neuronal firing is detrimental to information processing. 
When networks of task-irrelevant neurons fire in unison, they mask the signal 
generated by task-critical neurons. On a macroscopic level, such synchronisation 
can contribute to alpha/beta (8-30 Hz) oscillations. Reducing the amplitude of 
these oscillations, therefore, may enhance information processing. Here, we test 
this hypothesis. Twenty-one participants completed an associative memory task 
while undergoing simultaneous EEG-fMRI recordings. Using representational 
similarity analysis, we quantified the amount of stimulus-specific information 
represented within the BOLD signal on every trial. When correlating this metric 
with concurrently-recorded alpha/beta power, we found a significant negative 
correlation which indicated that as post-stimulus alpha/beta power decreased, 
stimulus-specific information increased. Critically, we found this effect in 
three unique tasks: visual perception, auditory perception, and visual memory 
retrieval, indicating that this phenomenon transcends both stimulus modality and 
cognitive task. These results indicate that alpha/beta power decreases 
parametrically track the fidelity of both externally-presented and 
internally-generated stimulus-specific information represented within the 
cortex.

© 2019, Griffiths et al.

DOI: 10.7554/eLife.49562
PMCID: PMC6904219
PMID: 31782730 [Indexed for MEDLINE]

Conflict of interest statement: BG, SM, KM, JJ, IC, MW, SH No competing 
interests declared


122. Vision (Basel). 2019 Feb 10;3(1):8. doi: 10.3390/vision3010008.

Reliability and Generalizability of Similarity-Based Fusion of MEG and fMRI Data 
in Human Ventral and Dorsal Visual Streams.

Mohsenzadeh Y(1), Mullin C(1), Lahner B(1)(2), Cichy RM(3), Oliva A(1).

Author information:
(1)Computer Science and AI Lab., Massachusetts Institute of Technology, 
Cambridge, MA 02139, USA.
(2)Department of Biomedical Engineering, Boston University, Boston, MA 02215, 
USA.
(3)Department of Education and Psychology, Freie Universität Berlin, Berlin 
14195, Germany.

To build a representation of what we see, the human brain recruits regions 
throughout the visual cortex in cascading sequence. Recently, an approach was 
proposed to evaluate the dynamics of visual perception in high spatiotemporal 
resolution at the scale of the whole brain. This method combined functional 
magnetic resonance imaging (fMRI) data with magnetoencephalography (MEG) data 
using representational similarity analysis and revealed a hierarchical 
progression from primary visual cortex through the dorsal and ventral streams. 
To assess the replicability of this method, we here present the results of a 
visual recognition neuro-imaging fusion experiment and compare them within and 
across experimental settings. We evaluated the reliability of this method by 
assessing the consistency of the results under similar test conditions, showing 
high agreement within participants. We then generalized these results to a 
separate group of individuals and visual input by comparing them to the fMRI-MEG 
fusion data of Cichy et al (2016), revealing a highly similar temporal 
progression recruiting both the dorsal and ventral streams. Together these 
results are a testament to the reproducibility of the fMRI-MEG fusion approach 
and allows for the interpretation of these spatiotemporal dynamic in a broader 
context.

DOI: 10.3390/vision3010008
PMCID: PMC6802768
PMID: 31735809

Conflict of interest statement: The authors declare no conflict of interest. The 
funders had no role in the design of the study; in the collection, analyses, or 
interpretation of data; in the writing of the manuscript, or in the decision to 
publish the result.


123. Elife. 2019 Oct 9;8:e48182. doi: 10.7554/eLife.48182.

A neural mechanism for contextualizing fragmented inputs during naturalistic 
vision.

Kaiser D(1)(2), Turini J(2)(3), Cichy RM(2)(4)(5).

Author information:
(1)Department of Psychology, University of York, York, United Kingdom.
(2)Department of Education and Psychology, Freie Universität Berlin, Berlin, 
Germany.
(3)Institute of Psychology, Goethe-Universität Frankfurt, Frankfurt am Main, 
Germany.
(4)Berlin School of Mind and Brain, Humboldt-Universität Berlin, Berlin, 
Germany.
(5)Bernstein Center for Computational Neuroscience Berlin, Berlin, Germany.

With every glimpse of our eyes, we sample only a small and incomplete fragment 
of the visual world, which needs to be contextualized and integrated into a 
coherent scene representation. Here we show that the visual system achieves this 
contextualization by exploiting spatial schemata, that is our knowledge about 
the composition of natural scenes. We measured fMRI and EEG responses to 
incomplete scene fragments and used representational similarity analysis to 
reconstruct their cortical representations in space and time. We observed a 
sorting of representations according to the fragments' place within the scene 
schema, which occurred during perceptual analysis in the occipital place area 
and within the first 200 ms of vision. This schema-based coding operates 
flexibly across visual features (as measured by a deep neural network model) and 
different types of environments (indoor and outdoor scenes). This flexibility 
highlights the mechanism's ability to efficiently organize incoming information 
under dynamic real-world conditions.

© 2019, Kaiser et al.

DOI: 10.7554/eLife.48182
PMCID: PMC6802952
PMID: 31596234 [Indexed for MEDLINE]

Conflict of interest statement: DK, JT, RC No competing interests declared


124. Cortex. 2019 Oct;119:428-440. doi: 10.1016/j.cortex.2019.07.019. Epub 2019 Aug 
14.

Insula and putamen centered functional connectivity networks reflect healthy 
agers' subjective experience of cognitive fatigue in multiple tasks.

Anderson AJ(1), Ren P(2), Baran TM(3), Zhang Z(4), Lin F(5).

Author information:
(1)Department of Neuroscience, University of Rochester Medical Center, USA; 
Department of Biomedical Engineering, University of Rochester, USA. Electronic 
address: aander41@ur.rochester.edu.
(2)Shenzhen Kangning Hospital, Guangdong, China; School of Nursing, University 
of Rochester Medical Center, USA.
(3)Department of Biomedical Engineering, University of Rochester, USA; 
Department of Imaging Science, University of Rochester Medical Center, USA.
(4)Department of Biostatistics and Computational Biology, University of 
Rochester Medical Center, USA.
(5)Department of Neuroscience, University of Rochester Medical Center, USA; 
School of Nursing, University of Rochester Medical Center, USA; Department of 
Neurology, University of Rochester Medical Center, USA; Department of 
Psychiatry, University of Rochester Medical Center, USA; Department of Brain and 
Cognitive Sciences, University of Rochester, USA. Electronic address: 
vankee_lin@urmc.rochester.edu.

Cognitive fatigue (CF) impairs ability to perform daily activities, is a common 
complaint of aging and a symptom of multiple neurological conditions. However, 
knowledge of the neural basis of CF is limited. This is partially because CF is 
difficult to systematically modulate in brain imaging experiments. The most 
common approach has been to scan brain activity during effortful cognitive 
tasks. Consequently, neural correlates of CF tend to be task-specific and may 
vary across tasks. This makes it difficult to know how results generalize across 
studies and is outside the subjective experience of CF which tends to be similar 
in different tasks. It has been hypothesized that the subjective experience of 
CF might arise from domain general systems monitoring and acting on energy 
depletion in task specific circuits. Direct supporting neural evidence is 
lacking. By repeatedly scanning aging individuals undertaking four different 
tasks using functional Magnetic Resonance Imaging and referencing scans to 
detailed CF self-ratings taken before and after scanning, we sought task-general 
correlates of CF. We ran a data-driven representational similarity analysis, 
treating each brain region as a candidate CF functional connectivity hub, and 
correlating inter-participant differences in hub-based connectivity patterns 
with inter-participant differences in self-rated CF-profiles (a pattern of 
ratings across 18 questions). Both right insula and right putamen-based network 
connectivity patterns reflected CF across all tasks and could underpin 
subjective experience of CF.

Copyright © 2019 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cortex.2019.07.019
PMCID: PMC6783365
PMID: 31499435 [Indexed for MEDLINE]


125. Neuroimage. 2019 Nov 15;202:116153. doi: 10.1016/j.neuroimage.2019.116153. Epub 
2019 Sep 3.

Lateral occipitotemporal cortex encodes perceptual components of social actions 
rather than abstract representations of sociality.

Wurm MF(1), Caramazza A(2).

Author information:
(1)Center for Mind/Brain Sciences, University of Trento, 38068, Rovereto, TN, 
Italy. Electronic address: moritz.wurm@unitn.it.
(2)Center for Mind/Brain Sciences, University of Trento, 38068, Rovereto, TN, 
Italy; Cognitive Neuropsychology Laboratory, Harvard University, Cambridge, MA, 
02138, USA.

Neuroimaging studies suggest that areas in the lateral occipitotemporal cortex 
(LOTC) play an important role in the perception of social actions. However, it 
is unclear what precisely about social actions these areas represent: perceptual 
features that may be indicative of social actions - such as the presence of 
persons in a scene, their orientation toward each other, and in particular the 
directedness of action movements toward persons or other targets - or more 
abstract representations that capture whether an action is meant to be social. 
In two fMRI experiments, we used representational similarity analysis (RSA) to 
test whether LOTC is sensitive to perceptual action components important for 
social interpretation and/or more general representations of sociality 
(Experiment 1) and implied person-directedness (Experiment 2). We found that 
LOTC is sensitive to perceptual action components (person presence, person 
orientation, and action directedness toward different types of recipients). By 
contrast, more general levels of sociality and implied person-directedness were 
not captured by LOTC. Our findings suggest that regions in LOTC provide the 
perceptual basis for social action interpretation but challenge accounts that 
posit specialization at more general levels sensitive to social actions and 
sociality as such. We propose that the interpretation of an action - in terms of 
sociality or other intentional aspects - arises from the interaction of multiple 
areas in processing relevant action components in a situation-dependent manner.

Copyright © 2019 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.116153
PMID: 31491524 [Indexed for MEDLINE]


126. Proc Natl Acad Sci U S A. 2019 Sep 3;116(36):17723-17728. doi: 
10.1073/pnas.1818575116. Epub 2019 Aug 19.

Mapping visual symbols onto spoken language along the ventral visual stream.

Taylor JSH(1), Davis MH(2), Rastle K(3).

Author information:
(1)School of Life and Health Sciences, Aston University, Birmingham B4 7ET, 
United Kingdom; joanne.taylor@ucl.ac.uk.
(2)Medical Research Council Cognition and Brain Sciences Unit, University of 
Cambridge, Cambridge CB2 7EF, United Kingdom.
(3)Department of Psychology, Royal Holloway University of London, Egham TW20 
0EX, United Kingdom.

Reading involves transforming arbitrary visual symbols into sounds and meanings. 
This study interrogated the neural representations in ventral occipitotemporal 
cortex (vOT) that support this transformation process. Twenty-four adults 
learned to read 2 sets of 24 novel words that shared phonemes and semantic 
categories but were written in different artificial orthographies. Following 2 
wk of training, participants read the trained words while neural activity was 
measured with functional MRI. Representational similarity analysis on item pairs 
from the same orthography revealed that right vOT and posterior regions of left 
vOT were sensitive to basic visual similarity. Left vOT encoded letter identity 
and representations became more invariant to position along a 
posterior-to-anterior hierarchy. Item pairs that shared sounds or meanings, but 
were written in different orthographies with no letters in common, evoked 
similar neural patterns in anterior left vOT. These results reveal a 
hierarchical, posterior-to-anterior gradient in vOT, in which representations of 
letters become increasingly invariant to position and are transformed to convey 
spoken language information.

Copyright © 2019 the Author(s). Published by PNAS.

DOI: 10.1073/pnas.1818575116
PMCID: PMC6731646
PMID: 31427523 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


127. J Neurosci. 2019 Oct 16;39(42):8386-8397. doi: 10.1523/JNEUROSCI.0725-19.2019. 
Epub 2019 Aug 19.

Representational Organization of Novel Task Sets during Proactive Encoding.

Palenciano AF(1), González-García C(2), Arco JE(1), Pessoa L(3), Ruz M(4).

Author information:
(1)Mind, Brain, and Behavior Research Center, University of Granada, 18011, 
Granada, Spain.
(2)Department of Experimental Psychology, Ghent University, 9000, Ghent, 
Belgium, and.
(3)Psychology Department, University of Maryland 20742.
(4)Mind, Brain, and Behavior Research Center, University of Granada, 18011, 
Granada, Spain, mruz@ugr.es.

Erratum in
    J Neurosci. 2020 Feb 5;40(6):1367.

Recent multivariate analyses of brain data have boosted our understanding of the 
organizational principles that shape neural coding. However, most of this 
progress has focused on perceptual visual regions (Connolly et al., 2012), 
whereas far less is known about the organization of more abstract, 
action-oriented representations. In this study, we focused on humans' remarkable 
ability to turn novel instructions into actions. While previous research shows 
that instruction encoding is tightly linked to proactive activations in 
frontoparietal brain regions, little is known about the structure that 
orchestrates such anticipatory representation. We collected fMRI data while 
participants (both males and females) followed novel complex verbal rules that 
varied across control-related variables (integrating within/across stimuli 
dimensions, response complexity, target category) and reward expectations. Using 
representational similarity analysis (Kriegeskorte et al., 2008), we explored 
where in the brain these variables explained the organization of novel task 
encoding, and whether motivation modulated these representational spaces. 
Instruction representations in the lateral PFC were structured by the three 
control-related variables, whereas intraparietal sulcus encoded response 
complexity and the fusiform gyrus and precuneus organized its activity according 
to the relevant stimulus category. Reward exerted a general effect, increasing 
the representational similarity among different instructions, which was robustly 
correlated with behavioral improvements. Overall, our results highlight the 
flexibility of proactive task encoding, governed by distinct representational 
organizations in specific brain regions. They also stress the variability of 
motivation-control interactions, which appear to be highly dependent on task 
attributes, such as complexity or novelty.SIGNIFICANCE STATEMENT In comparison 
with other primates, humans display a remarkable success in novel task contexts 
thanks to our ability to transform instructions into effective actions. This 
skill is associated with proactive task-set reconfigurations in frontoparietal 
cortices. It remains yet unknown, however, how the brain encodes in anticipation 
the flexible, rich repertoire of novel tasks that we can achieve. Here we 
explored cognitive control and motivation-related variables that might 
orchestrate the representational space for novel instructions. Our results 
showed that different dimensions become relevant for task prospective encoding, 
depending on the brain region, and that the lateral PFC simultaneously organized 
task representations following different control-related variables. Motivation 
exerted a general modulation upon this process, diminishing rather than 
increasing distances among instruction representations.

Copyright © 2019 the authors.

DOI: 10.1523/JNEUROSCI.0725-19.2019
PMCID: PMC6794921
PMID: 31427394 [Indexed for MEDLINE]


128. Neuroimage. 2019 Nov 15;202:116051. doi: 10.1016/j.neuroimage.2019.116051. Epub 
2019 Jul 24.

Long-term training-dependent representation of individual finger movements in 
the primary motor cortex.

Ogawa K(1), Mitsui K(2), Imai F(2), Nishida S(2).

Author information:
(1)Department of Psychology, Hokkaido University, Kita 10, Nishi 7, Kita-ku, 
Sapporo, 060-0810, Japan. Electronic address: ogawa@let.hokudai.ac.jp.
(2)Department of Psychology, Hokkaido University, Kita 10, Nishi 7, Kita-ku, 
Sapporo, 060-0810, Japan.

We investigated the effects of long-term training on the neural representation 
of individual finger movements in the primary sensorimotor cortex. One group of 
participants (trained group) included subjects trained in playing the piano 
(mean years of experience = 17.9; range = 9-26; n = 20). The other group of 
participants (novice group) had no prior experience (n = 20). All participants 
performed finger-tapping movements using either of the four digits of the hand 
(index, middle, ring, and little fingers). Functional magnetic resonance imaging 
(fMRI) was used to analyze the spatial activation patterns elicited by 
individual finger movements. Subsequently, we tried to classify the finger that 
was being moved using a multi-voxel pattern analysis (MVPA). Our results showed 
significantly higher-than-chance classification accuracies in both primary motor 
cortex (M1) and somatosensory cortex (S1) contralateral to the hand. We also 
found significantly lower classification accuracies for both hands in the 
trained group compared with the novice group in M1, without significant 
differences in the average signal changes and the number of activated voxels for 
individual fingers or overlap between digits. Representational similarity 
analysis (RSA) also demonstrated the differences in similarity patterns of 
activations between the trained and novice groups in M1. Our results indicate 
the modulation of neural representations of individual finger movements of M1 
due to long-term training.

Copyright © 2019 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.116051
PMID: 31351164 [Indexed for MEDLINE]


129. Cereb Cortex. 2020 Mar 21;30(2):836-848. doi: 10.1093/cercor/bhz130.

Regional Specialization and Coordination Within the Network for Perceiving and 
Knowing About Others.

Aglinskas A(1), Fairhall SL(1).

Author information:
(1)Center for Mind/Brain Sciences, University of Trento, Corso Bettini 31, 
Rovereto, Italy.

Seeing familiar faces prompts the recall of diverse kinds of person-related 
knowledge. How this information is encoded within the well-characterized 
face-/person-selective network remains an outstanding question. In this 
functional magnetic resonance imaging study, participants rated famous faces in 
10 tasks covering 5 domains of person knowledge (social, episodic, semantic, 
physical, and nominal). Comparing different cognitive domains enabled us to 1) 
test the relative roles of brain regions in specific cognitive processes and 2) 
apply a multivariate network-level representational similarity analysis (NetRSA) 
to gain insight into underlying system-level organization. Comparing across 
cognitive domains revealed the importance of multiple domains in most regions, 
the importance of social over nominal knowledge in the anterior temporal lobe, 
and the functional subdivision of the temporoparietal junction into perceptual 
superior temporal sulcus and knowledge-related angular gyrus. NetRSA revealed a 
strong divide between regions implicated in "default-mode" cognition and the 
fronto-lateral elements that coordinated more with "core" perceptual components 
(fusiform/occipital face areas and posterior superior temporal sulcus). NetRSA 
also revealed a taxonomy of cognitive processes, with semantic retrieval being 
more similar to episodic than nominal knowledge. Collectively, these results 
illustrate the importance of coordinated activity of the person knowledge 
network in the instantiation of the diverse cognitive capacities of this system.

© The Author(s) 2019. Published by Oxford University Press. All rights reserved. 
For permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhz130
PMCID: PMC7239670
PMID: 31340017 [Indexed for MEDLINE]


130. Elife. 2019 Jul 24;8:e45160. doi: 10.7554/eLife.45160.

Attentional amplification of neural codes for number independent of other 
quantities along the dorsal visual stream.

Castaldi E(1), Piazza M(2), Dehaene S(1), Vignaud A(3), Eger E(1).

Author information:
(1)Cognitive Neuroimaging Unit, CEA DRF/JOLIOT, INSERM, Université Paris-Sud, 
Université Paris-Saclay, NeuroSpin Center, Gif-sur-Yvette, France.
(2)Center for Mind/Brain Sciences, University of Trento, Trento, Italy.
(3)UNIRS, CEA DRF/JOLIOT, Université Paris-Saclay, NeuroSpin Center, 
Gif-sur-Yvette, France.

Humans and other animals base important decisions on estimates of number, and 
intraparietal cortex is thought to provide a crucial substrate of this ability. 
However, it remains debated whether an independent neuronal processing mechanism 
underlies this 'number sense', or whether number is instead judged indirectly on 
the basis of other quantitative features. We performed high-resolution 7 Tesla 
fMRI while adult human volunteers attended either to the numerosity or an 
orthogonal dimension (average item size) of visual dot arrays. Along the dorsal 
visual stream, numerosity explained a significant amount of variance in 
activation patterns, above and beyond non-numerical dimensions. Its 
representation was selectively amplified and progressively enhanced across the 
hierarchy when task relevant. Our results reveal a sensory extraction mechanism 
yielding information on numerosity separable from other dimensions already at 
early visual stages and suggest that later regions along the dorsal stream are 
most important for explicit manipulation of numerical quantity.

© 2019, Castaldi et al.

DOI: 10.7554/eLife.45160
PMCID: PMC6693892
PMID: 31339490 [Indexed for MEDLINE]

Conflict of interest statement: EC, MP, SD, AV, EE No competing interests 
declared


131. Neuroimage. 2019 Nov 1;201:116004. doi: 10.1016/j.neuroimage.2019.07.017. Epub 
2019 Jul 9.

Faces and voices in the brain: A modality-general person-identity representation 
in superior temporal sulcus.

Tsantani M(1), Kriegeskorte N(2), McGettigan C(3), Garrido L(4).

Author information:
(1)Division of Psychology, Department of Life Sciences, Brunel University 
London, Kingston Lane, Uxbridge, UB8 3PH, UK. Electronic address: 
maria.tsantani@gmail.com.
(2)Zuckerman Mind Brain Behavior Institute, Columbia University, 3227 Broadway, 
New York, NY, 10027, USA.
(3)Speech Hearing and Phonetic Sciences, University College London, 2 Wakefield 
St, Kings Cross, London, WC1N 1PJ, UK.
(4)Division of Psychology, Department of Life Sciences, Brunel University 
London, Kingston Lane, Uxbridge, UB8 3PH, UK. Electronic address: 
garridolucia@gmail.com.

Face-selective and voice-selective brain regions have been shown to represent 
face-identity and voice-identity, respectively. Here we investigated whether 
there are modality-general person-identity representations in the brain that can 
be driven by either a face or a voice, and that invariantly represent 
naturalistically varying face videos and voice recordings of the same identity. 
Models of face and voice integration suggest that such representations could 
exist in multimodal brain regions, and in unimodal regions via direct coupling 
between face- and voice-selective regions. Therefore, in this study we used fMRI 
to measure brain activity patterns elicited by the faces and voices of familiar 
people in face-selective, voice-selective, and person-selective multimodal brain 
regions. We used representational similarity analysis to (1) compare 
representational geometries (i.e. representational dissimilarity matrices) of 
face- and voice-elicited identities, and to (2) investigate the degree to which 
pattern discriminants for pairs of identities generalise from one modality to 
the other. We did not find any evidence of similar representational geometries 
across modalities in any of our regions of interest. However, our results showed 
that pattern discriminants that were trained to discriminate pairs of identities 
from their faces could also discriminate the respective voices (and vice-versa) 
in the right posterior superior temporal sulcus (rpSTS). Our findings suggest 
that the rpSTS is a person-selective multimodal region that shows a 
modality-general person-identity representation and integrates face and voice 
identity information.

Copyright © 2019 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.07.017
PMID: 31299368 [Indexed for MEDLINE]


132. Curr Biol. 2019 Jul 8;29(13):2237-2243.e4. doi: 10.1016/j.cub.2019.05.069. Epub 
2019 Jun 27.

Changing the Real Viewing Distance Reveals the Temporal Evolution of Size 
Constancy in Visual Cortex.

Chen J(1), Sperandio I(2), Henry MJ(3), Goodale MA(4).

Author information:
(1)Center for the Study of Applied Psychology, Guangdong Key Laboratory of 
Mental Health and Cognitive Science and the School of Psychology, South China 
Normal University, Guangzhou, Guangdong Province 510631, China; The Brain and 
Mind Institute, The University of Western Ontario, London, ON N6A 5B7, Canada. 
Electronic address: juanchen@m.scnu.edu.cn.
(2)The School of Psychology, University of East Anglia, Norwich NR4 7TJ, UK. 
Electronic address: i.sperandio@uea.ac.uk.
(3)The Brain and Mind Institute, The University of Western Ontario, London, ON 
N6A 5B7, Canada.
(4)The Brain and Mind Institute, The University of Western Ontario, London, ON 
N6A 5B7, Canada; Department of Psychology, The University of Western Ontario, 
London, ON N6A 5C2, Canada.

Our visual system provides a distance-invariant percept of object size by 
integrating retinal image size with viewing distance (size constancy). 
Single-unit studies with animals have shown that some distance cues, especially 
oculomotor cues such as vergence and accommodation, can modulate the signals in 
the thalamus or V1 at the initial processing stage [1-7]. Accordingly, one might 
predict that size constancy emerges much earlier in time [8-10], even as visual 
signals are being processed in the thalamus. So far, the studies that have 
looked directly at size coding have either used fMRI (poor temporal resolution 
[11-13]) or relied on inadequate stimuli (pictorial illusions presented on a 
monitor at a fixed distance [11, 12, 14, 15]). Here, we physically moved the 
monitor to different distances, a more ecologically valid paradigm that emulates 
what happens in everyday life and is an example of the increasing trend of 
"bringing the real world into the lab." Using this paradigm in combination with 
electroencephalography (EEG), we examined the computation of size constancy in 
real time with real-world viewing conditions. Our study provides strong evidence 
that, even though oculomotor distance cues have been shown to modulate the 
spiking rate of neurons in the thalamus and in V1, the integration of viewing 
distance cues and retinal image size takes at least 150 ms to unfold, which 
suggests that the size-constancy-related activation patterns in V1 reported in 
previous fMRI studies (e.g., [12, 13]) reflect the later processing within V1 
and/or top-down input from other high-level visual areas.

Copyright © 2019 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cub.2019.05.069
PMID: 31257140 [Indexed for MEDLINE]


133. Neuropsychologia. 2019 Sep;132:107120. doi: 
10.1016/j.neuropsychologia.2019.107120. Epub 2019 Jun 12.

Distinguishing between cognitive explanations of the problem size effect in 
mental arithmetic via representational similarity analysis of fMRI data.

Tiberghien K(1), De Smedt B(2), Fias W(1), Lyons IM(3).

Author information:
(1)Ghent University, Department of Experimental Psychology, Belgium.
(2)University of Leuven, Faculty of Psychology and Educational Sciences, 
Belgium.
(3)Georgetown University, Psychology Department, United States. Electronic 
address: ian.lyons@georgetown.edu.

Not all researchers interested in human behavior remain convinced that modern 
neuroimaging techniques have much to contribute to distinguishing between 
competing cognitive models for explaining human behavior, especially if one 
removes reverse inference from the table. Here, we took up this challenge in an 
attempt to distinguish between two competing accounts of the problem size effect 
(PSE), a robust finding in investigations of mathematical cognition. The PSE 
occurs when people solve arithmetic problems and indicates that numerically 
large problems are solved more slowly and erroneously than small problems. 
Neurocognitive explanations for the PSE can be categorized into 
representation-based and process-based views. Behavioral and traditional 
univariate neural measures have struggled to distinguish between these accounts. 
By contrast, a representational similarity analysis (RSA) approach with fMRI 
data provides competing hypotheses that can distinguish between accounts without 
recourse to reverse inference. To that end, our RSA (but not univariate) results 
provided clear evidence in favor of the representation-based over the 
process-based account of the PSE in multiplication; for addition, the results 
were less clear. Post-hoc similarity analysis distinguished still further 
between competing representation-based theoretical accounts. Namely, data 
favored the notion that individual multiplication problems are stored as 
individual memory traces sensitive to input frequency over a strictly 
magnitude-based account of memory encoding. Together, these results provide an 
example of how human neuroimaging evidence can directly inform cognitive-level 
explanations of a common behavioral phenomenon, the problem size effect. More 
broadly, these data may expand our understanding of calculation and memory 
systems in general.

Copyright © 2019 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2019.107120
PMID: 31201841 [Indexed for MEDLINE]


134. PLoS Comput Biol. 2019 May 24;15(5):e1006299. doi: 10.1371/journal.pcbi.1006299. 
eCollection 2019 May.

Representational structure or task structure? Bias in neural representational 
similarity analysis and a Bayesian method for reducing bias.

Cai MB(1), Schuck NW(2)(3), Pillow JW(1)(4), Niv Y(1)(4).

Author information:
(1)Princeton Neuroscience Institute, Princeton University, Princeton, New 
Jersey, United States of America.
(2)Max Planck Research Group Neurocode, Max Planck Institute for Human 
Development, Berlin, Germany.
(3)Max Planck UCL Centre for Computational Psychiatry and Ageing Research, 
Berlin, Germany.
(4)Department of Psychology, Princeton University, Princeton, New Jersey, United 
States of America.

The activity of neural populations in the brains of humans and animals can 
exhibit vastly different spatial patterns when faced with different tasks or 
environmental stimuli. The degrees of similarity between these neural activity 
patterns in response to different events are used to characterize the 
representational structure of cognitive states in a neural population. The 
dominant methods of investigating this similarity structure first estimate 
neural activity patterns from noisy neural imaging data using linear regression, 
and then examine the similarity between the estimated patterns. Here, we show 
that this approach introduces spurious bias structure in the resulting 
similarity matrix, in particular when applied to fMRI data. This problem is 
especially severe when the signal-to-noise ratio is low and in cases where 
experimental conditions cannot be fully randomized in a task. We propose 
Bayesian Representational Similarity Analysis (BRSA), an alternative method for 
computing representational similarity, in which we treat the covariance 
structure of neural activity patterns as a hyper-parameter in a generative model 
of the neural data. By marginalizing over the unknown activity patterns, we can 
directly estimate this covariance structure from imaging data. This method 
offers significant reductions in bias and allows estimation of neural 
representational similarity with previously unattained levels of precision at 
low signal-to-noise ratio, without losing the possibility of deriving an 
interpretable distance measure from the estimated similarity. The method is 
closely related to Pattern Component Model (PCM), but instead of modeling the 
estimated neural patterns as in PCM, BRSA models the imaging data directly and 
is suited for analyzing data in which the order of task conditions is not fully 
counterbalanced. The probabilistic framework allows for jointly analyzing data 
from a group of participants. The method can also simultaneously estimate a 
signal-to-noise ratio map that shows where the learned representational 
structure is supported more strongly. Both this map and the learned covariance 
matrix can be used as a structured prior for maximum a posteriori estimation of 
neural activity patterns, which can be further used for fMRI decoding. Our 
method therefore paves the way towards a more unified and principled analysis of 
neural representations underlying fMRI signals. We make our tool freely 
available in Brain Imaging Analysis Kit (BrainIAK).

DOI: 10.1371/journal.pcbi.1006299
PMCID: PMC6553797
PMID: 31125335 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


135. Neuroscience. 2019 Jul 1;410:254-263. doi: 10.1016/j.neuroscience.2019.05.019. 
Epub 2019 May 17.

Cross-Language Pattern Similarity in the Bilateral Fusiform Cortex Is Associated 
with Reading Proficiency in Second Language.

Qu J(1), Zhang L(1), Chen C(2), Xie P(1), Li H(1), Liu X(1), Mei L(3).

Author information:
(1)Guangdong Key Laboratory of Mental Health and Cognitive Science, Center for 
Studies of Psychological Application, and School of Psychology, South China 
Normal University, Guangzhou, China.
(2)Department of Psychological Science, University of California, Irvine, 
California, USA.
(3)Guangdong Key Laboratory of Mental Health and Cognitive Science, Center for 
Studies of Psychological Application, and School of Psychology, South China 
Normal University, Guangzhou, China. Electronic address: mll830925@126.com.

Previous studies have found that native Chinese speakers recruit the bilateral 
fusiform gyrus to read English words, in the same manner as they read Chinese 
words (i.e., the assimilation process). In this study, we quantified the neural 
pattern similarity between native (L1) and second languages (L2) by using 
representational similarity analysis (RSA), and examined the modulatory effects 
of L2 proficiency on cross-language neural pattern similarity (PS) in the 
bilateral fusiform cortex. Results showed that, for Chinese-English bilinguals, 
higher reading proficiency in L2 was associated with greater cross-language PS 
in the left fusiform gyrus, but with lower PS in the right fusiform gyrus. These 
results suggest that, as L2 proficiency increases, the assimilation process is 
enhanced in the region for word reading (left fusiform gyrus), but reduced in 
the region for nonlinguistic processing (right fusiform gyrus).

Copyright © 2019 IBRO. Published by Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuroscience.2019.05.019
PMID: 31103705 [Indexed for MEDLINE]


136. Nat Commun. 2019 May 2;10(1):2027. doi: 10.1038/s41467-019-10053-y.

Decoding individual differences in STEM learning from functional MRI data.

Cetron JS(1)(2), Connolly AC(3), Diamond SG(4), May VV(4), Haxby JV(3), Kraemer 
DJM(5).

Author information:
(1)Department of Education, Dartmouth College, Hanover, New Hampshire, 03755, 
USA.
(2)Department of Psychology, Harvard University, Cambridge, MA, 02138, USA.
(3)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
New Hampshire, 03755, USA.
(4)Thayer School of Engineering, Dartmouth College, Hanover, New Hampshire, 
03755, USA.
(5)Department of Education, Dartmouth College, Hanover, New Hampshire, 03755, 
USA. David.J.M.Kraemer@dartmouth.edu.

Traditional tests of concept knowledge generate scores to assess how well a 
learner understands a concept. Here, we investigated whether patterns of brain 
activity collected during a concept knowledge task could be used to compute a 
neural 'score' to complement traditional scores of an individual's conceptual 
understanding. Using a novel data-driven multivariate neuroimaging 
approach-informational network analysis-we successfully derived a neural score 
from patterns of activity across the brain that predicted individual differences 
in multiple concept knowledge tasks in the physics and engineering domain. These 
tasks include an fMRI paradigm, as well as two other previously validated 
concept inventories. The informational network score outperformed alternative 
neural scores computed using data-driven neuroimaging methods, including 
multivariate representational similarity analysis. This technique could be 
applied to quantify concept knowledge in a wide range of domains, including 
classroom-based education research, machine learning, and other areas of 
cognitive science.

DOI: 10.1038/s41467-019-10053-y
PMCID: PMC6497647
PMID: 31048694 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


137. Neuroimage. 2019 Aug 15;197:143-155. doi: 10.1016/j.neuroimage.2019.04.051. Epub 
2019 Apr 20.

Time-dependent motor memory representations in prefrontal cortex.

Dandolo LC(1), Schwabe L(2).

Author information:
(1)Department of Cognitive Psychology, University of Hamburg, 20146, Hamburg, 
Germany.
(2)Department of Cognitive Psychology, University of Hamburg, 20146, Hamburg, 
Germany. Electronic address: Lars.Schwabe@uni-hamburg.de.

How memories evolve over time is fundamental for understanding memory. 
Hippocampus-dependent episodic memories are generally assumed to undergo a 
time-dependent neural reorganization involving an increased reliance on 
neocortical areas. Yet, whether other forms of memory undergo a similar 
reorganization over time remains unclear. Here, we examined whether the neural 
underpinnings of motor sequence memories change over time. Participants were 
trained on a motor sequence learning task. Either 1d or 28d later, they 
performed a retention test for this task in the fMRI scanner. Sequence-specific 
motor memory was observed both 1d and 28d after initial training. Bayesian 
second-level fMRI analyses suggested a higher probability for task activity in 
the middle frontal gyrus and frontal pole 28d compared to 1d after initial motor 
learning. Searchlight representational similarity analysis indicated that areas 
in middle and superior frontal cortex were more involved in differentiating 
between multivariate activity patterns for old motor sequence memories and newly 
learned motor sequences in the 28d-group compared to the 1d-group. This 
increased involvement of lateral frontal areas during the task after 28 days was 
not paralleled by a decrease in those areas that were involved in performing the 
motor sequence retention task after 1d. These novel findings provide insights 
into how memories beyond the hippocampus evolve over time.

Copyright © 2019 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.04.051
PMID: 31015028 [Indexed for MEDLINE]


138. Brain Behav. 2019 May;9(5):e01288. doi: 10.1002/brb3.1288. Epub 2019 Apr 11.

Inferior parietal lobule and early visual areas support elicitation of 
individualized meanings during narrative listening.

Saalasti S(1)(2)(3), Alho J(1)(2), Bar M(4), Glerean E(1)(5)(6), Honkela T(7), 
Kauppila M(1), Sams M(1)(6), Jääskeläinen IP(1).

Author information:
(1)Department of Psychology and Logopedics, Medical Faculty, University of 
Helsinki, Helsinki, Finland.
(2)Brain and Mind Laboratory, Department of Neuroscience and Biomedical 
Engineering, Aalto University School of Science, Espoo, Finland.
(3)Advanced Magnetic Imaging (AMI) Centre, Aalto NeuroImaging, School of 
Science, Aalto University, Espoo, Finland.
(4)Gonda Multidisciplinary Brain Research Center, Bar-Ilan University, Ramat 
Gan, Israel.
(5)Helsinki Institute of Information Technology, Aalto University, Espoo, 
Finland.
(6)Department of Digital Humanities, University of Helsinki, Helsinki, Finland.
(7)Department of Computer Science, Aalto University School of Science, Espoo, 
Finland.

INTRODUCTION: When listening to a narrative, the verbal expressions translate 
into meanings and flow of mental imagery. However, the same narrative can be 
heard quite differently based on differences in listeners' previous experiences 
and knowledge. We capitalized on such differences to disclose brain regions that 
support transformation of narrative into individualized propositional meanings 
and associated mental imagery by analyzing brain activity associated with 
behaviorally assessed individual meanings elicited by a narrative.
METHODS: Sixteen right-handed female subjects were instructed to list words that 
best described what had come to their minds while listening to an eight-minute 
narrative during functional magnetic resonance imaging (fMRI). The fMRI data 
were analyzed by calculating voxel-wise intersubject correlation (ISC) values. 
We used latent semantic analysis (LSA) enhanced with Wordnet knowledge to 
measure semantic similarity of the produced words between subjects. Finally, we 
predicted the ISC with the semantic similarity using representational similarity 
analysis.
RESULTS: We found that semantic similarity in these word listings between 
subjects, estimated using LSA combined with WordNet knowledge, predicting 
similarities in brain hemodynamic activity. Subject pairs whose individual 
semantics were similar also exhibited similar brain activity in the bilateral 
supramarginal and angular gyrus of the inferior parietal lobe, and in the 
occipital pole.
CONCLUSIONS: Our results demonstrate, using a novel method to measure 
interindividual differences in semantics, brain mechanisms giving rise to 
semantics and associated imagery during narrative listening. During listening to 
a captivating narrative, the inferior parietal lobe and early visual cortical 
areas seem, thus, to support elicitation of individual meanings and flow of 
mental imagery.

© 2019 The Authors. Brain and Behavior published by Wiley Periodicals, Inc.

DOI: 10.1002/brb3.1288
PMCID: PMC6520291
PMID: 30977309 [Indexed for MEDLINE]

Conflict of interest statement: None of the authors claims any conflict of 
interest. None of the authors reports any competing financial interests.


139. Nat Commun. 2019 Apr 2;10(1):1483. doi: 10.1038/s41467-019-09161-6.

The computational and neural substrates of moral strategies in social 
decision-making.

van Baar JM(1)(2), Chang LJ(3), Sanfey AG(4)(5).

Author information:
(1)Donders Institute for Brain, Cognition and Behavior, Radboud University, 
Nijmegen, 6525 EN, The Netherlands. jeroen_van_baar@brown.edu.
(2)Department of Cognitive, Linguistic, and Psychological Sciences, Brown 
University, Providence, RI, 02912, USA. jeroen_van_baar@brown.edu.
(3)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH, 03755, USA.
(4)Donders Institute for Brain, Cognition and Behavior, Radboud University, 
Nijmegen, 6525 EN, The Netherlands.
(5)Behavioral Science Institute, Radboud University, Nijmegen, 6525 HR, The 
Netherlands.

Individuals employ different moral principles to guide their social 
decision-making, thus expressing a specific 'moral strategy'. Which computations 
characterize different moral strategies, and how might they be instantiated in 
the brain? Here, we tackle these questions in the context of decisions about 
reciprocity using a modified Trust Game. We show that different participants 
spontaneously and consistently employ different moral strategies. By mapping an 
integrative computational model of reciprocity decisions onto brain activity 
using inter-subject representational similarity analysis of fMRI data, we find 
markedly different neural substrates for the strategies of 'guilt aversion' and 
'inequity aversion', even under conditions where the two strategies produce the 
same choices. We also identify a new strategy, 'moral opportunism', in which 
participants adaptively switch between guilt and inequity aversion, with a 
corresponding switch observed in their neural activation patterns. These 
findings provide a valuable view into understanding how different individuals 
may utilize different moral principles.

DOI: 10.1038/s41467-019-09161-6
PMCID: PMC6445121
PMID: 30940815 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


140. Hum Brain Mapp. 2019 Jul;40(10):3078-3090. doi: 10.1002/hbm.24581. Epub 2019 Mar 
28.

Neural mechanisms of vibrotactile categorization.

Malone PS(1), Eberhardt SP(2), Wimmer K(3)(4)(5), Sprouse C(1), Klein R(1), 
Glomb K(3)(6), Scholl CA(1), Bokeria L(1), Cho P(1), Deco G(3)(7)(8)(9), Jiang 
X(1), Bernstein LE(2), Riesenhuber M(1).

Author information:
(1)Department of Neuroscience, Georgetown University Medical Center, Washington, 
District of Columbia.
(2)Department of Speech, Language, and Hearing Sciences, George Washington 
University, Washington, District of Columbia.
(3)Center for Brain and Cognition, Department of Information and Communication 
Technologies, Universitat Pompeu Fabra, Barcelona, Spain.
(4)Centre de Recerca Matemàtica, Barcelona, Spain.
(5)Barcelona Graduate School of Mathematics, Barcelona, Spain.
(6)Department of Radiology, Centre Hospitalier Universitaire Vaudois, Lausanne, 
Switzerland.
(7)Institució Catalana de la Recerca i Estudis Avançats (ICREA), Barcelona, 
Spain.
(8)Department of Neuropsychology, Max Planck Institute for Human Cognitive and 
Brain Sciences, Leipzig, Germany.
(9)School of Psychological Sciences, Monash University, Melbourne, Victoria, 
Australia.

The grouping of sensory stimuli into categories is fundamental to cognition. 
Previous research in the visual and auditory systems supports a two-stage 
processing hierarchy that underlies perceptual categorization: (a) a "bottom-up" 
perceptual stage in sensory cortices where neurons show selectivity for stimulus 
features and (b) a "top-down" second stage in higher level cortical areas that 
categorizes the stimulus-selective input from the first stage. In order to test 
the hypothesis that the two-stage model applies to the somatosensory system, 14 
human participants were trained to categorize vibrotactile stimuli presented to 
their right forearm. Then, during an fMRI scan, participants actively 
categorized the stimuli. Representational similarity analysis revealed stimulus 
selectivity in areas including the left precentral and postcentral gyri, the 
supramarginal gyrus, and the posterior middle temporal gyrus. Crucially, we 
identified a single category-selective region in the left ventral precentral 
gyrus. Furthermore, an estimation of directed functional connectivity delivered 
evidence for robust top-down connectivity from the second to first stage. These 
results support the validity of the two-stage model of perceptual categorization 
for the somatosensory system, suggesting common computational principles and a 
unified theory of perceptual categorization across the visual, auditory, and 
somatosensory systems.

© 2019 Wiley Periodicals, Inc.

DOI: 10.1002/hbm.24581
PMCID: PMC6865665
PMID: 30920706 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing conflict of 
interest.


141. Elife. 2019 Mar 7;8:e41861. doi: 10.7554/eLife.41861.

Neural dynamics of visual ambiguity resolution by perceptual prior.

Flounders MW(1), González-García C(2), Hardstone R(1), He BJ(1)(3)(4)(5).

Author information:
(1)Neuroscience Institute, New York University Langone Medical Center, New York, 
United States.
(2)Department of Experimental Psychology, Ghent University, Ghent, Belgium.
(3)Department of Neurology, New York University Langone Medical Center, New 
York, United States.
(4)Department of Neuroscience and Physiology, New York University Langone 
Medical Center, New York, United States.
(5)Department of Radiology, New York University Langone Medical Center, New 
York, United States.

Past experiences have enormous power in shaping our daily perception. Currently, 
dynamical neural mechanisms underlying this process remain mysterious. 
Exploiting a dramatic visual phenomenon, where a single experience of viewing a 
clear image allows instant recognition of a related degraded image, we 
investigated this question using MEG and 7 Tesla fMRI in humans. We observed 
that following the acquisition of perceptual priors, different degraded images 
are represented much more distinctly in neural dynamics starting from ~500 ms 
after stimulus onset. Content-specific neural activity related to 
stimulus-feature processing dominated within 300 ms after stimulus onset, while 
content-specific neural activity related to recognition processing dominated 
from 500 ms onward. Model-driven MEG-fMRI data fusion revealed the 
spatiotemporal evolution of neural activities involved in stimulus, attentional, 
and recognition processing. Together, these findings shed light on how 
experience shapes perceptual processing across space and time in the brain.

© 2019, Flounders et al.

DOI: 10.7554/eLife.41861
PMCID: PMC6415935
PMID: 30843519 [Indexed for MEDLINE]

Conflict of interest statement: MF, CG, RH, BH No competing interests declared


142. Brain Res. 2019 Jul 1;1714:133-146. doi: 10.1016/j.brainres.2019.02.029. Epub 
2019 Feb 27.

Processing symbolic and non-symbolic proportions: Domain-specific numerical and 
domain-general processes in intraparietal cortex.

Mock J(1), Huber S(2), Bloechle J(3), Bahnmueller J(4), Moeller K(5), Klein 
E(4).

Author information:
(1)Leibniz-Institut für Wissensmedien, Schleichstraße 6, 72076 Tuebingen, 
Germany. Electronic address: j.mock@iwm-tuebingen.de.
(2)Leibniz-Institut für Wissensmedien, Schleichstraße 6, 72076 Tuebingen, 
Germany.
(3)Leibniz-Institut für Wissensmedien, Schleichstraße 6, 72076 Tuebingen, 
Germany; Hertie-Institute for Clinical Brain Research, Division of 
Neuropsychology, Otfried-Müller-Straße 27, 72076 Tuebingen, Germany; Department 
of Psychiatry and Psychotherapy, University Hospital Tuebingen, Germany.
(4)Leibniz-Institut für Wissensmedien, Schleichstraße 6, 72076 Tuebingen, 
Germany; LEAD Graduate School, University of Tuebingen, 
Geschwister-Scholl-Platz, 72074 Tuebingen, Germany.
(5)Leibniz-Institut für Wissensmedien, Schleichstraße 6, 72076 Tuebingen, 
Germany; Department of Psychology, Eberhardt-Karls University Tuebingen, 
Schleichstraße 4, 72076 Tuebingen, Germany; LEAD Graduate School, University of 
Tuebingen, Geschwister-Scholl-Platz, 72074 Tuebingen, Germany.

Previous studies on the processing of fractions and proportions focused mainly 
on the processing of their overall magnitude information in the intraparietal 
sulcus (IPS). However, the IPS is also associated with domain-general cognitive 
functions beyond processing overall magnitude, which may nevertheless be 
involved in operating on magnitude information of proportions. To pursue this 
issue, the present study aimed at investigating whether there is a shared neural 
correlate for proportion processing in the intraparietal cortex beyond overall 
magnitude processing and how part-whole relations are processed on the neural 
level. Across four presentation formats (i.e., fractions, decimals, dot 
patterns, and pie charts) we observed a shared neural substrate in bilateral 
inferior parietal cortex, slightly anterior and inferior to IPS areas recently 
found for overall magnitude proportion processing. Nevertheless, when evaluating 
the neural correlates of part-whole processing (i.e., contrasting fractions, dot 
patterns, and pie charts vs. decimals), we found wide-spread activation in 
fronto-parietal brain areas. These results indicate involvement of 
domain-general cognitive processes in part-whole processing beyond processing 
the overall magnitude of proportions. The dissociation between proportions 
involving part-whole relations and decimals was further substantiated by a 
representational similarity analysis, which revealed common neural processing 
for fractions, pie charts, and dot patterns, possibly representing their 
bipartite part-whole structure. In contrast, decimals seemed to be processed 
differently on the neural level, possibly reflecting missing processes of actual 
proportion calculation in decimals.

Copyright © 2019 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.brainres.2019.02.029
PMID: 30825420 [Indexed for MEDLINE]


143. Hippocampus. 2019 Nov;29(11):1025-1037. doi: 10.1002/hipo.23082. Epub 2019 Feb 
19.

Focusing on what matters: Modulation of the human hippocampus by relational 
attention.

Córdova NI(1)(2), Turk-Browne NB(2), Aly M(3).

Author information:
(1)Princeton Neuroscience Institute, Princeton University, Princeton, New 
Jersey.
(2)Department of Psychology, Yale University, New Haven, Connecticut.
(3)Department of Psychology, Columbia University, New York City, New York.

Hippocampal episodic memory is fundamentally relational, comprising links 
between events and the spatiotemporal contexts in which they occurred. Such 
relations are also important over shorter timescales, during online perception. 
For example, how do we assess the relative spatial positions of objects, their 
temporal order, or the relationship between their features? Here, we investigate 
the role of the hippocampus in online relational processing by manipulating 
attention to different kinds of relations. While undergoing fMRI, participants 
viewed two images in rapid succession on each trial and performed one of three 
relational tasks, judging the images' relative: spatial positions, temporal 
onsets, or sizes. Additionally, they sometimes judged whether one image was 
tilted, irrespective of the other. This served as a baseline item task with no 
demands on relational processing. The hippocampus showed reliable deactivation 
when participants attended to relational vs. item information. Attention to 
temporal relations was associated with the most robust deactivation. One 
interpretation of such deactivation is that it reflects hippocampal 
disengagement. If true, there should be reduced information content and noisier 
activity patterns for the temporal vs. other tasks. Instead, multivariate 
pattern analysis revealed more stable hippocampal representations in the 
temporal task. This increased pattern similarity was not simply a reflection of 
lower univariate activity. Thus, the hippocampus differentiates between 
relational and item processing even during online perception, and its 
representations of temporal relations are particularly robust. These findings 
suggest that the relational computations of the hippocampus extend beyond 
long-term memory, enabling rapid extraction of relational information in 
perception.

© 2019 Wiley Periodicals, Inc.

DOI: 10.1002/hipo.23082
PMCID: PMC6699927
PMID: 30779473 [Indexed for MEDLINE]


144. Neuropsychologia. 2019 Apr;127:35-47. doi: 
10.1016/j.neuropsychologia.2019.02.006. Epub 2019 Feb 14.

Distinct representations in occipito-temporal, parietal, and premotor cortex 
during action perception revealed by fMRI and computational modeling.

Urgen BA(1), Pehlivan S(2), Saygin AP(3).

Author information:
(1)Department of Psychology, Bilkent University, Ankara, Turkey; National 
Magnetic Resonance Research Center and Aysel Sabuncu Brain Research Center, 
Bilkent University, Ankara, Turkey; Graduate School of Science and Engineering, 
Interdisciplinary Neuroscience Program, Bilkent University, Ankara, Turkey. 
Electronic address: burcu.urgen@bilkent.edu.tr.
(2)Department of Computer Engineering, TED University, Ankara, Turkey. 
Electronic address: selen.pehlivan@tedu.edu.tr.
(3)Department of Cognitive Science, UC San Diego, La Jolla, CA, USA; 
Neurosciences Program, UC San Diego, La Jolla, CA, USA. Electronic address: 
asaygin@cogsci.ucsd.edu.

Visual processing of actions is supported by a network consisting of 
occipito-temporal, parietal, and premotor regions in the human brain, known as 
the Action Observation Network (AON). In the present study, we investigate what 
aspects of visually perceived actions are represented in this network using fMRI 
and computational modeling. Human subjects performed an action perception task 
during scanning. We characterized the different aspects of the stimuli starting 
from purely visual properties such as form and motion to higher-aspects such as 
intention using computer vision and categorical modeling. We then linked the 
models of the stimuli to the three nodes of the AON with representational 
similarity analysis. Our results show that different nodes of the network 
represent different aspects of actions. While occipito-temporal cortex performs 
visual analysis of actions by means of integrating form and motion information, 
parietal cortex builds on these visual representations and transforms them into 
more abstract and semantic representations coding target of the action, action 
type and intention. Taken together, these results shed light on the 
neuro-computational mechanisms that support visual perception of actions and 
provide support that AON is a hierarchical system in which increasing levels of 
the cortex code increasingly complex features.

Copyright © 2019 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2019.02.006
PMID: 30772426 [Indexed for MEDLINE]


145. Neuroimage. 2019 May 1;191:234-242. doi: 10.1016/j.neuroimage.2019.02.029. Epub 
2019 Feb 13.

Directional tuning for eye and arm movements in overlapping regions in human 
posterior parietal cortex.

Magri C(1), Fabbri S(2), Caramazza A(3), Lingnau A(4).

Author information:
(1)Center for Mind/Brain Sciences (CIMeC), University of Trento, Italy; 
Department of Cognitive Science, University of Trento, Italy; Department of 
Psychology, Harvard University, Cambridge, MA, USA.
(2)Center for Mind/Brain Sciences (CIMeC), University of Trento, Italy; 
Department of Experimental Psychology, Faculty of Behavioural and Social 
Sciences, University of Groningen, the Netherlands.
(3)Center for Mind/Brain Sciences (CIMeC), University of Trento, Italy; 
Department of Psychology, Harvard University, Cambridge, MA, USA.
(4)Center for Mind/Brain Sciences (CIMeC), University of Trento, Italy; 
Department of Cognitive Science, University of Trento, Italy; Department of 
Psychology, Royal Holloway University of London, UK. Electronic address: 
angelika.lingnau@psychologie.uni-regensburg.de.

A network of frontal and parietal regions is known to be recruited during the 
planning and execution of arm and eye movements. While movements of the two 
effectors are typically coupled with each other, it remains unresolved how 
information is shared between them. Here we aimed to identify regions containing 
neuronal populations that show directional tuning for both arm and eye 
movements. In two separate fMRI experiments, the same participants were scanned 
while performing a center-out arm or eye movement task. Using a whole-brain 
searchlight-based representational similarity analysis (RSA), we found that a 
bilateral region in the posterior superior parietal lobule represents both arm 
and eye movement direction, thus extending previous findings in monkeys.

Copyright © 2019 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2019.02.029
PMID: 30769145 [Indexed for MEDLINE]


146. Cereb Cortex. 2019 Dec 17;29(11):4775-4784. doi: 10.1093/cercor/bhz010.

The Neural Dynamics of Familiar Face Recognition.

Ambrus GG(1), Kaiser D(2), Cichy RM(2)(3)(4), Kovács G(1).

Author information:
(1)Institute of Psychology, Friedrich Schiller University Jena, Leutragraben 1, 
Jena, Germany.
(2)Department of Education and Psychology, Freie Universität Berlin, 
Habelschwerdter Allee 45, Berlin, Germany.
(3)Berlin School of Mind and Brain, Humboldt-Universität Berlin, Luisenstraβe 
56, Haus 1, Berlin, Germany.
(4)Bernstein Center for Computational Neuroscience Berlin, Philippstraβe 13/Haus 
6, Berlin, Germany.

In real-life situations, the appearance of a person's face can vary 
substantially across different encounters, making face recognition a challenging 
task for the visual system. Recent fMRI decoding studies have suggested that 
face recognition is supported by identity representations located in regions of 
the occipitotemporal cortex. Here, we used EEG to elucidate the temporal 
emergence of these representations. Human participants viewed a set of highly 
variable face images of 4 highly familiar celebrities (2 males and 2 females), 
while performing an orthogonal task. Univariate analyses of event-related EEG 
responses revealed a pronounced differentiation between male and female faces, 
but not between identities of the same sex. Using multivariate representational 
similarity analysis, we observed a gradual emergence of face identity 
representations, with an increasing degree of invariance. Face identity 
information emerged rapidly, starting shortly after 100 ms from stimulus onset, 
but was modulated by sex differences and image similarities. From 400 ms after 
onset and predominantly in the right hemisphere, identity representations showed 
2 invariance properties: 1) they equally discriminated identities of opposite 
sexes and of the same sex, and 2) they were tolerant to image-based variations. 
These invariant representations may be a crucial prerequisite for successful 
face recognition in everyday situations, where the appearance of a familiar 
person can vary drastically.

© The Author(s) 2019. Published by Oxford University Press. All rights reserved. 
For Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhz010
PMID: 30753332 [Indexed for MEDLINE]


147. Elife. 2019 Feb 5;8:e37227. doi: 10.7554/eLife.37227.

Obtaining and maintaining cortical hand representation as evidenced from 
acquired and congenital handlessness.

Wesselink DB(#)(1)(2), van den Heiligenberg FM(#)(1)(2), Ejaz N(3)(4), 
Dempsey-Jones H(1)(2), Cardinali L(3)(5), Tarall-Jozwiak A(6), Diedrichsen 
J(3)(4), Makin TR(1)(2)(7).

Author information:
(1)Institute of Cognitive Neuroscience, University College London, London, 
United Kingdom.
(2)Wellcome Centre for Integrative Neuroimaging, University of Oxford, Oxford, 
United Kingdom.
(3)Brain and Mind Institute, University of Western Ontario, London, Canada.
(4)Department of Computer Science, University of Western Ontario, London, 
Canada.
(5)Unit for Visually Impaired People, Istituto Italiano di Tecnologia, Genoa, 
Italy.
(6)Queen Mary's Hospital, London, United Kingdom.
(7)Wellcome Centre for Human Neuroimaging, University College London, London, 
United Kingdom.
(#)Contributed equally

A key question in neuroscience is how cortical organisation relates to 
experience. Previously we showed that amputees experiencing highly vivid phantom 
sensations maintain cortical representation of their missing hand (Kikkert et 
al., 2016). Here, we examined the role of sensory hand experience on persistent 
hand representation by studying individuals with acquired and congenital hand 
loss. We used representational similarity analysis in primary somatosensory and 
motor cortex during missing and intact hand movements. We found that key aspects 
of acquired amputees' missing hand representation persisted, despite varying 
vividness of phantom sensations. In contrast, missing hand representation of 
congenital one-handers, who do not experience phantom sensations, was 
significantly reduced. Across acquired amputees, individuals' reported motor 
control over their phantom hand positively correlated with the extent to which 
their somatosensory hand representation was normally organised. We conclude that 
once cortical organisation is formed, it is remarkably persistent, despite 
long-term attenuation of peripheral signals.

© 2019, Wesselink et al.

DOI: 10.7554/eLife.37227
PMCID: PMC6363469
PMID: 30717824 [Indexed for MEDLINE]

Conflict of interest statement: DW, Fv, NE, HD, LC, AT No competing interests 
declared, JD, TM Member of eLife BRE


148. Open Mind (Camb). 2019 Feb 1;3:1-12. doi: 10.1162/opmi_a_00021. eCollection 
2019.

The Neural Representational Space of Social Memory.

Dziura SL(1), Thompson JC(1).

Author information:
(1)Department of Psychology, George Mason University, Fairfax, VA, 22030 USA.

Social functioning involves learning about the social networks in which we live 
and interact; knowing not just our friends, but also who is friends with our 
friends. This study utilized an incidental learning paradigm and 
representational similarity analysis (RSA), a functional MRI multivariate 
pattern analysis technique, to examine the relationship between learning social 
networks and the brain's response to the faces within the networks. We found 
that accuracy of learning face pair relationships through observation is 
correlated with neural similarity patterns to those pairs in the left 
temporoparietal junction (TPJ), the left fusiform gyrus, and the subcallosal 
ventromedial prefrontal cortex (vmPFC), all areas previously implicated in 
social cognition. This model was also significant in portions of the cerebellum 
and thalamus. These results show that the similarity of neural patterns 
represent how accurately we understand the closeness of any two faces within a 
network. Our findings indicate that these areas of the brain not only process 
knowledge and understanding of others, but also support learning relations 
between individuals in groups.

© 2018 Massachusetts Institute of Technology.

DOI: 10.1162/opmi_a_00021
PMCID: PMC8412184
PMID: 34485787

Conflict of interest statement: Competing Interests: The authors have declared 
that no competing interests exist.


149. Front Hum Neurosci. 2018 Oct 18;12:419. doi: 10.3389/fnhum.2018.00419. 
eCollection 2018.

Abstract Representations of Emotions Perceived From the Face, Body, and 
Whole-Person Expressions in the Left Postcentral Gyrus.

Cao L(1), Xu J(1), Yang X(1), Li X(2), Liu B(1)(3).

Author information:
(1)School of Computer Science and Technology, Tianjin Key Laboratory of 
Cognitive Computing and Application, Tianjin University, Tianjin, China.
(2)Medical Imaging Research Institute, Binzhou Medical University, Yantai, 
China.
(3)State Key Laboratory of Intelligent Technology and Systems, Tsinghua National 
Laboratory for Information Science and Technology, Tsinghua University, Beijing, 
China.

Emotions can be perceived through the face, body, and whole-person, while 
previous studies on the abstract representations of emotions only focused on the 
emotions of the face and body. It remains unclear whether emotions can be 
represented at an abstract level regardless of all three sensory cues in 
specific brain regions. In this study, we used the representational similarity 
analysis (RSA) to explore the hypothesis that the emotion category is 
independent of all three stimulus types and can be decoded based on the activity 
patterns elicited by different emotions. Functional magnetic resonance imaging 
(fMRI) data were collected when participants classified emotions (angry, 
fearful, and happy) expressed by videos of faces, bodies, and whole-persons. An 
abstract emotion model was defined to estimate the neural representational 
structure in the whole-brain RSA, which assumed that the neural patterns were 
significantly correlated in within-emotion conditions ignoring the stimulus 
types but uncorrelated in between-emotion conditions. A neural representational 
dissimilarity matrix (RDM) for each voxel was then compared to the abstract 
emotion model to examine whether specific clusters could identify the abstract 
representation of emotions that generalized across stimulus types. The 
significantly positive correlations between neural RDMs and models suggested 
that the abstract representation of emotions could be successfully captured by 
the representational space of specific clusters. The whole-brain RSA revealed an 
emotion-specific but stimulus category-independent neural representation in the 
left postcentral gyrus, left inferior parietal lobe (IPL) and right superior 
temporal sulcus (STS). Further cluster-based MVPA revealed that only the left 
postcentral gyrus could successfully distinguish three types of emotions for the 
two stimulus type pairs (face-body and body-whole person) and happy versus 
angry/fearful, which could be considered as positive versus negative for three 
stimulus type pairs, when the cross-modal classification analysis was performed. 
Our study suggested that abstract representations of three emotions (angry, 
fearful, and happy) could extend from the face and body stimuli to whole-person 
stimuli and the findings of this study provide support for abstract 
representations of emotions in the left postcentral gyrus.

DOI: 10.3389/fnhum.2018.00419
PMCID: PMC6200969
PMID: 30405375


150. Neuroimage. 2019 Feb 1;186:155-163. doi: 10.1016/j.neuroimage.2018.11.002. Epub 
2018 Nov 2.

Stability of representational geometry across a wide range of fMRI activity 
levels.

Arbuckle SA(1), Yokoi A(2), Pruszynski JA(3), Diedrichsen J(4).

Author information:
(1)Brain and Mind Institute, Western University, Canada.
(2)Graduate School of Frontier Biosciences, Osaka University, Japan; Center for 
Information and Neural Networks (CiNet), National Institute of Information and 
Communications Technology, Osaka, Japan.
(3)Brain and Mind Institute, Western University, Canada; Department of 
Physiology and Pharmacology, Western University, Canada; Department of 
Psychology, Western University, Canada; Robarts Research Institute, Western 
University, Canada.
(4)Brain and Mind Institute, Western University, Canada; Department of 
Statistical and Actuarial Sciences, Western University, Canada; Department of 
Computer Science, Western University, Canada. Electronic address: 
jdiedric@uwo.ca.

Fine-grained activity patterns, as measured with functional magnetic resonance 
imaging (fMRI), are thought to reflect underlying neural representations. 
Multivariate analysis techniques, such as representational similarity analysis 
(RSA), can be used to test models of brain representation by quantifying the 
representational geometry (the collection of pair-wise dissimilarities between 
activity patterns). One important caveat, however, is that non-linearities in 
the coupling between neural activity and the fMRI signal may lead to significant 
distortions in the representational geometry estimated from fMRI activity 
patterns. Here we tested the stability of representational dissimilarity 
measures in primary sensory-motor (S1 and M1) and early visual regions (V1/V2) 
across a large range of activation levels. Participants were visually cued with 
different letters to perform single finger presses with one of the 5 fingers at 
a rate of 0.3-2.6 Hz. For each stimulation frequency, we quantified the 
difference between the 5 activity patterns in M1, S1, and V1/V2. We found that 
the representational geometry remained relatively stable, even though the 
average activity increased over a large dynamic range. These results indicate 
that the representational geometry of fMRI activity patterns can be reliably 
assessed, largely independent of the average activity in the region. This has 
important methodological implications for RSA and other multivariate analysis 
approaches that use the representational geometry to make inferences about brain 
representations.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2018.11.002
PMID: 30395930 [Indexed for MEDLINE]


151. J Neurosci. 2019 Jan 2;39(1):140-148. doi: 10.1523/JNEUROSCI.1431-18.2018. Epub 
2018 Nov 2.

The Social Brain Automatically Predicts Others' Future Mental States.

Thornton MA(1)(2), Weaverdyck ME(3), Tamir DI(3)(2).

Author information:
(1)Department of Psychology and mthornto@princeton.edu.
(2)Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey 
08540.
(3)Department of Psychology and.

Social life requires people to predict the future: people must anticipate 
others' thoughts, feelings, and actions to interact with them successfully. The 
theory of predictive coding suggests that the social brain may meet this need by 
automatically predicting others' social futures. If so, when representing 
others' current mental state, the brain should already start representing their 
future states. To test this hypothesis, we used fMRI to measure female and male 
human participants' neural representations of mental states. Representational 
similarity analysis revealed that neural patterns associated with mental states 
currently under consideration resembled patterns of likely future states more so 
than patterns of unlikely future states. This effect manifested in activity 
across the social brain network and in medial prefrontal cortex in particular. 
Repetition suppression analysis also supported the social predictive coding 
hypothesis: considering mental states presented in predictable sequences reduced 
activity in the precuneus relative to unpredictable sequences. In addition to 
demonstrating that the brain makes automatic predictions of others' social 
futures, the results also demonstrate that the brain leverages a 3D 
representational space to make these predictions. Proximity between mental 
states on the psychological dimensions of rationality, social impact, and 
valence explained much of the association between state-specific neural pattern 
similarity and state transition likelihood. Together, these findings suggest 
that the way the brain represents the social present gives people an automatic 
glimpse of the social future.SIGNIFICANCE STATEMENT When you see a ball in 
flight, your brain calculates, not just its static visual features such as size 
and shape, but also predicts its future trajectory. Here, we investigated 
whether the same might hold true in the social world: when we see someone flying 
into a rage, does our brain automatically predict their social trajectory? In 
this study, we scanned participants' brain activity while they judged others' 
mental states. We found that neural activity associated with a given state 
resembled activity associated with likely future states. Additionally, 
unpredictable sequences of states evoked more brain activity than predictable 
sequences, consistent with monitoring for, and updating from, prediction errors. 
These results suggest that the social brain automatically predicts others' 
future mental states.

Copyright © 2019 the authors 0270-6474/19/390140-09$15.00/0.

DOI: 10.1523/JNEUROSCI.1431-18.2018
PMCID: PMC6325264
PMID: 30389840 [Indexed for MEDLINE]


152. Neuropsychologia. 2018 Nov;120:35-42. doi: 
10.1016/j.neuropsychologia.2018.10.008. Epub 2018 Oct 12.

The neural representation of an individualized relational affective space.

Levine SM(1), Wackerle A(2), Rupprecht R(2), Schwarzbach JV(3).

Author information:
(1)Department of Psychiatry and Psychotherapy, University of Regensburg, 93053 
Regensburg, Germany. Electronic address: seth.levine@ukr.de.
(2)Department of Psychiatry and Psychotherapy, University of Regensburg, 93053 
Regensburg, Germany.
(3)Department of Psychiatry and Psychotherapy, University of Regensburg, 93053 
Regensburg, Germany. Electronic address: jens.schwarzbach@ukr.de.

Humans experience emotions every day. Traditionally, psychology has described 
emotions through discrete labels (e.g. happy, afraid) or standardized affective 
dimensions (e.g. valence, arousal), and neuroscience has more recently sought 
the neurobiological basis of emotions via functional neuroimaging. However, by 
treating emotions similarly among everyone, we neglect that emotions are 
individualized; thus the overall relational structure of an individual's emotion 
information may be vital in understanding how the brain represents emotions. 
Combining behavioral and functional MRI experiments with similarity analyses, we 
demonstrate that neural activity patterns in the left insula correspond to the 
multi-dimensional arrangement of individuals' affective spaces, despite 
interindividual differences, better than to a group-averaged model of affective 
space, a standardized valence-arousal space, a semantic category space, and a 
visual similarity space. This finding suggests that the insula may underlie 
individual-level affective information processing that is specific to one's own 
affective states, which offers new opportunities for functional neuroimaging to 
inform clinical approaches of disorders involving emotion dysregulation.

Copyright © 2018 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2018.10.008
PMID: 30321612 [Indexed for MEDLINE]


153. Sci Rep. 2018 Oct 8;8(1):14899. doi: 10.1038/s41598-018-32879-0.

The experience of vivid autobiographical reminiscence is supported by subjective 
content representations in the precuneus.

Sreekumar V(1)(2), Nielson DM(1)(3), Smith TA(4), Dennis SJ(5), Sederberg 
PB(6)(7).

Author information:
(1)Department of Psychology, The Ohio State University, Columbus, OH, USA.
(2)Surgical Neurology Branch, NINDS, National Institutes of Health, Bethesda, 
MD, 20892, USA.
(3)Data Science and Sharing Team, Section on Functional Imaging Methods, 
Laboratory of Brain and Cognition, NIMH, National Institutes of Health, 
Bethesda, MD, 20892, USA.
(4)Department of Psychological Science, University of North Georgia, Oakwood, 
GA, 30566, USA.
(5)School of Psychology, University of Melbourne, Melbourne, VIC, Australia.
(6)Department of Psychology, The Ohio State University, Columbus, OH, USA. 
pbs5u@virginia.edu.
(7)Department of Psychology, University of Virginia, Charlottesville, VA, 22903, 
USA. pbs5u@virginia.edu.

The human posteromedial cortex, which includes core regions of the default mode 
network (DMN), is thought to play an important role in episodic memory. However, 
the nature and functional role of representations in these brain regions remain 
unspecified. Nine participants (all female) wore smartphone devices to record 
episodes from their daily lives for multiple weeks, each night indicating the 
personally-salient attributes of each episode. Participants then relived their 
experiences in an fMRI scanner cued by images from their own lives. 
Representational Similarity Analysis revealed a broad network, including parts 
of the DMN, that represented personal semantics during autobiographical 
reminiscence. Within this network, activity in the right precuneus reflected 
more detailed representations of subjective contents during vivid relative to 
non-vivid, recollection. Our results suggest a more specific mechanism 
underlying the phenomenology of vivid autobiographical reminiscence, supported 
by rich subjective content representations in the precuneus, a hub of the DMN 
previously implicated in metacognitive evaluations during memory retrieval.

DOI: 10.1038/s41598-018-32879-0
PMCID: PMC6175904
PMID: 30297824 [Indexed for MEDLINE]

Conflict of interest statement: Professor Dennis is the CEO of a startup called 
Unforgettable Technologies Pty Ltd (UT) that specializes in providing privacy 
preserving experience sampling collection and analysis services. The other 
authors declare no potential conflict of interest.


154. Proc Natl Acad Sci U S A. 2018 Oct 23;115(43):11084-11089. doi: 
10.1073/pnas.1800006115. Epub 2018 Oct 8.

Neural reactivation in parietal cortex enhances memory for episodically linked 
information.

Jonker TR(1), Dimsdale-Zucker H(2), Ritchey M(3), Clarke A(4)(5), Ranganath 
C(2).

Author information:
(1)Center for Neuroscience, University of California, Davis, CA 95616; 
tanyarjonker@gmail.com.
(2)Center for Neuroscience, University of California, Davis, CA 95616.
(3)Department of Psychology, Boston College, Chestnut Hill, MA 02467.
(4)Department of Psychology, University of Cambridge, Cambridge CB2 3EB, United 
Kingdom.
(5)Department of Psychology, Anglia Ruskin University, Cambridge CB1 1PT, United 
Kingdom.

Remembering is a complex process that involves recalling specific details, such 
as who you were with when you celebrated your last birthday, as well as 
contextual information, such as the place where you celebrated. It is well 
established that the act of remembering enhances long-term retention of the 
retrieved information, but the neural and cognitive mechanisms that drive memory 
enhancement are not yet understood. One possibility is that the process of 
remembering results in reactivation of the broader episodic context. Consistent 
with this idea, in two experiments, we found that multiple retrieval attempts 
enhanced long-term retention of both the retrieved object and the nontarget 
object that shared scene context, compared with a restudy control. Using 
representational similarity analysis of fMRI data in experiment 2, we found that 
retrieval resulted in greater neural reactivation of both the target objects and 
contextually linked objects compared with restudy. Furthermore, this 
reactivation occurred in a network of medial and lateral parietal lobe regions 
that have been linked to episodic recollection. The results demonstrate that 
retrieving a memory can enhance retention of information that is linked in the 
broader event context and the hippocampus and a posterior medial network of 
parietal cortical areas (also known as the Default Network) play complementary 
roles in supporting the reactivation of episodically linked information during 
retrieval.

DOI: 10.1073/pnas.1800006115
PMCID: PMC6205442
PMID: 30297400 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


155. Cortex. 2019 May;114:17-27. doi: 10.1016/j.cortex.2018.07.017. Epub 2018 Jul 31.

Processing number and length in the parietal cortex: Sharing resources, not a 
common code.

Borghesani V(1), de Hevia MD(2), Viarouge A(3), Pinheiro-Chagas P(4), Eger E(5), 
Piazza M(6).

Author information:
(1)Université Pierre et Marie Curie, Paris, France; Cognitive Neuroimaging Unit, 
CEA DRF/I2BM, INSERM, Université Paris-Sud, Université Paris-Saclay, NeuroSpin 
center, Gif/Yvette, France; Center for Mind/Brain Sciences, University of 
Trento, Italy. Electronic address: valentinaborghesani@gmail.com.
(2)Université Paris Descartes, Paris, France; Laboratoire Psychologie de la 
Perception, Paris, France. Electronic address: dehevialola@gmail.com.
(3)Laboratory for the Psychology of Child Development and Education, University 
Paris Descartes, USPC, Paris, France. Electronic address: arnaud.via@gmail.com.
(4)Université Pierre et Marie Curie, Paris, France; Cognitive Neuroimaging Unit, 
CEA DRF/I2BM, INSERM, Université Paris-Sud, Université Paris-Saclay, NeuroSpin 
center, Gif/Yvette, France. Electronic address: ppinheirochagas@gmail.com.
(5)Cognitive Neuroimaging Unit, CEA DRF/I2BM, INSERM, Université Paris-Sud, 
Université Paris-Saclay, NeuroSpin center, Gif/Yvette, France. Electronic 
address: evelyn.eger@gmail.com.
(6)Cognitive Neuroimaging Unit, CEA DRF/I2BM, INSERM, Université Paris-Sud, 
Université Paris-Saclay, NeuroSpin center, Gif/Yvette, France; Center for 
Mind/Brain Sciences, University of Trento, Italy. Electronic address: 
manuela.piazza@gmail.com.

A current intense discussion in numerical cognition concerns the relationship 
between the processing of numerosity and other non-numerical quantities. In 
particular, it is a matter of debate whether number and other quantities (e.g., 
size, length) are represented separately in the brain or whether they share a 
common generalized magnitude representation. We acquired high-resolution 
functional MRI data while adult subjects engaged in a magnitude comparison task 
involving either numerosity (i.e., which of the two sets has more elements?) or 
line length (i.e., which of the two lines is longer?). We compared the 
activation evoked by the two different types of quantity and observed a common 
recruitment of a vast portion of occipital and parietal cortices. Using MVPA, we 
demonstrated that some of the commonly activated regions represented the 
discrete and continuous quantities via a similar distance-dependent magnitude 
code. However, we found no effect of distance across the two quantity 
representations, failing to support the existence of a common, dimension 
invariant, generalized quantity code. Taken together, these findings indicate 
that although the processing of number and length is supported by partially 
overlapping neural resources, representations within these regions do not appear 
to be based on a common neural code.

Copyright © 2018 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cortex.2018.07.017
PMID: 30219571 [Indexed for MEDLINE]


156. Neuroimage. 2019 Jan 1;184:161-170. doi: 10.1016/j.neuroimage.2018.09.010. Epub 
2018 Sep 12.

Shared understanding of narratives is correlated with shared neural responses.

Nguyen M(1), Vanderwal T(2), Hasson U(3).

Author information:
(1)Department of Psychology, Princeton University, Princeton, NJ, 08540, USA. 
Electronic address: mlnguyen@princeton.edu.
(2)Yale Child Study Center, Yale University, 230 S Frontage Rd, New Haven, CT, 
06520, USA.
(3)Department of Psychology, Princeton University, Princeton, NJ, 08540, USA; 
Princeton Neuroscience Institute, Princeton University, Princeton, NJ, 08540, 
USA.

Humans have a striking ability to infer meaning from even the sparsest and most 
abstract forms of narratives. At the same time, flexibility in the form of a 
narrative is matched by inherent ambiguity in its interpretation. How does the 
brain represent subtle, idiosyncratic differences in the interpretation of 
abstract and ambiguous narratives? In this fMRI study, subjects were scanned 
either watching a novel 7-min animation depicting a complex narrative through 
the movement of geometric shapes, or listening to a narration of the animation's 
social story. Using an intersubject representational similarity analysis that 
compared interpretation similarity and neural similarity across subjects, we 
found that the more similar two people's interpretations of the abstract shapes 
animation were, the more similar were their neural responses in regions of the 
default mode network (DMN) and fronto-parietal network. Moreover, these shared 
responses were modality invariant: the shapes movie and the verbal 
interpretation of the movie elicited shared responses in linguistic areas and a 
subset of the DMN when subjects shared interpretations. Together, these results 
suggest a network of high-level regions that are not only sensitive to subtle 
individual differences in narrative interpretation during naturalistic 
conditions, but also resilient to large differences in the modality of the 
narrative.

Copyright © 2018 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2018.09.010
PMCID: PMC6287615
PMID: 30217543 [Indexed for MEDLINE]

Conflict of interest statement: Declarations of interest: none


157. Neuroimage. 2018 Dec;183:627-634. doi: 10.1016/j.neuroimage.2018.08.066. Epub 
2018 Aug 29.

Creatures great and small: Real-world size of animals predicts visual cortex 
representations beyond taxonomic category.

Coutanche MN(1), Koch GE(2).

Author information:
(1)Department of Psychology, University of Pittsburgh, Pittsburgh, PA, USA; 
Learning, Research & Development Center, University of Pittsburgh, Pittsburgh, 
PA, USA; Brain Institute, University of Pittsburgh, Pittsburgh, PA, USA. 
Electronic address: marc.coutanche@pitt.edu.
(2)Department of Psychology, University of Pittsburgh, Pittsburgh, PA, USA; 
Learning, Research & Development Center, University of Pittsburgh, Pittsburgh, 
PA, USA.

Human occipitotemporal cortex contains neural representations for a variety of 
perceptual and conceptual features. We report a study examining neural 
representations of real-world size along the visual ventral stream, while 
carefully accounting for taxonomic categories that typically co-vary with size. 
We recorded brain activity during a functional Magnetic Resonance Imaging (fMRI) 
scan from eighteen participants as they were presented with images of twelve 
animal species. The animals were selected to vary on a number of dimensions, 
including taxonomic group, real-world size and prior familiarity. We apply 
multivariate analysis methods, including representational similarity analysis 
(RSA) and machine learning classifiers, to probe the distributed patterns of 
neural activity evoked by these presentations. We find that the real-world size 
of visually presented animate items is represented in posterior, but not 
anterior, regions of the ventral stream. A significant linear relationship is 
present for real-world size representation along the ventral stream. These 
representations remain after controlling for factors such as taxonomic category, 
familiarity and models of visual similarity, and even after restricting 
examinations to within-taxonomic category comparisons, suggesting that size 
information is found for within, as well as between, taxonomic categories. These 
findings are consistent with real-world size having an influence on activity 
patterns in early regions of the visual system.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2018.08.066
PMID: 30170151 [Indexed for MEDLINE]


158. Neuroimage. 2018 Dec;183:606-616. doi: 10.1016/j.neuroimage.2018.08.064. Epub 
2018 Aug 28.

GLMdenoise improves multivariate pattern analysis of fMRI data.

Charest I(1), Kriegeskorte N(2), Kay KN(3).

Author information:
(1)School of Psychology, University of Birmingham, UK; Medical Research Council 
Cognition and Brain Sciences Unit, University of Cambridge, UK. Electronic 
address: i.charest@bham.ac.uk.
(2)Medical Research Council Cognition and Brain Sciences Unit, University of 
Cambridge, UK; Department of Psychology, Zuckerman Mind Brain Behavior 
Institute, Columbia University, USA.
(3)Center for Magnetic Resonance Research (CMRR), Department of Radiology, 
University of Minnesota, USA.

GLMdenoise is a denoising technique for task-based fMRI. In GLMdenoise, 
estimates of spatially correlated noise (which may be physiological, 
instrumental, motion-related, or neural in origin) are derived from the data and 
incorporated as nuisance regressors in a general linear model (GLM) analysis. We 
previously showed that GLMdenoise outperforms a variety of other denoising 
techniques in terms of cross-validation accuracy of GLM estimates (Kay et al., 
2013a). However, the practical impact of denoising for experimental studies 
remains unclear. Here we examine whether and to what extent GLMdenoise improves 
sensitivity in the context of multivariate pattern analysis of fMRI data. On a 
large number of participants (31 participants across 4 experiments; 3 T, 
gradient-echo, spatial resolution 2-3.75 mm, temporal resolution 1.3-2 s, number 
of conditions 32-75), we perform representational similarity analysis 
(Kriegeskorte et al., 2008a) as well as pattern classification (Haxby et al., 
2001). We find that GLMdenoise substantially improves replicability of 
representational dissimilarity matrices (RDMs) across independent splits of each 
participant's dataset (average RDM replicability increases from r = 0.46 to 
r = 0.61). Additionally, we find that GLMdenoise substantially improves pairwise 
classification accuracy (average classification accuracy increases from 79% 
correct to 84% correct). We show that GLMdenoise often improves and never 
degrades performance for individual participants and that GLMdenoise also 
improves across-participant consistency. We conclude that GLMdenoise is a useful 
tool that can be routinely used to maximize the amount of information extracted 
from fMRI activity patterns.

Copyright © 2018 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2018.08.064
PMCID: PMC6215334
PMID: 30170148 [Indexed for MEDLINE]


159. Proc Natl Acad Sci U S A. 2018 Sep 11;115(37):9318-9323. doi: 
10.1073/pnas.1721259115. Epub 2018 Aug 27.

Default mode network can support the level of detail in experience during active 
task states.

Sormaz M(1), Murphy C(2), Wang HT(2), Hymers M(2), Karapanagiotidis T(2), Poerio 
G(3), Margulies DS(4), Jefferies E(2), Smallwood J(1).

Author information:
(1)Department of Psychology, University of York, Heslington, York YO10 5DD, 
United Kingdom; mladen.sormaz@york.ac.uk smallwoodjm@gmail.com.
(2)Department of Psychology, University of York, Heslington, York YO10 5DD, 
United Kingdom.
(3)Department of Psychology, The University of Sheffield, Western Bank, 
Sheffield S10 2TN, United Kingdom.
(4)Centre National de la Recherche Scientifique (CNRS) UMR 7225, Frontlab, 
Institut du Cerveau et de la Moelle Épinière, Paris, France.

Erratum in
    Proc Natl Acad Sci U S A. 2018 Nov 20;115(47):E11198.

Regions of transmodal cortex, in particular the default mode network (DMN), have 
historically been argued to serve functions unrelated to task performance, in 
part because of associations with naturally occurring periods of off-task 
thought. In contrast, contemporary views of the DMN suggest it plays an 
integrative role in cognition that emerges from its location at the top of a 
cortical hierarchy and its relative isolation from systems directly involved in 
perception and action. The combination of these topographical features may allow 
the DMN to support abstract representations derived from lower levels in the 
hierarchy and so reflect the broader cognitive landscape. To investigate these 
contrasting views of DMN function, we sampled experience as participants 
performed tasks varying in their working-memory load while inside an fMRI 
scanner. We used self-report data to establish dimensions of thought that 
describe levels of detail, the relationship to a task, the modality of thought, 
and its emotional qualities. We used representational similarity analysis to 
examine correspondences between patterns of neural activity and each dimension 
of thought. Our results were inconsistent with a task-negative view of DMN 
function. Distinctions between on- and off-task thought were associated with 
patterns of consistent neural activity in regions adjacent to unimodal cortex, 
including motor and premotor cortex. Detail in ongoing thought was associated 
with patterns of activity within the DMN during periods of working-memory 
maintenance. These results demonstrate a contribution of the DMN to ongoing 
cognition extending beyond task-unrelated processing that can include detailed 
experiences occurring under active task conditions.

Copyright © 2018 the Author(s). Published by PNAS.

DOI: 10.1073/pnas.1721259115
PMCID: PMC6140531
PMID: 30150393 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


160. Hum Brain Mapp. 2019 Jan;40(1):98-109. doi: 10.1002/hbm.24357. Epub 2018 Aug 23.

Lexical learning in a new language leads to neural pattern similarity with word 
reading in native language.

Li H(1), Qu J(1), Chen C(2), Chen Y(1), Xue G(3), Zhang L(1), Lu C(1), Mei L(1).

Author information:
(1)Guangdong Key Laboratory of Mental Health and Cognitive Science, Center for 
Studies of Psychological Application, and School of Psychology, South China 
Normal University, Guangzhou, China.
(2)Department of Psychological Science, University of California, Irvine, 
California.
(3)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brain Research, Beijing Normal University, Beijing, China.

Previous neuroimaging studies have suggested similar neural activations for word 
reading in native and second languages. However, such similarities were 
qualitatively determined (i.e., overlapping activation based on traditional 
univariate activation analysis). In this study, using representational 
similarity analysis and an artificial language training paradigm, we 
quantitatively computed cross-language neural pattern similarity to examine the 
modulatory effect of proficiency in the new language. Twenty-four native Chinese 
speakers were trained to learn 30 words in a logographic artificial language for 
12 days and scanned while performing a semantic decision task after 4-day 
training and after 12-day training. Results showed that higher proficiency in 
the new language was associated with higher cross-language pattern similarity in 
select regions of the reading network.

© 2018 Wiley Periodicals, Inc.

DOI: 10.1002/hbm.24357
PMCID: PMC6865609
PMID: 30136328 [Indexed for MEDLINE]


161. Brain Struct Funct. 2018 Dec;223(9):4023-4038. doi: 10.1007/s00429-018-1734-x. 
Epub 2018 Aug 17.

Establishing the cognitive signature of human brain networks derived from 
structural and functional connectivity.

Jung J(1), Visser M(2)(3), Binney RJ(2)(4), Lambon Ralph MA(5).

Author information:
(1)Neuroscience and Aphasia Research Unit (NARU), Division of Neuroscience and 
Experimental Psychology, School of Biological Sciences (Zochonis Building), 
University of Manchester, Brunswick Street, Manchester, M13 9PL, UK. 
jeyoung.jung@manchester.ac.uk.
(2)Neuroscience and Aphasia Research Unit (NARU), Division of Neuroscience and 
Experimental Psychology, School of Biological Sciences (Zochonis Building), 
University of Manchester, Brunswick Street, Manchester, M13 9PL, UK.
(3)Grupo de Neuropslcología y NeuroLmagen Functional, University Jaume I, 
Castellón de la Plana, Castellón, Spain.
(4)School of Psychology, Bangor University, Bangor, UK.
(5)Neuroscience and Aphasia Research Unit (NARU), Division of Neuroscience and 
Experimental Psychology, School of Biological Sciences (Zochonis Building), 
University of Manchester, Brunswick Street, Manchester, M13 9PL, UK. 
matt.lambon-ralph@manchester.ac.uk.

Numerous neuroimaging studies have identified various brain networks using 
task-free analyses. While these networks undoubtedly support higher cognition, 
their precise functional characteristics are rarely probed directly. The 
frontal, temporal, and parietal lobes contain the majority of the tertiary 
association cortex, which are key substrates for higher cognition including 
executive function, language, memory, and attention. Accordingly, we established 
the cognitive signature of a set of contrastive brain networks on the main 
tertiary association cortices, identified in two task-independent datasets. 
Using graph-theory analysis, we revealed multiple networks across the frontal, 
temporal, and parietal cortex, derived from structural and functional 
connectivity. The patterns of network activity were then investigated using 
three task-active fMRI datasets to generate the functional profiles of the 
identified networks. We employed representational dissimilarity analysis on 
these functional data to quantify and compare the representational 
characteristics of the networks. Our results demonstrated that the topology of 
the task-independent networks was strongly associated with the patterns of 
network activity in the task-active fMRI. Our findings establish a direct 
relationship between the brain networks identified from task-free datasets and 
higher cognitive functions including cognitive control, language, memory, 
visuospatial function, and perception. Not only does this study support the 
widely held view that higher cognitive functions are supported by widespread, 
distributed cortical networks, but also it elucidates a methodological approach 
for formally establishing their relationship.

DOI: 10.1007/s00429-018-1734-x
PMCID: PMC6267264
PMID: 30120553 [Indexed for MEDLINE]

Conflict of interest statement: CONFLICT OF INTEREST: The authors declare that 
they have no conflict of interest. ETHICAL APPROVAL: All procedures performed in 
studies involving human participants were in accordance with the ethical 
standards of the ethics committee of the University of Manchester and with the 
Helsinki Declaration and its later amendments or comparable ethical standards. 
INFORMED CONSENT: Informed consent was obtained from all individual participants 
included in the study.


162. Neuroimage. 2018 Dec;183:99-111. doi: 10.1016/j.neuroimage.2018.07.062. Epub 
2018 Aug 4.

Putting the pieces together: Generating a novel representational space through 
deductive reasoning.

Alfred KL(1), Connolly AC(2), Kraemer DJM(3).

Author information:
(1)Department of Psychological and Brain Sciences, Dartmouth College, 6207 Moore 
Hall, Hanover, NH, 03755, USA. Electronic address: 
katherinealfred.dartmouth@gmail.com.
(2)Geisel School of Medicine at Dartmouth, 582K01 Borwell, DHMC, NH, 03756, 
Lebanon, USA.
(3)Department of Psychological and Brain Sciences, Dartmouth College, 6207 Moore 
Hall, Hanover, NH, 03755, USA.

How does the brain represent a newly-learned mental model? Representational 
similarity analysis (RSA) has revealed the neural basis of common 
representational spaces learned early in development, such as categories of 
natural kinds. This study uses RSA to examine the neural implementation of a 
newly-learned mental model-i.e., a representational space created through 
deductive reasoning-and study the structure of previously found parietal 
activity in reasoning tasks. Specifically, all the information in this mental 
model could only be obtained through abstract transitive reasoning, as there 
were no predictive differences between observable features in the stimuli, and 
stimuli were counterbalanced across participants. Participants were shown 
unfamiliar face portraits paired with names and asked to learn about the height 
of each person pictured in the portraits through comparison to other individuals 
in the set. Participants learned the relative heights only of adjacent pairs in 
the set and then used transitive reasoning to generate a linear ranking of 
heights (e.g., "Matthew is taller than Thomas; Thomas is taller than Andrew; 
therefore Matthew is taller than Andrew"). During fMRI, participants recalled 
the approximate height of each individual based on these inferences. Using a 
predictive model based on the relative heights of the set of individuals, RSA 
revealed three brain regions in the right hemisphere that encoded this 
newly-learned representational space, located within the intraparietal sulcus, 
precuneus, and inferior frontal gyrus. These findings demonstrate the value of 
RSA for analyzing structure within patterns of activity and support theories 
asserting that logical reasoning recruits spatial processing mechanisms.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2018.07.062
PMID: 30081195 [Indexed for MEDLINE]


163. J Cogn Neurosci. 2018 Sep;30(9):1209-1228. doi: 10.1162/jocn_a_01306. Epub 2018 
Jul 13.

Attentional Fluctuations Influence the Neural Fidelity and Connectivity of 
Stimulus Representations.

Rothlein D(1), DeGutis J(1)(2), Esterman M(1)(3).

Author information:
(1)VA Boston Healthcare System.
(2)Harvard Medical School.
(3)Boston University School of Medicine.

Attention is thought to facilitate both the representation of task-relevant 
features and the communication of these representations across large-scale brain 
networks. However, attention is not "all or none," but rather it fluctuates 
between stable/accurate (in-the-zone) and variable/error-prone (out-of-the-zone) 
states. Here we ask how different attentional states relate to the neural 
processing and transmission of task-relevant information. Specifically, during 
in-the-zone periods: (1) Do neural representations of task stimuli have greater 
fidelity? (2) Is there increased communication of this stimulus information 
across large-scale brain networks? Finally, (3) can the influence of 
performance-contingent reward be differentiated from zone-based fluctuations? To 
address these questions, we used fMRI and representational similarity analysis 
during a visual sustained attention task (the gradCPT). Participants ( n = 16) 
viewed a series of city or mountain scenes, responding to cities (90% of trials) 
and withholding to mountains (10%). Representational similarity matrices, 
reflecting the similarity structure of the city exemplars ( n = 10), were 
computed from visual, attentional, and default mode networks. Representational 
fidelity (RF) and representational connectivity (RC) were quantified as the 
interparticipant reliability of representational similarity matrices within (RF) 
and across (RC) brain networks. We found that being in the zone was 
characterized by increased RF in visual networks and increasing RC between 
visual and attentional networks. Conversely, reward only increased the RC 
between the attentional and default mode networks. These results diverge with 
analogous analyses using functional connectivity, suggesting that RC and 
functional connectivity in tandem better characterize how different mental 
states modulate the flow of information throughout the brain.

DOI: 10.1162/jocn_a_01306
PMID: 30004852 [Indexed for MEDLINE]


164. J Neurosci. 2018 Aug 8;38(32):7143-7157. doi: 10.1523/JNEUROSCI.3336-17.2018. 
Epub 2018 Jun 29.

Neural Computations Underlying Causal Structure Learning.

Tomov MS(1), Dorfman HM(2), Gershman SJ(2).

Author information:
(1)Department of Psychology and Center for Brain Science, Harvard University, 
Cambridge, Massachusetts 02138 mtomov@g.harvard.edu.
(2)Department of Psychology and Center for Brain Science, Harvard University, 
Cambridge, Massachusetts 02138.

Behavioral evidence suggests that beliefs about causal structure constrain 
associative learning, determining which stimuli can enter into association, as 
well as the functional form of that association. Bayesian learning theory 
provides one mechanism by which structural beliefs can be acquired from 
experience, but the neural basis of this mechanism is poorly understood. We 
studied this question with a combination of behavioral, computational, and 
neuroimaging techniques. Male and female human subjects learned to predict an 
outcome based on cue and context stimuli while being scanned using fMRI. Using a 
model-based analysis of the fMRI data, we show that structure learning signals 
are encoded in posterior parietal cortex, lateral prefrontal cortex, and the 
frontal pole. These structure learning signals are distinct from associative 
learning signals. Moreover, representational similarity analysis and information 
mapping revealed that the multivariate patterns of activity in posterior 
parietal cortex and anterior insula encode the full posterior distribution over 
causal structures. Variability in the encoding of the posterior across subjects 
predicted variability in their subsequent behavioral performance. These results 
provide evidence for a neural architecture in which structure learning guides 
the formation of associations.SIGNIFICANCE STATEMENT Animals are able to infer 
the hidden structure behind causal relations between stimuli in the environment, 
allowing them to generalize this knowledge to stimuli they have never 
experienced before. A recently published computational model based on this idea 
provided a parsimonious account of a wide range of phenomena reported in the 
animal learning literature, suggesting a dedicated neural mechanism for learning 
this hidden structure. Here, we validate this model by measuring brain activity 
during a task that involves both structure learning and associative learning. We 
show that a distinct network of regions supports structure learning and that the 
neural signal corresponding to beliefs about structure predicts future 
behavioral performance.

Copyright © 2018 the authors 0270-6474/18/387143-15$15.00/0.

DOI: 10.1523/JNEUROSCI.3336-17.2018
PMCID: PMC6083455
PMID: 29959234 [Indexed for MEDLINE]


165. Hum Brain Mapp. 2018 Sep;39(9):3779-3792. doi: 10.1002/hbm.24212. Epub 2018 Jun 
26.

Animacy and real-world size shape object representations in the human medial 
temporal lobes.

Blumenthal A(1)(2), Stojanoski B(1)(2), Martin CB(3), Cusack R(4), Köhler 
S(1)(2)(5).

Author information:
(1)Department of Psychology, University of Western Ontario, London, Ontario, 
Canada.
(2)The Brain and Mind Institute, University of Western Ontario, London, Ontario, 
Canada.
(3)Department of Psychology, University of Toronto, Toronto, Ontario, Canada.
(4)Department of Psychology, Trinity College, Dublin, Ireland.
(5)Rotman Research Institute, Baycrest, Toronto, Ontario, Canada.

Identifying what an object is, and whether an object has been encountered 
before, is a crucial aspect of human behavior. Despite this importance, we do 
not yet have a complete understanding of the neural basis of these abilities. 
Investigations into the neural organization of human object representations have 
revealed category specific organization in the ventral visual stream in 
perceptual tasks. Interestingly, these categories fall within broader domains of 
organization, with reported distinctions between animate, inanimate large, and 
inanimate small objects. While there is some evidence for category specific 
effects in the medial temporal lobe (MTL), in particular in perirhinal and 
parahippocampal cortex, it is currently unclear whether domain level 
organization is also present across these structures. To this end, we used fMRI 
with a continuous recognition memory task. Stimuli were images of objects from 
several different categories, which were either animate or inanimate, or large 
or small within the inanimate domain. We employed representational similarity 
analysis (RSA) to test the hypothesis that object-evoked responses in MTL 
structures during recognition-memory judgments also show evidence for 
domain-level organization along both dimensions. Our data support this 
hypothesis. Specifically, object representations were shaped by either animacy, 
real-world size, or both, in perirhinal and parahippocampal cortex, and the 
hippocampus. While sensitivity to these dimensions differed across structures 
when probed individually, hinting at interesting links to functional 
differentiation, similarities in organization across MTL structures were more 
prominent overall. These results argue for continuity in the organization of 
object representations in the ventral visual stream and the MTL.

© 2018 Wiley Periodicals, Inc.

DOI: 10.1002/hbm.24212
PMCID: PMC6866524
PMID: 29947037 [Indexed for MEDLINE]


166. J Neurosci. 2018 Jul 4;38(27):6076-6089. doi: 10.1523/JNEUROSCI.3258-17.2018. 
Epub 2018 Jun 11.

Neural Prediction Errors Distinguish Perception and Misperception of Speech.

Blank H(1)(2), Spangenberg M(3)(4), Davis MH(3).

Author information:
(1)Medical Research Council Cognition and Brain Sciences Unit, University of 
Cambridge, Cambridge CB2 7E, United Kingdom, hblank@uke.de.
(2)Department of Systems Neuroscience, University Medical Center Hamburg, 20248 
Hamburg, Germany, and.
(3)Medical Research Council Cognition and Brain Sciences Unit, University of 
Cambridge, Cambridge CB2 7E, United Kingdom.
(4)Department of Experimental Psychology, University of Oxford, Oxford OX1 3PH, 
United Kingdom.

Humans use prior expectations to improve perception, especially of sensory 
signals that are degraded or ambiguous. However, if sensory input deviates from 
prior expectations, then correct perception depends on adjusting or rejecting 
prior expectations. Failure to adjust or reject the prior leads to perceptual 
illusions, especially if there is partial overlap (and thus partial mismatch) 
between expectations and input. With speech, "slips of the ear" occur when 
expectations lead to misperception. For instance, an entomologist might be more 
susceptible to hear "The ants are my friends" for "The answer, my friend" (in 
the Bob Dylan song Blowing in the Wind). Here, we contrast two mechanisms by 
which prior expectations may lead to misperception of degraded speech. First, 
clear representations of the common sounds in the prior and input (i.e., 
expected sounds) may lead to incorrect confirmation of the prior. Second, 
insufficient representations of sounds that deviate between prior and input 
(i.e., prediction errors) could lead to deception. We used crossmodal 
predictions from written words that partially match degraded speech to compare 
neural responses when male and female human listeners were deceived into 
accepting the prior or correctly reject it. Combined behavioral and multivariate 
representational similarity analysis of fMRI data show that veridical perception 
of degraded speech is signaled by representations of prediction error in the 
left superior temporal sulcus. Instead of using top-down processes to support 
perception of expected sensory input, our findings suggest that the strength of 
neural prediction error representations distinguishes correct perception and 
misperception.SIGNIFICANCE STATEMENT Misperceiving spoken words is an everyday 
experience, with outcomes that range from shared amusement to serious 
miscommunication. For hearing-impaired individuals, frequent misperception can 
lead to social withdrawal and isolation, with severe consequences for wellbeing. 
In this work, we specify the neural mechanisms by which prior expectations, 
which are so often helpful for perception, can lead to misperception of degraded 
sensory signals. Most descriptive theories of illusory perception explain 
misperception as arising from a clear sensory representation of features or 
sounds that are in common between prior expectations and sensory input. Our work 
instead provides support for a complementary proposal: that misperception occurs 
when there is an insufficient sensory representations of the deviation between 
expectations and sensory signals.

Copyright © 2018 the authors 0270-6474/18/386076-14$15.00/0.

DOI: 10.1523/JNEUROSCI.3258-17.2018
PMCID: PMC6596154
PMID: 29891730 [Indexed for MEDLINE]


167. Proc Natl Acad Sci U S A. 2018 Jun 19;115(25):6398-6403. doi: 
10.1073/pnas.1803650115. Epub 2018 Jun 4.

Human midcingulate cortex encodes distributed representations of task progress.

Holroyd CB(1), Ribas-Fernandes JJF(2), Shahnazian D(2), Silvetti M(3)(4), 
Verguts T(3)(4).

Author information:
(1)Department of Psychology, University of Victoria, Victoria, BC V8W 2Y2, 
Canada; holroyd@uvic.ca.
(2)Department of Psychology, University of Victoria, Victoria, BC V8W 2Y2, 
Canada.
(3)Department of Experimental Psychology, Ghent University, B-9000 Ghent, 
Belgium.
(4)Ghent Institute for Functional and Metabolic Imaging (GIFMI), Ghent 
University Hospital, 9000 Ghent, Belgium.

The function of midcingulate cortex (MCC) remains elusive despite decades of 
investigation and debate. Complicating matters, individual MCC neurons respond 
to highly diverse task-related events, and MCC activation is reported in most 
human neuroimaging studies employing a wide variety of task manipulations. Here 
we investigate this issue by applying a model-based cognitive neuroscience 
approach involving neural network simulations, functional magnetic resonance 
imaging, and representational similarity analysis. We demonstrate that human MCC 
encodes distributed, dynamically evolving representations of extended, 
goal-directed action sequences. These representations are uniquely sensitive to 
the stage and identity of each sequence, indicating that MCC sustains contextual 
information necessary for discriminating between task states. These results 
suggest that standard univariate approaches for analyzing MCC function overlook 
the major portion of task-related information encoded by this brain area and 
point to promising new avenues for investigation.

DOI: 10.1073/pnas.1803650115
PMCID: PMC6016775
PMID: 29866834 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


168. Neuropsychologia. 2018 Aug;117:199-210. doi: 
10.1016/j.neuropsychologia.2018.05.026. Epub 2018 May 30.

Disentangling representations of shape and action components in the tool 
network.

Wang X(1), Zhuang T(1), Shen J(1), Bi Y(2).

Author information:
(1)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brian Research, Beijing Normal University, Beijing 100875, China; 
Beijing Key Laboratory of Brain Imaging and Connectomics, Beijing Normal 
University, Beijing 100875, China.
(2)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brian Research, Beijing Normal University, Beijing 100875, China; 
Beijing Key Laboratory of Brain Imaging and Connectomics, Beijing Normal 
University, Beijing 100875, China. Electronic address: ybi@bnu.edu.cn.

Shape and how they should be used are two key components of our knowledge about 
tools. Viewing tools preferentially activated a frontoparietal and 
occipitotemporal network, with dorsal regions implicated in computation of 
tool-related actions and ventral areas in shape representation. As shape and 
manners of manipulation are highly correlated for daily tools, whether they are 
independently represented in different regions remains inconclusive. In the 
current study, we collected fMRI data when participants viewed blocks of 
pictures of four daily tools (i.e., paintbrush, corkscrew, screwdriver, razor) 
where shape and action (manner of manipulation for functional use) were 
orthogonally manipulated, to tease apart these two dimensions. Behavioral 
similarity judgments tapping on object shape and finer aspects of actions (i.e., 
manners of motion, magnitude of arm movement, configuration of hand) were also 
collected to further disentangle the representation of object shape and 
different action components. Information analysis and representational 
similarity analysis were conducted on regional neural activation patterns of the 
tool-preferring network. In both analyses, the bilateral lateral 
occipitotemporal cortex showed robust shape representations but could not 
effectively distinguish between tool-use actions. The frontal and precentral 
regions represented kinematic action components, whereas the left parietal 
region (in information analyses) exhibited coding of both shape and tool-use 
action. By teasing apart shape and action components, we found both dissociation 
and association of them within the tool network. Taken together, our study 
disentangles representations for object shape from finer tool-use action 
components in the tool network, revealing the potential dissociable roles 
different tool-preferring regions play in tool processing.

Copyright © 2018 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2018.05.026
PMID: 29859296 [Indexed for MEDLINE]


169. Neuroscientist. 2018 Dec;24(6):582-608. doi: 10.1177/1073858418769554. Epub 2018 
Jun 1.

Orientation Encoding and Viewpoint Invariance in Face Recognition: Inferring 
Neural Properties from Large-Scale Signals.

Ramírez FM(1).

Author information:
(1)1 Bernstein Center for Computational Neuroscience, Charité 
Universitätsmedizin Berlin, Berlin, Germany.

Viewpoint-invariant face recognition is thought to be subserved by a distributed 
network of occipitotemporal face-selective areas that, except for the human 
anterior temporal lobe, have been shown to also contain face-orientation 
information. This review begins by highlighting the importance of bilateral 
symmetry for viewpoint-invariant recognition and face-orientation perception. 
Then, monkey electrophysiological evidence is surveyed describing key tuning 
properties of face-selective neurons-including neurons bimodally tuned to 
mirror-symmetric face-views-followed by studies combining functional magnetic 
resonance imaging (fMRI) and multivariate pattern analyses to probe the 
representation of face-orientation and identity information in humans. 
Altogether, neuroimaging studies suggest that face-identity is gradually 
disentangled from face-orientation information along the ventral visual 
processing stream. The evidence seems to diverge, however, regarding the 
prevalent form of tuning of neural populations in human face-selective areas. In 
this context, caveats possibly leading to erroneous inferences regarding 
mirror-symmetric coding are exposed, including the need to distinguish angular 
from Euclidean distances when interpreting multivariate pattern analyses. On 
this basis, this review argues that evidence from the fusiform face area is best 
explained by a view-sensitive code reflecting head angular disparity, consistent 
with a role of this area in face-orientation perception. Finally, the importance 
is stressed of explicit models relating neural properties to large-scale 
signals.

DOI: 10.1177/1073858418769554
PMID: 29855217 [Indexed for MEDLINE]


170. J Neurosci. 2018 May 23;38(21):4996-5007. doi: 10.1523/JNEUROSCI.3250-17.2018. 
Epub 2018 May 2.

Behavioral and Neural Representations of Spatial Directions across Words, 
Schemas, and Images.

Weisberg SM(1), Marchette SA(2), Chatterjee A(3).

Author information:
(1)Department of Neurology and stweis@pennmedicine.upenn.edu.
(2)Department of Psychology, University of Pennsylvania, Philadelphia, 
Pennsylvania 19104.
(3)Department of Neurology and.

Modern spatial navigation requires fluency with multiple representational 
formats, including visual scenes, signs, and words. These formats convey 
different information. Visual scenes are rich and specific but contain 
extraneous details. Arrows, as an example of signs, are schematic 
representations in which the extraneous details are eliminated, but analog 
spatial properties are preserved. Words eliminate all spatial information and 
convey spatial directions in a purely abstract form. How does the human brain 
compute spatial directions within and across these formats? To investigate this 
question, we conducted two experiments on men and women: a behavioral study that 
was preregistered and a neuroimaging study using multivoxel pattern analysis of 
fMRI data to uncover similarities and differences among representational 
formats. Participants in the behavioral study viewed spatial directions 
presented as images, schemas, or words (e.g., "left"), and responded to each 
trial, indicating whether the spatial direction was the same or different as the 
one viewed previously. They responded more quickly to schemas and words than 
images, despite the visual complexity of stimuli being matched. Participants in 
the fMRI study performed the same task but responded only to occasional catch 
trials. Spatial directions in images were decodable in the intraparietal sulcus 
bilaterally but were not in schemas and words. Spatial directions were also 
decodable between all three formats. These results suggest that intraparietal 
sulcus plays a role in calculating spatial directions in visual scenes, but this 
neural circuitry may be bypassed when the spatial directions are presented as 
schemas or words.SIGNIFICANCE STATEMENT Human navigators encounter spatial 
directions in various formats: words ("turn left"), schematic signs (an arrow 
showing a left turn), and visual scenes (a road turning left). The brain must 
transform these spatial directions into a plan for action. Here, we investigate 
similarities and differences between neural representations of these formats. We 
found that bilateral intraparietal sulci represent spatial directions in visual 
scenes and across the three formats. We also found that participants respond 
quickest to schemas, then words, then images, suggesting that spatial directions 
in abstract formats are easier to interpret than concrete formats. These results 
support a model of spatial direction interpretation in which spatial directions 
are either computed for real world action or computed for efficient visual 
comparison.

Copyright © 2018 the authors 0270-6474/18/384996-12$15.00/0.

DOI: 10.1523/JNEUROSCI.3250-17.2018
PMCID: PMC5966795
PMID: 29720551 [Indexed for MEDLINE]


171. eNeuro. 2018 Feb 28;5(1):ENEURO.0445-17.2018. doi: 10.1523/ENEURO.0445-17.2018. 
eCollection 2018 Jan-Feb.

Amygdala Adaptation and Temporal Dynamics of the Salience Network in Conditioned 
Fear: A Single-Trial fMRI Study.

Yin S(1), Liu Y(2), Petro NM(3), Keil A(3), Ding M(1).

Author information:
(1)J. Crayton Pruitt Family Department of Biomedical Engineering, University of 
Florida, Gainesville, FL 32611.
(2)Center for Mind and Brain, University of California, Davis, CA 95618.
(3)Department of Psychology, University of Florida, Gainesville, FL 32611.

Research in rodents has established the role of the amygdaloid complex in 
defensive responses to conditioned threat. In human imaging studies, however, 
activation of the amygdala by conditioned threat cues is often not observed. One 
hypothesis states that this finding reflects adaptation of amygdaloid responses 
over time. We tested this hypothesis by estimating single-trial neural responses 
over a large number of conditioning trials. Functional MRI (fMRI) was recorded 
from 18 participants during classical differential fear conditioning: 
Participants viewed oriented grayscale grating stimuli (45° or 135°) presented 
centrally in random order. In the acquisition block, one grating (the CS+) was 
paired with a noxious noise, the unconditioned stimulus (US), on 25% of trials. 
The other grating, denoted CS-, was never paired with the US. Consistent with 
previous reports, BOLD in dorsal anterior cingulate cortex (dACC) and insula, 
but not the amygdala, was heightened when viewing CS+ stimuli that were not 
paired with US compared to CS- stimuli. Trial-by-trial analysis showed that over 
the course of acquisition, activity in the amygdala attenuated. Interestingly, 
activity in the dACC and insula also declined. Representational similarity 
analysis (RSA) corroborated these results, indicating that the voxel patterns 
evoked by CS+ and CS- in these brain regions became less distinguishable over 
time. Together, the present findings support the hypothesis that the lack of 
BOLD differences in the amygdaloid complex in many studies of classical 
conditioning is due to adaptation, and the adaptation effects may reflect 
changes in large-scale networks mediating aversive conditioning, particularly 
the salience network.

DOI: 10.1523/ENEURO.0445-17.2018
PMCID: PMC5830351
PMID: 29497705 [Indexed for MEDLINE]


172. Sci Rep. 2018 Feb 14;8(1):3047. doi: 10.1038/s41598-018-21062-0.

Representational similarity analysis reveals task-dependent semantic influence 
of the visual word form area.

Wang X(1)(2)(3), Xu Y(2)(3), Wang Y(4)(5), Zeng Y(4)(5), Zhang J(6), Ling Z(7), 
Bi Y(2)(3).

Author information:
(1)College of Information Science and Technology, Beijing Normal University, 
Beijing, 100875, China.
(2)National Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brain Research, Beijing Normal University, Beijing, 100875, China.
(3)Beijing Key Laboratory of Brain Imaging and Connectomics, Beijing Normal 
University, Beijing, 100875, China.
(4)Research Center for Brain-inspired Intelligence & National Laboratory of 
Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, 
Beijing, 100190, China.
(5)Center for Excellence in Brain Science and Intelligence Technology, Chinese 
Academy of Sciences, Shanghai, 200031, China.
(6)College of Information Science and Technology, Beijing Normal University, 
Beijing, 100875, China. jiacai.zhang@bnu.edu.cn.
(7)National Engineering Laboratory for Speech and Language Information 
Processing, University of Science and Technology of China, Hefei, 230027, China. 
zhling@ustc.edu.cn.

Access to semantic information of visual word forms is a key component of 
reading comprehension. In this study, we examined the involvement of the visual 
word form area (VWFA) in this process by investigating whether and how the 
activity patterns of the VWFA are influenced by semantic information during 
semantic tasks. We asked participants to perform two semantic tasks - taxonomic 
or thematic categorization - on visual words while obtaining the 
blood-oxygen-level-dependent (BOLD) fMRI responses to each word. 
Representational similarity analysis with four types of semantic relations 
(taxonomic, thematic, subjective semantic rating and word2vec) revealed that 
neural activity patterns of the VWFA were associated with taxonomic information 
only in the taxonomic task, with thematic information only in the thematic task 
and with the composite semantic information measured by word2vec in both 
semantic tasks. Furthermore, the semantic information in the VWFA cannot be 
explained by confounding factors including orthographic, low-level visual and 
phonological information. These findings provide positive evidence for the 
presence of both orthographic and task-relevant semantic information in the VWFA 
and have significant implications for the neurobiological basis of reading.

DOI: 10.1038/s41598-018-21062-0
PMCID: PMC5813029
PMID: 29445098 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


173. Neuroimage. 2018 May 15;172:415-426. doi: 10.1016/j.neuroimage.2018.01.084. Epub 
2018 Feb 2.

Rule activation and ventromedial prefrontal engagement support accurate stopping 
in self-paced learning.

O'Bryan SR(1), Walden E(2), Serra MJ(3), Davis T(3).

Author information:
(1)Department of Psychological Sciences, Texas Tech University, Lubbock, TX 
79409, USA. Electronic address: sean.r.obryan@ttu.edu.
(2)Rawls College of Business, Texas Tech University, Lubbock, TX 79409, USA.
(3)Department of Psychological Sciences, Texas Tech University, Lubbock, TX 
79409, USA.

When weighing evidence for a decision, individuals are continually faced with 
the choice of whether to gather more information or act on what has already been 
learned. The present experiment employed a self-paced category learning task and 
fMRI to examine the neural mechanisms underlying stopping of information search 
and how they contribute to choice accuracy. Participants learned to classify 
triads of face, object, and scene cues into one of two categories using a rule 
based on one of the stimulus dimensions. After each trial, participants were 
given the option to explicitly solve the rule or continue learning. 
Representational similarity analysis (RSA) was used to examine activation of 
rule-relevant information on trials leading up to a decision to solve the rule. 
We found that activation of rule-relevant information increased leading up to 
participants' stopping decisions. Stopping was associated with widespread 
activation that included medial prefrontal cortex and visual association areas. 
Engagement of ventromedial prefrontal cortex (vmPFC) was associated with 
accurate stopping, and activation in this region was functionally coupled with 
signal in dorsolateral prefrontal cortex (dlPFC). Results suggest that 
activating rule information when deciding whether to stop an information search 
increases choice accuracy, and that the response profile of vmPFC during such 
decisions may provide an index of effective learning.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2018.01.084
PMID: 29410293 [Indexed for MEDLINE]


174. Neuroimage. 2018 May 15;172:313-325. doi: 10.1016/j.neuroimage.2018.01.068. Epub 
2018 Jan 31.

Brain mechanisms underlying cue-based memorizing during free viewing of movie 
Memento.

Kauttonen J(1), Hlushchuk Y(2), Jääskeläinen IP(3), Tikka P(4).

Author information:
(1)Department of Media, Aalto University, FI-00076 Aalto, Finland; Department of 
Neuroscience and Biomedical Engineering, Aalto University, FI-00076 Aalto, 
Finland. Electronic address: janne.kauttonen@gmail.com.
(2)Department of Media, Aalto University, FI-00076 Aalto, Finland; University of 
Helsinki and Helsinki University Hospital, HUS Medical Imaging Center, 
Radiology, Finland.
(3)Department of Neuroscience and Biomedical Engineering, Aalto University, 
FI-00076 Aalto, Finland.
(4)Department of Media, Aalto University, FI-00076 Aalto, Finland; Aalto 
NeuroImaging, Aalto University, FI-00076 Aalto, Finland.

How does the human brain recall and connect relevant memories with unfolding 
events? To study this, we presented 25 healthy subjects, during functional 
magnetic resonance imaging, the movie 'Memento' (director C. Nolan). In this 
movie, scenes are presented in chronologically reverse order with certain scenes 
briefly overlapping previously presented scenes. Such overlapping "key-frames" 
serve as effective memory cues for the viewers, prompting recall of relevant 
memories of the previously seen scene and connecting them with the concurrent 
scene. We hypothesized that these repeating key-frames serve as immediate recall 
cues and would facilitate reconstruction of the story piece-by-piece. The 
chronological version of Memento, shown in a separate experiment for another 
group of subjects, served as a control condition. Using multivariate 
event-related pattern analysis method and representational similarity analysis, 
focal fingerprint patterns of hemodynamic activity were found to emerge during 
presentation of key-frame scenes. This effect was present in higher-order 
cortical network with regions including precuneus, angular gyrus, cingulate 
gyrus, as well as lateral, superior, and middle frontal gyri within frontal 
poles. This network was right hemispheric dominant. These distributed patterns 
of brain activity appear to underlie ability to recall relevant memories and 
connect them with ongoing events, i.e., "what goes with what" in a complex 
story. Given the real-life likeness of cinematic experience, these results 
provide new insight into how the human brain recalls, given proper cues, 
relevant memories to facilitate understanding and prediction of everyday life 
events.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2018.01.068
PMID: 29409793 [Indexed for MEDLINE]


175. Neuroscience. 2018 Feb 21;372:87-96. doi: 10.1016/j.neuroscience.2017.12.043. 
Epub 2017 Dec 30.

Revealing the Semantic Association between Perception of Scenes and Significant 
Objects by Representational Similarity Analysis.

Wang S(1), Cao L(1), Xu J(2), Zhang G(1), Lou Y(3), Liu B(4).

Author information:
(1)School of Computer Science and Technology, Tianjin Key Laboratory of 
Cognitive Computing and Application, Tianjin University, Tianjin 300350, PR 
China.
(2)School of Computer Science and Technology, Tianjin Key Laboratory of 
Cognitive Computing and Application, Tianjin University, Tianjin 300350, PR 
China. Electronic address: jhxu@tju.edu.cn.
(3)Research Center for Sectional and Imaging Anatomy, Shandong University 
Cheeloo College of medicine, Jinan, Shandong 250012, PR China.
(4)School of Computer Science and Technology, Tianjin Key Laboratory of 
Cognitive Computing and Application, Tianjin University, Tianjin 300350, PR 
China; State Key Laboratory of Intelligent Technology and Systems, National 
Laboratory for Information Science and Technology, Tsinghua University, Beijing 
100084, PR China. Electronic address: jhxu@tju.edu.cn.

'Significant' objects contribute greatly to scene recognition. The lateral 
occipital complex (LOC), parahippocampal place area (PPA), and retrosplenial 
cortex (RSC) play a crucial role in the cognitive processing of objects and 
scenes. However, the associated mechanism between objects and scenes remains 
unclear. In this study, four categories of scene images and four types of 
significant objects were designed as stimuli. Representational similarity 
analysis (RSA) of functional magnetic resonance imaging (fMRI) data showed that 
correlation coefficients of the activity patterns for objects and scenes were 
significantly positive in the LOC and PPA. Compared to the out-of-scene objects, 
the correlation strengths for within-scene objects were significantly greater in 
the PPA and two subregions of the LOC: the lateral occipital area (LO), and 
posterior fusiform area (PF). Further correlation analyses showed that the 
scene-object correlations were different for indoor and outdoor scenes in the 
LO, pF and PPA. Semantic associations were represented in the LO and pF, while 
the PPA was involved in semantic correlations and spatial characteristics, which 
were sensitive to the openness of scenes. However, these trends were not 
observed in the RSC, suggesting that it is not recruited to process semantic 
associations between scenes and objects. Our findings provide an understanding 
of the neural mechanism of scene recognition.

Copyright © 2017 IBRO. Published by Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.neuroscience.2017.12.043
PMID: 29294340 [Indexed for MEDLINE]


176. Soc Cogn Affect Neurosci. 2017 Dec 1;12(12):1916-1927. doi: 10.1093/scan/nsx125.

Love flows downstream: mothers' and children's neural representation similarity 
in perceiving distress of self and family.

Lee TH(1), Qu Y(2), Telzer EH(1).

Author information:
(1)Department of Psychology and Neuroscience, The University of North Carolina 
at Chapel Hill, Chapel Hill, NC 27599-3270, USA.
(2)Department of Psychology, Stanford University, Stanford, CA 94305, USA.

The current study aimed to capture empathy processing in an interpersonal 
context. Mother-adolescent dyads (N = 22) each completed an empathy task during 
fMRI, in which they imagined the target person in distressing scenes as either 
themselves or their family (i.e. child for the mother, mother for the child). 
Using multi-voxel pattern approach, we compared neural pattern similarity for 
the self and family conditions and found that mothers showed greater perceptual 
similarity between self and child in the fusiform face area (FFA), representing 
high self-child overlap, whereas adolescents showed significantly less 
self-mother overlap. Adolescents' pattern similarity was dependent upon family 
relationship quality, such that they showed greater self-mother overlap with 
higher relationship quality, whereas mothers' pattern similarity was independent 
of relationship quality. Furthermore, adolescents' perceptual similarity in the 
FFA was associated with increased social brain activation (e.g. temporal 
parietal junction). Mediation analyses indicated that high relationship quality 
was associated with greater social brain activation, which was mediated by 
greater self-mother overlap in the FFA. Our findings suggest that adolescents 
show more distinct neural patterns in perceiving their own vs their mother's 
distress, and such distinction is sensitive to mother-child relationship 
quality. In contrast, mothers' perception for their own and child's distress is 
highly similar and unconditional.

© The Author (2017). Published by Oxford University Press.

DOI: 10.1093/scan/nsx125
PMCID: PMC5716095
PMID: 29069521 [Indexed for MEDLINE]


177. Cereb Cortex. 2018 Nov 1;28(11):3908-3921. doi: 10.1093/cercor/bhx255.

Auditory Frequency Representations in Human Somatosensory Cortex.

Pérez-Bellido A(1), Anne Barnes K(1), Crommett LE(1), Yau JM(1).

Author information:
(1)Department of Neuroscience, Baylor College of Medicine, Houston, One Baylor 
Plaza, Houston, TX, USA.

Recent studies have challenged the traditional notion of modality-dedicated 
cortical systems by showing that audition and touch evoke responses in the same 
sensory brain regions. While much of this work has focused on somatosensory 
responses in auditory regions, fewer studies have investigated sound responses 
and representations in somatosensory regions. In this functional magnetic 
resonance imaging (fMRI) study, we measured BOLD signal changes in participants 
performing an auditory frequency discrimination task and characterized 
activation patterns related to stimulus frequency using both univariate and 
multivariate analysis approaches. Outside of bilateral temporal lobe regions, we 
observed robust and frequency-specific responses to auditory stimulation in 
classically defined somatosensory areas. Moreover, using representational 
similarity analysis to define the relationships between multi-voxel activation 
patterns for all sound pairs, we found clear similarity patterns for auditory 
responses in the parietal lobe that correlated significantly with perceptual 
similarity judgments. Our results demonstrate that auditory frequency 
representations can be distributed over brain regions traditionally considered 
to be dedicated to somatosensation. The broad distribution of auditory and 
tactile responses over parietal and temporal regions reveals a number of 
candidate brain areas that could support general temporal frequency processing 
and mediate the extensive and robust perceptual interactions between audition 
and touch.

DOI: 10.1093/cercor/bhx255
PMCID: PMC6188539
PMID: 29045579 [Indexed for MEDLINE]


178. J Neurosci. 2017 Nov 8;37(45):11037-11050. doi: 10.1523/JNEUROSCI.0935-17.2017. 
Epub 2017 Oct 2.

Dynamic Trial-by-Trial Recoding of Task-Set Representations in the 
Frontoparietal Cortex Mediates Behavioral Flexibility.

Qiao L(1), Zhang L(1), Chen A(2), Egner T(3).

Author information:
(1)Key Laboratory of Cognition and Personality of Ministry of Education, Faculty 
of Psychology, Chongqing Collaborative Innovation Center for Brain Science, 
Southwest University, Chongqing 400715, China, and.
(2)Key Laboratory of Cognition and Personality of Ministry of Education, Faculty 
of Psychology, Chongqing Collaborative Innovation Center for Brain Science, 
Southwest University, Chongqing 400715, China, and xscat@swu.edu.cn.
(3)Center for Cognitive Neuroscience, Department of Psychology and Neuroscience, 
Duke University, Durham, North Carolina 27708.

Cognitive flexibility forms the core of the extraordinary ability of humans to 
adapt, but the precise neural mechanisms underlying our ability to nimbly shift 
between task sets remain poorly understood. Recent functional magnetic resonance 
imaging (fMRI) studies employing multivoxel pattern analysis (MVPA) have shown 
that a currently relevant task set can be decoded from activity patterns in the 
frontoparietal cortex, but whether these regions support the dynamic 
transformation of task sets from trial to trial is not clear. Here, we combined 
a cued task-switching protocol with human (both sexes) fMRI, and harnessed 
representational similarity analysis (RSA) to facilitate a novel assessment of 
trial-by-trial changes in neural task-set representations. We first used MVPA to 
define task-sensitive frontoparietal and visual regions and found that neural 
task-set representations on switch trials are less stably encoded than on repeat 
trials. We then exploited RSA to show that the neural representational pattern 
dissimilarity across consecutive trials is greater for switch trials than for 
repeat trials, and that the degree of this pattern dissimilarity predicts 
behavior. Moreover, the overall neural pattern of representational 
dissimilarities followed from the assumption that repeating sets, compared with 
switching sets, results in stronger neural task representations. Finally, when 
moving from cue to target phase within a trial, pattern dissimilarities tracked 
the transformation from previous-trial task representations to the currently 
relevant set. These results provide neural evidence for the longstanding 
assumptions of an effortful task-set reconfiguration process hampered by 
task-set inertia, and they demonstrate that frontoparietal and stimulus 
processing regions support "dynamic adaptive coding," flexibly representing 
changing task sets in a trial-by-trial fashion.SIGNIFICANCE STATEMENT Humans can 
fluently switch between different tasks, reflecting an ability to dynamically 
configure "task sets," rule representations that link stimuli to appropriate 
responses. Recent studies show that neural signals in frontal and parietal brain 
regions can tell us which of two tasks a person is currently performing. 
However, it is not known whether these regions are also involved in dynamically 
reconfiguring task-set representations when switching between tasks. Here we 
measured human brain activity during task switching and tracked the similarity 
of neural task-set representations from trial to trial. We show that frontal and 
parietal brain regions flexibly recode changing task sets in a trial-by-trial 
fashion, and that task-set similarity over consecutive trials predicts behavior.

Copyright © 2017 the authors 0270-6474/17/3711037-14$15.00/0.

DOI: 10.1523/JNEUROSCI.0935-17.2017
PMCID: PMC5678027
PMID: 28972126 [Indexed for MEDLINE]


179. Cereb Cortex. 2018 Sep 1;28(9):3241-3254. doi: 10.1093/cercor/bhx195.

Task-General and Acoustic-Invariant Neural Representation of Speech Categories 
in the Human Brain.

Feng G(1)(2)(3), Gan Z(4), Wang S(4)(5), Wong PCM(1)(2), Chandrasekaran 
B(3)(6)(7)(8)(9).

Author information:
(1)Department of Linguistics and Modern Languages, The Chinese University of 
Hong Kong, Shatin, N.T., Hong Kong SAR, China.
(2)Brain and Mind Institute, The Chinese University of Hong Kong, Shatin, N.T., 
Hong Kong SAR, China.
(3)Department of Communication Sciences & Disorders, Moody College of 
Communication, The University of Texas at Austin, 2504A Whitis Avenue (A1100), 
Austin, TX, USA.
(4)Center for the Study of Applied Psychology and School of Psychology, South 
China Normal University, Guangzhou, China.
(5)Guangdong Provincial Key Laboratory of Mental Health and Cognitive Science, 
South China Normal University, Guangzhou, China.
(6)Department of Psychology, The University of Texas at Austin, 108 E. Dean 
Keeton Stop, Austin, TX, USA.
(7)Department of Linguistics, The University of Texas at Austin, 305 E. 23rd 
Street STOP, Austin, TX, USA.
(8)Institute for Mental Health Research, College of Liberal Arts, The University 
of Texas at Austin, 305 E. 23rd St. Stop, Austin, TX, USA.
(9)The Institute for Neuroscience, The University of Texas at Austin, 1 
University Station Stop, Austin, TX, USA.

A significant neural challenge in speech perception includes extracting discrete 
phonetic categories from continuous and multidimensional signals despite varying 
task demands and surface-acoustic variability. While neural representations of 
speech categories have been previously identified in frontal and posterior 
temporal-parietal regions, the task dependency and dimensional specificity of 
these neural representations are still unclear. Here, we asked native Mandarin 
participants to listen to speech syllables carrying 4 distinct lexical tone 
categories across passive listening, repetition, and categorization tasks while 
they underwent functional magnetic resonance imaging (fMRI). We used searchlight 
classification and representational similarity analysis (RSA) to identify the 
dimensional structure underlying neural representation across tasks and 
surface-acoustic properties. Searchlight classification analyses revealed 
significant "cross-task" lexical tone decoding within the bilateral superior 
temporal gyrus (STG) and left inferior parietal lobule (LIPL). RSA revealed that 
the LIPL and LSTG, in contrast to the RSTG, relate to 2 critical dimensions 
(pitch height, pitch direction) underlying tone perception. Outside this core 
representational network, we found greater activation in the inferior frontal 
and parietal regions for stimuli that are more perceptually similar during tone 
categorization. Our findings reveal the specific characteristics of 
fronto-tempo-parietal regions that support speech representation and 
categorization processing.

DOI: 10.1093/cercor/bhx195
PMCID: PMC6454529
PMID: 28968658 [Indexed for MEDLINE]


180. Biol Psychol. 2017 Oct;129:314-323. doi: 10.1016/j.biopsycho.2017.09.015. Epub 
2017 Sep 28.

Neural bases of action abstraction.

Quandt LC(1), Lee YS(2), Chatterjee A(3).

Author information:
(1)Ph.D. in Educational Neuroscience Program, Gallaudet University, 800 Florida 
Ave NE, Washington, DC 20002, United States. Electronic address: 
lorna.quandt@gallaudet.edu.
(2)Department of Speech and Hearing Science, Center for Brain Injury, The Ohio 
State University, 1070 Carmack Rd., Columbus, OH 43210, United States.
(3)Center for Cognitive Neuroscience, Department of Neurology, University of 
Pennsylvania, 3701 Hamilton Walk, Philadelphia, PA 19104, United States.

There has been recent debate over whether actions are processed primarily by 
means of motor simulation or cognitive semantics. The current study investigated 
how abstract action concepts are processed in the brain, independent of the 
format in which they are presented. Eighteen healthy adult participants viewed 
different actions (e.g., diving, boxing) in the form of verbs and schematic 
action pictograms while functional magnetic resonance imaging (fMRI) was 
collected. We predicted that sensorimotor and semantic brain regions would show 
similar patterns of neural activity for different instances of the same action 
(e.g., diving pictogram and the word 'diving'). A representational similarity 
analysis revealed posterior temporal and sensorimotor regions where specific 
action concepts were encoded, independent of the format of presentation. These 
results reveal the neural instantiations of abstract action concepts, and 
demonstrate that both sensorimotor and semantic systems are involved in 
processing actions.

Copyright © 2017 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.biopsycho.2017.09.015
PMCID: PMC5673573
PMID: 28964789 [Indexed for MEDLINE]


181. Sci Rep. 2017 Sep 25;7(1):12237. doi: 10.1038/s41598-017-12559-1.

The neural representation of personally familiar and unfamiliar faces in the 
distributed system for face perception.

Visconti di Oleggio Castello M(1), Halchenko YO(2), Guntupalli JS(3), Gors 
JD(3), Gobbini MI(4)(5).

Author information:
(1)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH, 03755, USA. mvdoc.gr@dartmouth.edu.
(2)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH, 03755, USA. yoh@dartmouth.edu.
(3)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH, 03755, USA.
(4)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH, 03755, USA. mariaida.gobbini@unibo.it.
(5)Dipartimento di Medicina Specialistica, Diagnostica e Sperimentale (DIMES), 
Medical School, University of Bologna, Bologna, Italy. 
mariaida.gobbini@unibo.it.

Personally familiar faces are processed more robustly and efficiently than 
unfamiliar faces. The human face processing system comprises a core system that 
analyzes the visual appearance of faces and an extended system for the retrieval 
of person-knowledge and other nonvisual information. We applied multivariate 
pattern analysis to fMRI data to investigate aspects of familiarity that are 
shared by all familiar identities and information that distinguishes specific 
face identities from each other. Both identity-independent familiarity 
information and face identity could be decoded in an overlapping set of areas in 
the core and extended systems. Representational similarity analysis revealed a 
clear distinction between the two systems and a subdivision of the core system 
into ventral, dorsal and anterior components. This study provides evidence that 
activity in the extended system carries information about both individual 
identities and personal familiarity, while clarifying and extending the 
organization of the core system for face perception.

DOI: 10.1038/s41598-017-12559-1
PMCID: PMC5612994
PMID: 28947835 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no competing 
interests.


182. Front Hum Neurosci. 2017 Aug 22;11:424. doi: 10.3389/fnhum.2017.00424. 
eCollection 2017.

Neural Pattern Similarity in the Left IFG and Fusiform Is Associated with Novel 
Word Learning.

Qu J(1), Qian L(1), Chen C(2), Xue G(3), Li H(1), Xie P(1), Mei L(1).

Author information:
(1)Guangdong Key Laboratory of Mental Health and Cognitive Science, Center for 
Studies of Psychological Application, School of Psychology, South China Normal 
UniversityGuangzhou, China.
(2)Department of Psychology and Social Behavior, University of California, 
IrvineIrvine, CA, United States.
(3)State Key Laboratory of Cognitive Neuroscience and Learning, IDG McGovern 
Institute for Brain Research, Beijing Normal UniversityBeijing, China.

Previous studies have revealed that greater neural pattern similarity across 
repetitions is associated with better subsequent memory. In this study, we used 
an artificial language training paradigm and representational similarity 
analysis to examine whether neural pattern similarity across repetitions before 
training was associated with post-training behavioral performance. Twenty-four 
native Chinese speakers were trained to learn a logographic artificial language 
for 12 days and behavioral performance was recorded using the word naming and 
picture naming tasks. Participants were scanned while performing a passive 
viewing task before training, after 4-day training and after 12-day training. 
Results showed that pattern similarity in the left pars opercularis (PO) and 
fusiform gyrus (FG) before training was negatively associated with reaction time 
(RT) in both word naming and picture naming tasks after training. These results 
suggest that neural pattern similarity is an effective neurofunctional predictor 
of novel word learning in addition to word memory.

DOI: 10.3389/fnhum.2017.00424
PMCID: PMC5572377
PMID: 28878640


183. Neuroimage. 2017 Nov 15;162:32-44. doi: 10.1016/j.neuroimage.2017.08.033. Epub 
2017 Aug 13.

Multi-Connection Pattern Analysis: Decoding the representational content of 
neural communication.

Li Y(1), Richardson RM(2), Ghuman AS(3).

Author information:
(1)Center for the Neural Basis of Cognition, Carnegie Mellon University and 
University of Pittsburgh, USA; Program in Neural Computation, Carnegie Mellon 
University and University of Pittsburgh, USA; Department of Neurological 
Surgery, University of Pittsburgh, USA. Electronic address: ynli@cmu.edu.
(2)Center for the Neural Basis of Cognition, Carnegie Mellon University and 
University of Pittsburgh, USA; Department of Neurological Surgery, University of 
Pittsburgh, USA.
(3)Center for the Neural Basis of Cognition, Carnegie Mellon University and 
University of Pittsburgh, USA; Program in Neural Computation, Carnegie Mellon 
University and University of Pittsburgh, USA; Department of Neurological 
Surgery, University of Pittsburgh, USA.

The lack of multivariate methods for decoding the representational content of 
interregional neural communication has left it difficult to know what 
information is represented in distributed brain circuit interactions. Here we 
present Multi-Connection Pattern Analysis (MCPA), which works by learning 
mappings between the activity patterns of the populations as a factor of the 
information being processed. These maps are used to predict the activity from 
one neural population based on the activity from the other population. 
Successful MCPA-based decoding indicates the involvement of distributed 
computational processing and provides a framework for probing the 
representational structure of the interaction. Simulations demonstrate the 
efficacy of MCPA in realistic circumstances. In addition, we demonstrate that 
MCPA can be applied to different signal modalities to evaluate a variety of 
hypothesis associated with information coding in neural communications. We apply 
MCPA to fMRI and human intracranial electrophysiological data to provide a 
proof-of-concept of the utility of this method for decoding individual natural 
images and faces in functional connectivity data. We further use a MCPA-based 
representational similarity analysis to illustrate how MCPA may be used to test 
computational models of information transfer among regions of the visual 
processing stream. Thus, MCPA can be used to assess the information represented 
in the coupled activity of interacting neural circuits and probe the underlying 
principles of information transformation between regions.

Copyright © 2017 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2017.08.033
PMCID: PMC5705443
PMID: 28813643 [Indexed for MEDLINE]


184. Neuroimage. 2017 Oct 1;159:371-387. doi: 10.1016/j.neuroimage.2017.07.043. Epub 
2017 Jul 22.

Illuminating the conceptual structure of the space of moral violations with 
searchlight representational similarity analysis.

Wasserman EA(1), Chakroff A(2), Saxe R(3), Young L(2).

Author information:
(1)Dept. of Psychology, Boston College, Chestnut Hill, MA, United States. 
Electronic address: emily.wasserman@bc.edu.
(2)Dept. of Psychology, Boston College, Chestnut Hill, MA, United States.
(3)Dept. of Brain & Cognitive Sciences, Massachusetts Institute of Technology, 
Cambridge, MA, United States.

Characterizing how representations of moral violations are organized, 
cognitively and neurally, is central to understanding how people conceive and 
judge them. Past work has identified brain regions that represent morally 
relevant features and distinguish moral domains, but has not yet advanced a 
broader account of where and on what basis neural representations of moral 
violations are organized. With searchlight representational similarity analysis, 
we investigate where category membership drives similarity in neural patterns 
during moral judgment of violations from two key moral domains: Harm and Purity. 
Representations converge across domains in a network of regions resembling the 
mentalizing network. However, Harm and Purity violation representations 
respectively converge in different regions: precuneus (PC) and left inferior 
frontal gyrus (LIFG). Examining substructure within moral domains, Harm 
violations converge in PC regardless of subdomain (physical harms, psychological 
harms), while Purity subdomains (pathogen-related violations, sex-related 
violations) converge in distinct sets of regions - mirroring a dissociation 
observed in principal-component analysis of behavioral data. Further, we find 
initial evidence for representation of morally relevant features within these 
two domain-encoding regions. The present analyses offer a case study for 
understanding how organization within the complex conceptual space of moral 
violations is reflected in the organization of neural patterns across the 
cortex.

Copyright © 2017 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2017.07.043
PMCID: PMC5671354
PMID: 28743459 [Indexed for MEDLINE]


185. Neuroimage. 2017 Oct 1;159:131-145. doi: 10.1016/j.neuroimage.2017.07.033. Epub 
2017 Jul 17.

The neural basis of precise visual short-term memory for complex recognisable 
objects.

Veldsman M(1), Mitchell DJ(2), Cusack R(3).

Author information:
(1)Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford, 
UK. Electronic address: michele.veldsman@ndcn.ox.ac.uk.
(2)Medical Research Council Cognition and Brain Science Unit, Cambridge, UK.
(3)Brain and Mind Institute, University of Western Ontario, London, Canada; 
Trinity College Institute of Neuroscience, Trinity College Dublin, Dublin, 
Ireland.

Recent evidence suggests that visual short-term memory (VSTM) capacity estimated 
using simple objects, such as colours and oriented bars, may not generalise well 
to more naturalistic stimuli. More visual detail can be stored in VSTM when 
complex, recognisable objects are maintained compared to simple objects. It is 
not yet known if it is recognisability that enhances memory precision, nor 
whether maintenance of recognisable objects is achieved with the same network of 
brain regions supporting maintenance of simple objects. We used a novel stimulus 
generation method to parametrically warp photographic images along a continuum, 
allowing separate estimation of the precision of memory representations and the 
number of items retained. The stimulus generation method was also designed to 
create unrecognisable, though perceptually matched, stimuli, to investigate the 
impact of recognisability on VSTM. We adapted the widely-used change detection 
and continuous report paradigms for use with complex, photographic images. 
Across three functional magnetic resonance imaging (fMRI) experiments, we 
demonstrated greater precision for recognisable objects in VSTM compared to 
unrecognisable objects. This clear behavioural advantage was not the result of 
recruitment of additional brain regions, or of stronger mean activity within the 
core network. Representational similarity analysis revealed greater variability 
across item repetitions in the representations of recognisable, compared to 
unrecognisable complex objects. We therefore propose that a richer range of 
neural representations support VSTM for complex recognisable objects.

Copyright © 2017 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2017.07.033
PMID: 28729161 [Indexed for MEDLINE]


186. Neuroimage. 2017 Sep;158:441-454. doi: 10.1016/j.neuroimage.2017.07.023. Epub 
2017 Jul 14.

Multivariate pattern analysis of MEG and EEG: A comparison of representational 
structure in time and space.

Cichy RM(1), Pantazis D(2).

Author information:
(1)Department of Education and Psychology, Free University Berlin, Berlin, 
Germany. Electronic address: radoslaw.cichy@fu-berlin.de.
(2)McGovern Institute for Brain Research, Massachusetts Institute of Technology, 
Cambridge, MA, USA.

Multivariate pattern analysis of magnetoencephalography (MEG) and 
electroencephalography (EEG) data can reveal the rapid neural dynamics 
underlying cognition. However, MEG and EEG have systematic differences in 
sampling neural activity. This poses the question to which degree such 
measurement differences consistently bias the results of multivariate analysis 
applied to MEG and EEG activation patterns. To investigate, we conducted a 
concurrent MEG/EEG study while participants viewed images of everyday objects. 
We applied multivariate classification analyses to MEG and EEG data, and 
compared the resulting time courses to each other, and to fMRI data for an 
independent evaluation in space. We found that both MEG and EEG revealed the 
millisecond spatio-temporal dynamics of visual processing with largely 
equivalent results. Beyond yielding convergent results, we found that MEG and 
EEG also captured partly unique aspects of visual representations. Those unique 
components emerged earlier in time for MEG than for EEG. Identifying the sources 
of those unique components with fMRI, we found the locus for both MEG and EEG in 
high-level visual cortex, and in addition for MEG in low-level visual cortex. 
Together, our results show that multivariate analyses of MEG and EEG data offer 
a convergent and complimentary view on neural processing, and motivate the wider 
adoption of these methods in both MEG and EEG research.

Copyright © 2017 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2017.07.023
PMID: 28716718 [Indexed for MEDLINE]


187. Neuroimage. 2017 Aug 15;157:486-499. doi: 10.1016/j.neuroimage.2017.06.023. Epub 
2017 Jun 12.

Low-frequency oscillations employ a general coding of the spatio-temporal 
similarity of dynamic faces.

Furl N(1), Lohse M(2), Pizzorni-Ferrarese F(3).

Author information:
(1)Department of Psychology, Royal Holloway, University of London, Surrey TW20 
0EX, United Kingdom; Cognition and Brain Sciences Unit, Medical Research 
Council, Cambridge CB2 7EF, United Kingdom. Electronic address: 
nicholas.furl@rhul.ac.uk.
(2)Cognition and Brain Sciences Unit, Medical Research Council, Cambridge CB2 
7EF, United Kingdom; Department of Physiology, Anatomy, and Genetics, University 
of Oxford, Oxford OX1 3QX, United Kingdom.
(3)Department of Psychology, Royal Holloway, University of London, Surrey TW20 
0EX, United Kingdom.

Brain networks use neural oscillations as information transfer mechanisms. 
Although the face perception network in occipitotemporal cortex is well-studied, 
contributions of oscillations to face representation remain an open question. We 
tested for links between oscillatory responses that encode facial dimensions and 
the theoretical proposal that faces are encoded in similarity-based "face 
spaces". We quantified similarity-based encoding of dynamic faces in 
magnetoencephalographic sensor-level oscillatory power for identity, expression, 
physical and perceptual similarity of facial form and motion. Our data show that 
evoked responses manifest physical and perceptual form similarity that 
distinguishes facial identities. Low-frequency induced oscillations (< 20Hz) 
manifested more general similarity structure, which was not limited to identity, 
and spanned physical and perceived form and motion. A supplementary 
fMRI-constrained source reconstruction implicated fusiform gyrus and V5 in this 
similarity-based representation. These findings introduce a potential link 
between "face space" encoding and oscillatory network communication, which 
generates new hypotheses about the potential oscillation-mediated mechanisms 
that might encode facial dimensions.

Copyright © 2017 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2017.06.023
PMCID: PMC6390175
PMID: 28619657 [Indexed for MEDLINE]


188. Neuroimage. 2017 Jun;153:221-231. doi: 10.1016/j.neuroimage.2017.04.025. Epub 
2017 Apr 12.

Trial timing and pattern-information analyses of fMRI data.

Zeithamova D(1), de Araujo Sanchez MA(2), Adke A(3).

Author information:
(1)University of Oregon, Department of Psychology, 1227 University of Oregon, 
Eugene, OR 97403, USA. Electronic address: dasa@uoregon.edu.
(2)University of Oregon, Department of Psychology, 1227 University of Oregon, 
Eugene, OR 97403, USA. Electronic address: dearaujo@uoregon.edu.
(3)University of Oregon, Department of Psychology, 1227 University of Oregon, 
Eugene, OR 97403, USA. Electronic address: aadke@uoregon.edu.

Pattern-information approaches to fMRI data analysis are becoming increasingly 
popular but few studies to date have investigated experimental design 
optimization for these analyses. Here, we tested several designs that varied in 
the number of trials and trial timing within fixed duration scans while 
participants encoded images of animals and tools. Trial timing conditions with 
fixed onset-to-onset timing ranged from slow 12-s trials with two repetitions of 
each item to quick 6-s trials with four repetitions per item. We also tested a 
jittered version of the quick design with 4-8s trials. We assessed the effect of 
trial timing on three dependent measures: category-level (animals vs. tools) 
decoding accuracy using a multivoxel pattern analysis, item-level (e.g., cat vs. 
dog vs. lion) information estimates using pattern similarity analysis, and 
memory effects comparing pattern similarity scores across repetitions of 
individual items subsequently remembered vs. forgotten. For single trial 
estimates, category decoding was equal across all trial timing conditions while 
item-level information and memory effects were better detected using slow trial 
timing. When modeling events on an item-by-item basis across all repetitions of 
a given item, a larger number of quick, regularly spaced trials provided an 
advantage over fewer slow trials for category decoding while item-level 
information was comparable across conditions. Jittered and non-jittered versions 
of the quick trial timing did not differ significantly in any analysis. These 
results will help inform experimental design choices in future studies planning 
to employ pattern-information analyses and demonstrate that design optimization 
guidelines developed for univariate analyses of a few conditions are not 
necessarily optimal for pattern-information analyses and condition-rich designs.

Copyright © 2017 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2017.04.025
PMID: 28411155 [Indexed for MEDLINE]


189. Cortex. 2017 May;90:88-102. doi: 10.1016/j.cortex.2017.02.017. Epub 2017 Mar 18.

Decoding levels of representation in reading: A representational similarity 
approach.

Fischer-Baum S(1), Bruggemann D(2), Gallego IF(2), Li DSP(3), Tamez ER(4).

Author information:
(1)Department of Psychology, Rice University, Houston, TX, USA. Electronic 
address: simon.j.fischer-baum@rice.edu.
(2)Department of Psychology, Rice University, Houston, TX, USA.
(3)Department of Cognitive Science, Johns Hopkins University, Baltimore, MD, 
USA.
(4)Center for Cognitive Neuroscience, University of Pennsylvania, Philadelphia, 
PA, USA.

Multiple levels of representation are involved in reading single words: visual 
representations of letter shape, orthographic representations of letter identity 
and order, phonological representations of the word's pronunciation, and 
semantic representations of its meaning. Previous lesion and neuroimaging 
studies have identified a network of regions recruited during word reading, 
including ventral occipital-temporal regions and the angular gyrus (AG). 
However, there is still debate about what information is being represented and 
processed in these regions. This study has two aims. The first is to help 
adjudicate between competing hypotheses concerning the role of ventral occipital 
cortex in reading. The second is to adjudicate between competing hypotheses 
concerning the role of the AG in reading. Participants read words in the scanner 
while performing a proper name detection task and we use a multivariate pattern 
analysis technique for analyzing fMRI data - representational similarity 
analysis (RSA) - to decode the type of information being represented in these 
regions based on computationally explicit theories. Distributed patterns of 
activation in the left ventral occipitotemporal cortex (vOT) and the AG show 
evidence of some type of orthographic processing, while the right hemisphere 
homologues of the vOT supports visual, but not orthographic, information 
processing of letter strings. In addition, there is evidence of left-lateralized 
semantic processing in the lvOT and evidence of top-down feedback in the lvOT. 
Taken together, these results suggest an interactive activation theory of visual 
word processing in which both the lvOT and lAG are neural loci of an 
orthographic level of representations.

Copyright © 2017 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cortex.2017.02.017
PMID: 28384482 [Indexed for MEDLINE]


190. Cereb Cortex. 2017 May 1;27(5):3064-3079. doi: 10.1093/cercor/bhx056.

Vocal Tract Images Reveal Neural Representations of Sensorimotor Transformation 
During Speech Imitation.

Carey D(1)(2)(3), Miquel ME(4)(5), Evans BG(6), Adank P(6), McGettigan 
C(1)(2)(7).

Author information:
(1)Department of Psychology, Royal Holloway, University of London, London TW20 
0EX, UK.
(2)Combined Universities Brain Imaging Centre, Royal Holloway, University of 
London, London TW20 0EX, UK.
(3)The Irish Longitudinal Study on Ageing (TILDA), Department of Medical 
Gerontology, Trinity College Dublin, Dublin, Ireland.
(4)William Harvey Research Institute, Queen Mary, University of London, London 
EC1M 6BQ, UK.
(5)Clinical Physics, Barts Health NHS Trust, London EC1A 7BE, UK.
(6)Department of Speech, Hearing & Phonetic Sciences, University College London, 
London WC1E 6BT, UK.
(7)Institute of Cognitive Neuroscience, University College London, London WC1N 
3AR, UK.

Imitating speech necessitates the transformation from sensory targets to vocal 
tract motor output, yet little is known about the representational basis of this 
process in the human brain. Here, we address this question by using real-time MR 
imaging (rtMRI) of the vocal tract and functional MRI (fMRI) of the brain in a 
speech imitation paradigm. Participants trained on imitating a native vowel and 
a similar nonnative vowel that required lip rounding. Later, participants 
imitated these vowels and an untrained vowel pair during separate fMRI and rtMRI 
runs. Univariate fMRI analyses revealed that regions including left inferior 
frontal gyrus were more active during sensorimotor transformation (ST) and 
production of nonnative vowels, compared with native vowels; further, ST for 
nonnative vowels activated somatomotor cortex bilaterally, compared with ST of 
native vowels. Using test representational similarity analysis (RSA) models 
constructed from participants' vocal tract images and from stimulus formant 
distances, we found that RSA searchlight analyses of fMRI data showed either 
type of model could be represented in somatomotor, temporal, cerebellar, and 
hippocampal neural activation patterns during ST. We thus provide the first 
evidence of widespread and robust cortical and subcortical neural representation 
of vocal tract and/or formant parameters, during prearticulatory ST.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/cercor/bhx056
PMCID: PMC5939209
PMID: 28334401 [Indexed for MEDLINE]


191. J Math Psychol. 2017 Feb;76(Pt B):184-197. doi: 10.1016/j.jmp.2016.10.007.

Fixed versus mixed RSA: Explaining visual representations by fixed and mixed 
feature sets from shallow and deep computational models.

Khaligh-Razavi SM(1), Henriksson L(2), Kay K(3), Kriegeskorte N(4).

Author information:
(1)MRC Cognition and Brain Sciences Unit, Cambridge, UK; Computer Science & 
Artificial intelligence Laboratory, Massachusetts Institute of Technology, 
Cambridge, MA, USA.
(2)MRC Cognition and Brain Sciences Unit, Cambridge, UK; Department of 
Neuroscience and Biomedical Engineering, Aalto University, Espoo, Finland.
(3)Department of Psychology, Washington University in St. Louis, St. Louis, MO, 
USA.
(4)MRC Cognition and Brain Sciences Unit, Cambridge, UK.

Studies of the primate visual system have begun to test a wide range of complex 
computational object-vision models. Realistic models have many parameters, which 
in practice cannot be fitted using the limited amounts of brain-activity data 
typically available. Task performance optimization (e.g. using backpropagation 
to train neural networks) provides major constraints for fitting parameters and 
discovering nonlinear representational features appropriate for the task (e.g. 
object classification). Model representations can be compared to brain 
representations in terms of the representational dissimilarities they predict 
for an image set. This method, called representational similarity analysis 
(RSA), enables us to test the representational feature space as is (fixed RSA) 
or to fit a linear transformation that mixes the nonlinear model features so as 
to best explain a cortical area's representational space (mixed RSA). Like 
voxel/population-receptive-field modelling, mixed RSA uses a training set 
(different stimuli) to fit one weight per model feature and response channel 
(voxels here), so as to best predict the response profile across images for each 
response channel. We analysed response patterns elicited by natural images, 
which were measured with functional magnetic resonance imaging (fMRI). We found 
that early visual areas were best accounted for by shallow models, such as a 
Gabor wavelet pyramid (GWP). The GWP model performed similarly with and without 
mixing, suggesting that the original features already approximated the 
representational space, obviating the need for mixing. However, a higher 
ventral-stream visual representation (lateral occipital region) was best 
explained by the higher layers of a deep convolutional network and mixing of its 
feature set was essential for this model to explain the representation. We 
suspect that mixing was essential because the convolutional network had been 
trained to discriminate a set of 1000 categories, whose frequencies in the 
training set did not match their frequencies in natural experience or their 
behavioural importance. The latter factors might determine the representational 
prominence of semantic dimensions in higher-level ventral-stream areas. Our 
results demonstrate the benefits of testing both the specific representational 
hypothesis expressed by a model's original feature space and the hypothesis 
space generated by linear transformations of that feature space.

DOI: 10.1016/j.jmp.2016.10.007
PMCID: PMC5341758
PMID: 28298702


192. Neural Plast. 2017;2017:2761913. doi: 10.1155/2017/2761913. Epub 2017 Feb 8.

The Cognitive Neuroplasticity of Reading Recovery following Chronic Stroke: A 
Representational Similarity Analysis Approach.

Fischer-Baum S(1), Jang A(1), Kajander D(2).

Author information:
(1)Department of Psychology, Rice University, Houston, TX, USA.
(2)Department of Psychology, University of Massachusetts, Amherst, MA, USA.

Damage to certain left hemisphere regions leads to reading impairments, at least 
acutely, though some individuals eventually recover reading. Previous 
neuroimaging studies have shown a relationship between reading recovery and 
increases in contralesional and perilesional activation during word reading 
tasks, relative to controls. Questions remain about how to interpret these 
changes in activation. Do these changes reflect functional take-over, a 
reorganization of functions in the damaged brain? Or do they reveal compensatory 
masquerade or the use of alternative neural pathways to reading that are 
available in both patients and controls? We address these questions by studying 
a single individual, CH, who has made a partial recovery of reading familiar 
words following stroke. We use an fMRI analysis technique, representational 
similarity analysis (RSA), which allows us to decode cognitive function from 
distributed patterns of neural activity. Relative to controls, we find that CH 
shows a shift from visual to orthographic processing in contralesional regions, 
with a marginally significant result in perilesional regions as well. This 
pattern supports a contralesional reorganization of orthographic processing 
following stroke. More generally, these analyses demonstrate how powerful RSA 
can be for mapping the neural plasticity of language function.

DOI: 10.1155/2017/2761913
PMCID: PMC5320323
PMID: 28270937 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no competing 
interests.


193. J Neurosci. 2017 Mar 15;37(11):2986-2998. doi: 10.1523/JNEUROSCI.2324-16.2017. 
Epub 2017 Feb 15.

Transformed Neural Pattern Reinstatement during Episodic Memory Retrieval.

Xiao X(1)(2), Dong Q(1)(2), Gao J(3), Men W(3), Poldrack RA(4), Xue G(5)(2).

Author information:
(1)State Key Laboratory of Cognitive Neuroscience and Learning and IDG/McGovern 
Institute of Brain Research, Beijing Normal University, Beijing 100875, PR 
China.
(2)Center for Collaboration and Innovation in Brain and Learning Sciences, 
Beijing Normal University, Beijing 100875, PR China.
(3)Center for MRI Research and Beijing City Key Laboratory for Medical Physics 
and Engineering, School of Physics and McGovern Institute for Brain Research, 
Peking University, Beijing 100871, PR China, and.
(4)Department of Psychology, Stanford University, Stanford, California 94305.
(5)State Key Laboratory of Cognitive Neuroscience and Learning and IDG/McGovern 
Institute of Brain Research, Beijing Normal University, Beijing 100875, PR 
China, guixue@gmail.com.

Contemporary models of episodic memory posit that remembering involves the 
reenactment of encoding processes. Although encoding-retrieval similarity has 
been consistently reported and linked to memory success, the nature of neural 
pattern reinstatement is poorly understood. Using high-resolution fMRI on human 
subjects, our results obtained clear evidence for item-specific pattern 
reinstatement in the frontoparietal cortex, even when the encoding-retrieval 
pairs shared no perceptual similarity. No item-specific pattern reinstatement 
was found in the ventral visual cortex. Importantly, the brain regions and 
voxels carrying item-specific representation differed significantly between 
encoding and retrieval, and the item specificity for encoding-retrieval 
similarity was smaller than that for encoding or retrieval, suggesting different 
nature of representations between encoding and retrieval. Moreover, cross-region 
representational similarity analysis suggests that the encoded representation in 
the ventral visual cortex was reinstated in the frontoparietal cortex during 
retrieval. Together, these results suggest that, in addition to reinstatement of 
the originally encoded pattern in the brain regions that perform encoding 
processes, retrieval may also involve the reinstatement of a transformed 
representation of the encoded information. These results emphasize the 
constructive nature of memory retrieval that helps to serve important adaptive 
functions.SIGNIFICANCE STATEMENT Episodic memory enables humans to vividly 
reexperience past events, yet how this is achieved at the neural level is barely 
understood. A long-standing hypothesis posits that memory retrieval involves the 
faithful reinstatement of encoding-related activity. We tested this hypothesis 
by comparing the neural representations during encoding and retrieval. We found 
strong pattern reinstatement in the frontoparietal cortex, but not in the 
ventral visual cortex, that represents visual details. Critically, even within 
the same brain regions, the nature of representation during retrieval was 
qualitatively different from that during encoding. These results suggest that 
memory retrieval is not a faithful replay of past event but rather involves 
additional constructive processes to serve adaptive functions.

Copyright © 2017 the authors 0270-6474/17/372986-13$15.00/0.

DOI: 10.1523/JNEUROSCI.2324-16.2017
PMCID: PMC6596730
PMID: 28202612 [Indexed for MEDLINE]


194. Cereb Cortex. 2017 Jan 1;27(1):310-321. doi: 10.1093/cercor/bhw419.

Task Context Overrules Object- and Category-Related Representational Content in 
the Human Parietal Cortex.

Bracci S(1), Daniels N(1), Op de Beeck H(1).

Author information:
(1)Laboratory of Biological Psychology, KU Leuven3000, Leuven, Belgium.

The dorsal, parietal visual stream is activated when seeing objects, but the 
exact nature of parietal object representations is still under discussion. Here 
we test 2 specific hypotheses. First, parietal cortex is biased to host some 
representations more than others, with a different bias compared with ventral 
areas. A prime example would be object action representations. Second, parietal 
cortex forms a general multiple-demand network with frontal areas, showing 
similar task effects and representational content compared with frontal areas. 
To differentiate between these hypotheses, we implemented a human neuroimaging 
study with a stimulus set that dissociates associated object action from object 
category while manipulating task context to be either action- or 
category-related. Representations in parietal as well as prefrontal areas 
represented task-relevant object properties (action representations in the 
action task), with no sign of the irrelevant object property (category 
representations in the action task). In contrast, irrelevant object properties 
were represented in ventral areas. These findings emphasize that human parietal 
cortex does not preferentially represent particular object properties 
irrespective of task, but together with frontal areas is part of a 
multiple-demand and content-rich cortical network representing task-relevant 
object properties.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/cercor/bhw419
PMCID: PMC5939221
PMID: 28108492 [Indexed for MEDLINE]


195. J Neurosci. 2017 Jan 18;37(3):562-575. doi: 10.1523/JNEUROSCI.1717-16.2016.

Action Categories in Lateral Occipitotemporal Cortex Are Organized Along 
Sociality and Transitivity.

Wurm MF(1)(2), Caramazza A(3)(2), Lingnau A(2)(4)(5).

Author information:
(1)Cognitive Neuropsychology Laboratory, Harvard University, Cambridge, 
Massachusetts 02138, mwurm@fas.harvard.edu.
(2)Center for Mind/Brain Sciences, University of Trento, 38068 Rovereto (TN), 
Italy.
(3)Cognitive Neuropsychology Laboratory, Harvard University, Cambridge, 
Massachusetts 02138.
(4)Department of Psychology, Royal Holloway University of London, TW20 0EX 
Egham, Surrey, United Kingdom, and.
(5)Department of Cognitive Sciences, University of Trento, 38068 Rovereto (TN), 
Italy.

Comment in
    J Neurosci. 2017 May 17;37(20):5048-5050.

How neural specificity for distinct conceptual knowledge categories arises is 
central for understanding the organization of semantic memory in the human 
brain. Although there is a large body of research on the neural processing of 
distinct object categories, the organization of action categories remains 
largely unknown. In particular, it is unknown whether different action 
categories follow a specific topographical organization on the cortical surface 
analogously to the category-specific organization of object knowledge. Here, we 
tested whether the neural representation of action knowledge is organized in 
terms of nonsocial versus social and object-unrelated versus object-related 
actions (sociality and transitivity, respectively, hereafter). We hypothesized a 
major distinction of sociality and transitivity along dorsal and ventral lateral 
occipitotemporal cortex (LOTC), respectively. Using fMRI-based multivoxel 
pattern analysis, we identified neural representations of action information 
associated with sociality and transitivity in bilateral LOTC. Representational 
similarity analysis revealed a dissociation between dorsal and ventral LOTC. We 
found that action representations in dorsal LOTC are segregated along features 
of sociality, whereas action representations in ventral LOTC are segregated 
along features of transitivity. In addition, representations of sociality and 
transitivity features were found more anteriorly in LOTC than representations of 
specific subtypes of actions, suggesting a posterior-anterior gradient from 
concrete to abstract action features. These findings elucidate how the neural 
representations of perceptually and conceptually diverse actions are organized 
in distinct subsystems in the LOTC.
SIGNIFICANCE STATEMENT: The lateral occipitotemporal cortex (LOTC) is critically 
involved in the recognition of objects and actions, but our knowledge about the 
underlying organizing principles is limited. Here, we discovered a 
dorsal-ventral distinction of actions in LOTC: dorsal LOTC represents actions 
based on sociality (how much an action is directed to another person) in 
proximity to person knowledge. In contrast, ventral LOTC represents actions 
based on transitivity (how much an action involves the interaction with 
inanimate objects) in proximity to tools/artifacts in ventral LOTC, suggesting a 
mutually dependent organization of actions and objects. In addition, we found a 
posterior-to-anterior organization of the LOTC for concrete and abstract 
representations, respectively. Our findings provide important insights about the 
organization of actions in LOTC.

Copyright © 2017 the authors 0270-6474/17/370562-14$15.00/0.

DOI: 10.1523/JNEUROSCI.1717-16.2016
PMCID: PMC6596756
PMID: 28100739 [Indexed for MEDLINE]


196. Cereb Cortex. 2017 Jan 1;27(1):294-309. doi: 10.1093/cercor/bhw379.

Representational Similarity Mapping of Distributional Semantics in Left Inferior 
Frontal, Middle Temporal, and Motor Cortex.

Carota F(1)(2)(3)(4), Kriegeskorte N(1), Nili H(1)(5), Pulvermüller F(1)(3)(4).

Author information:
(1)MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, 
UK.
(2)Department of Psychology, University of Cambridge, Downing Street, Cambridge 
CB2 3EB, UK.
(3)Berlin School of Mind and Brain, Humboldt Universität zu Berlin, Unter den 
Linden 6, 10099 Berlin, Germany.
(4)Department of Philosophy and Humanities, Brain Language Laboratory, WE4, 
Freie Universität Berlin, 19145 Berlin, Germany.
(5)Department of Experimental Psychology, University of Oxford, Tinbergen 
Building, 9 South Parks Road, Oxford OX1 3UD, UK.

Language comprehension engages a distributed network of frontotemporal, 
parietal, and sensorimotor regions, but it is still unclear how meaning of words 
and their semantic relationships are represented and processed within these 
regions and to which degrees lexico-semantic representations differ between 
regions and semantic types. We used fMRI and representational similarity 
analysis to relate word-elicited multivoxel patterns to semantic similarity 
between action and object words. In left inferior frontal (BA 44-45-47), left 
posterior middle temporal and left precentral cortex, the similarity of brain 
response patterns reflected semantic similarity among action-related verbs, as 
well as across lexical classes-between action verbs and tool-related nouns and, 
to a degree, between action verbs and food nouns, but not between action verbs 
and animal nouns. Instead, posterior inferior temporal cortex exhibited a 
reverse response pattern, which reflected the semantic similarity among 
object-related nouns, but not action-related words. These results show that 
semantic similarity is encoded by a range of cortical areas, including 
multimodal association (e.g., anterior inferior frontal, posterior middle 
temporal) and modality-preferential (premotor) cortex and that the 
representational geometries in these regions are partly dependent on semantic 
type, with semantic similarity among action-related words crossing 
lexical-semantic category boundaries.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/cercor/bhw379
PMCID: PMC6044349
PMID: 28077514 [Indexed for MEDLINE]


197. J Neurosci. 2017 Feb 1;37(5):1257-1268. doi: 10.1523/JNEUROSCI.1407-16.2016. 
Epub 2016 Dec 27.

Idiosyncratic Patterns of Representational Similarity in Prefrontal Cortex 
Predict Attentional Performance.

Lee J(1), Geng JJ(2).

Author information:
(1)Center for Mind and Brain, University of California, Davis, Davis, California 
95618 jmslee@ucdavis.edu.
(2)Center for Mind and Brain, University of California, Davis, Davis, California 
95618.

The efficiency of finding an object in a crowded environment depends largely on 
the similarity of nontargets to the search target. Models of attention theorize 
that the similarity is determined by representations stored within an 
"attentional template" held in working memory. However, the degree to which the 
contents of the attentional template are individually unique and where those 
idiosyncratic representations are encoded in the brain are unknown. We 
investigated this problem using representational similarity analysis of human 
fMRI data to measure the common and idiosyncratic representations of famous face 
morphs during an identity categorization task; data from the categorization task 
were then used to predict performance on a separate identity search task. We 
hypothesized that the idiosyncratic categorical representations of the 
continuous face morphs would predict their distractability when searching for 
each target identity. The results identified that patterns of activation in the 
lateral prefrontal cortex (LPFC) as well as in face-selective areas in the 
ventral temporal cortex were highly correlated with the patterns of behavioral 
categorization of face morphs and search performance that were common across 
subjects. However, the individually unique components of the categorization 
behavior were reliably decoded only in right LPFC. Moreover, the neural pattern 
in right LPFC successfully predicted idiosyncratic variability in search 
performance, such that reaction times were longer when distractors had a higher 
probability of being categorized as the target identity. These results suggest 
that the prefrontal cortex encodes individually unique components of categorical 
representations that are also present in attentional templates for target 
search.
SIGNIFICANCE STATEMENT: Everyone's perception of the world is uniquely shaped by 
personal experiences and preferences. Using functional MRI, we show that 
individual differences in the categorization of face morphs between two 
identities could be decoded from the prefrontal cortex and the ventral temporal 
cortex. Moreover, the individually unique representations in prefrontal cortex 
predicted idiosyncratic variability in attentional performance when looking for 
each identity in the "crowd" of another morphed face in a separate search task. 
Our results reveal that the representation of task-related information in 
prefrontal cortex is individually unique and preserved across categorization and 
search performance. This demonstrates the possibility of predicting individual 
behaviors across tasks with patterns of brain activity.

Copyright © 2017 the authors 0270-6474/17/371257-12$15.00/0.

DOI: 10.1523/JNEUROSCI.1407-16.2016
PMCID: PMC6596852
PMID: 28028199 [Indexed for MEDLINE]


198. Cereb Cortex. 2018 Feb 1;28(2):549-560. doi: 10.1093/cercor/bhw389.

Spatiotemporal Dynamics of Attention Networks Revealed by Representational 
Similarity Analysis of EEG and fMRI.

Salmela V(1)(2), Salo E(1)(2), Salmi J(1)(2)(3), Alho K(1)(2).

Author information:
(1)Division of Cognitive Psychology and Neuropsychology, Institute of Behavioral 
Sciences, University of Helsinki, FI-00014 Helsinki, Finland.
(2)Advanced Magnetic Imaging Centre, Aalto NeuroImaging, Aalto University, Espoo 
FI-00076, Finland.
(3)Faculty of Arts, Psychology and Theology, Åbo Akademi University, FI-20500 
Turku, Finland.

The fronto-parietal attention networks have been extensively studied with 
functional magnetic resonance imaging (fMRI), but spatiotemporal dynamics of 
these networks are not well understood. We measured event-related potentials 
(ERPs) with electroencephalography (EEG) and collected fMRI data from identical 
experiments where participants performed visual and auditory discrimination 
tasks separately or simultaneously and with or without distractors. To overcome 
the low temporal resolution of fMRI, we used a novel ERP-based application of 
multivariate representational similarity analysis (RSA) to parse time-averaged 
fMRI pattern activity into distinct spatial maps that each corresponded, in 
representational structure, to a short temporal ERP segment. Discriminant 
analysis of ERP-fMRI correlations revealed 8 cortical networks-2 sensory, 3 
attention, and 3 other-segregated by 4 orthogonal, temporally multifaceted and 
spatially distributed functions. We interpret these functions as 4 
spatiotemporal components of attention: modality-dependent and stimulus-driven 
orienting, top-down control, mode transition, and response preparation, 
selection and execution.

© The Author 2016. Published by Oxford University Press. All rights reserved. 
For Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhw389
PMID: 27999122 [Indexed for MEDLINE]


199. J Neurosci. 2016 Dec 7;36(49):12412-12424. doi: 10.1523/JNEUROSCI.2889-15.2016.

Coding of Event Nodes and Narrative Context in the Hippocampus.

Milivojevic B(1), Varadinov M(2), Vicente Grabovetsky A(2), Collin SH(2), 
Doeller CF(1)(3).

Author information:
(1)Donders Institute for Brain, Cognition and Behaviour, Radboud University, 
6525 EN Nijmegen, The Netherlands; b.milivojevic@donders.ru.nl 
christian.doeller@donders.ru.nl.
(2)Donders Institute for Brain, Cognition and Behaviour, Radboud University, 
6525 EN Nijmegen, The Netherlands.
(3)Kavli Institute for Systems Neuroscience, Centre for Neural Computation, Egil 
and Pauline Braathen and Fred Kavli Centre for Cortical Microcircuits, NTNU, 
Norwegian University of Science and Technology; Department of Radiology and 
Nuclear Medicine, St. Olavs Hospital, Trondheim University Hospital, 7030 
Trondheim, Norway.

Erratum in
    J Neurosci. 2017 May 31;37(22):5588.

Comment in
    J Neurosci. 2017 Jun 21;37(25):5975-5977.

Narratives may provide a general context, unrestricted by space and time, which 
can be used to organize episodic memories into networks of related events. 
However, it is not clear how narrative contexts are represented in the brain. 
Here we test the novel hypothesis that the formation of narrative-based 
contextual representations in humans relies on the same hippocampal mechanisms 
that enable formation of spatiotemporal contexts in rodents. Participants 
watched a movie consisting of two interleaved narratives while we monitored 
their brain activity using fMRI. We used representational similarity analysis, a 
type of multivariate pattern analysis, which uses across-voxel correlations as a 
proxy for neural-pattern similarity, to examine whether the patterns of neural 
activity can be used to differentiate between narratives and recurring narrative 
elements, such as people and locations. We demonstrate that the neural activity 
patterns in the hippocampus differentiate between event nodes (people and 
locations) and narratives (different stories) and that these narrative-context 
representations diverge gradually over time akin to remapping-induced spatial 
maps represented by rodent place cells.
SIGNIFICANCE STATEMENT: Narratives, especially in movie format, are very 
engaging and can be used to investigate neural mechanisms underlying cognitive 
functions in more naturalistic settings than that of traditional paradigms. 
Narratives also provide a more general context, unrestricted by space and time, 
that can be used to organize memories into networks of related events. For this 
reason, narratives are ideally suited to engage neural mechanisms underlying 
episodic memory formation. In this study, participants watched a movie with two 
interleaved narratives while their brain activity was monitored using fMRI. We 
show that the hippocampus, which is involved in formation of spatiotemporal 
contexts in episodic memory, also represents gradually diverging narrative 
contexts as well as narrative elements, such as people and locations.

Copyright © 2016 the authors 0270-6474/16/3612412-13$15.00/0.

DOI: 10.1523/JNEUROSCI.2889-15.2016
PMCID: PMC6601969
PMID: 27927958 [Indexed for MEDLINE]


200. J Neurophysiol. 2017 Jan 1;117(1):388-402. doi: 10.1152/jn.00569.2016. Epub 2016 
Nov 2.

Visual search for object categories is predicted by the representational 
architecture of high-level visual cortex.

Cohen MA(1), Alvarez GA(2), Nakayama K(2), Konkle T(2).

Author information:
(1)McGovern Institute for Brain Research, Department of Brain and Cognitive 
Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts; and 
michaelthecohen@gmail.com.
(2)Department of Psychology, Harvard University, Cambridge, Massachusetts.

Visual search is a ubiquitous visual behavior, and efficient search is essential 
for survival. Different cognitive models have explained the speed and accuracy 
of search based either on the dynamics of attention or on similarity of item 
representations. Here, we examined the extent to which performance on a visual 
search task can be predicted from the stable representational architecture of 
the visual system, independent of attentional dynamics. Participants performed a 
visual search task with 28 conditions reflecting different pairs of categories 
(e.g., searching for a face among cars, body among hammers, etc.). The time it 
took participants to find the target item varied as a function of category 
combination. In a separate group of participants, we measured the neural 
responses to these object categories when items were presented in isolation. 
Using representational similarity analysis, we then examined whether the 
similarity of neural responses across different subdivisions of the visual 
system had the requisite structure needed to predict visual search performance. 
Overall, we found strong brain/behavior correlations across most of the 
higher-level visual system, including both the ventral and dorsal pathways when 
considering both macroscale sectors as well as smaller mesoscale regions. These 
results suggest that visual search for real-world object categories is well 
predicted by the stable, task-independent architecture of the visual system.
NEW & NOTEWORTHY: Here, we ask which neural regions have neural response 
patterns that correlate with behavioral performance in a visual processing task. 
We found that the representational structure across all of high-level visual 
cortex has the requisite structure to predict behavior. Furthermore, when 
directly comparing different neural regions, we found that they all had highly 
similar category-level representational structures. These results point to a 
ubiquitous and uniform representational structure in high-level visual cortex 
underlying visual object processing.

Copyright © 2017 the American Physiological Society.

DOI: 10.1152/jn.00569.2016
PMCID: PMC5236111
PMID: 27832600 [Indexed for MEDLINE]


201. J Cogn Neurosci. 2017 Apr;29(4):677-697. doi: 10.1162/jocn_a_01068. Epub 2016 
Oct 25.

Decoding Dynamic Brain Patterns from Evoked Responses: A Tutorial on 
Multivariate Pattern Analysis Applied to Time Series Neuroimaging Data.

Grootswagers T(1)(2)(3), Wardle SG(1)(2), Carlson TA(2)(3).

Author information:
(1)Macquarie University, Sydney, Australia.
(2)ARC Centre of Excellence in Cognition and its Disorders.
(3)University of Sydney.

Multivariate pattern analysis (MVPA) or brain decoding methods have become 
standard practice in analyzing fMRI data. Although decoding methods have been 
extensively applied in brain-computer interfaces, these methods have only 
recently been applied to time series neuroimaging data such as MEG and EEG to 
address experimental questions in cognitive neuroscience. In a tutorial style 
review, we describe a broad set of options to inform future time series decoding 
studies from a cognitive neuroscience perspective. Using example MEG data, we 
illustrate the effects that different options in the decoding analysis pipeline 
can have on experimental results where the aim is to "decode" different 
perceptual stimuli or cognitive states over time from dynamic brain activation 
patterns. We show that decisions made at both preprocessing (e.g., 
dimensionality reduction, subsampling, trial averaging) and decoding (e.g., 
classifier selection, cross-validation design) stages of the analysis can 
significantly affect the results. In addition to standard decoding, we describe 
extensions to MVPA for time-varying neuroimaging data including representational 
similarity analysis, temporal generalization, and the interpretation of 
classifier weight maps. Finally, we outline important caveats in the design and 
interpretation of time series decoding experiments.

DOI: 10.1162/jocn_a_01068
PMID: 27779910 [Indexed for MEDLINE]


202. Front Hum Neurosci. 2016 Sep 21;10:435. doi: 10.3389/fnhum.2016.00435. 
eCollection 2016.

Is the Sensorimotor Cortex Relevant for Speech Perception and Understanding? An 
Integrative Review.

Schomers MR(1), Pulvermüller F(1).

Author information:
(1)Brain Language Laboratory, Department of Philosophy and Humanities, Freie 
Universität BerlinBerlin, Germany; Berlin School of Mind and Brain, 
Humboldt-Universität zu BerlinBerlin, Germany.

In the neuroscience of language, phonemes are frequently described as multimodal 
units whose neuronal representations are distributed across perisylvian cortical 
regions, including auditory and sensorimotor areas. A different position views 
phonemes primarily as acoustic entities with posterior temporal localization, 
which are functionally independent from frontoparietal articulatory programs. To 
address this current controversy, we here discuss experimental results from 
functional magnetic resonance imaging (fMRI) as well as transcranial magnetic 
stimulation (TMS) studies. On first glance, a mixed picture emerges, with 
earlier research documenting neurofunctional distinctions between phonemes in 
both temporal and frontoparietal sensorimotor systems, but some recent work 
seemingly failing to replicate the latter. Detailed analysis of methodological 
differences between studies reveals that the way experiments are set up explains 
whether sensorimotor cortex maps phonological information during speech 
perception or not. In particular, acoustic noise during the experiment and 
'motor noise' caused by button press tasks work against the frontoparietal 
manifestation of phonemes. We highlight recent studies using sparse imaging and 
passive speech perception tasks along with multivariate pattern analysis (MVPA) 
and especially representational similarity analysis (RSA), which succeeded in 
separating acoustic-phonological from general-acoustic processes and in mapping 
specific phonological information on temporal and frontoparietal regions. The 
question about a causal role of sensorimotor cortex on speech perception and 
understanding is addressed by reviewing recent TMS studies. We conclude that 
frontoparietal cortices, including ventral motor and somatosensory areas, 
reflect phonological information during speech perception and exert a causal 
influence on language understanding.

DOI: 10.3389/fnhum.2016.00435
PMCID: PMC5030253
PMID: 27708566


203. Cereb Cortex. 2017 Nov 1;27(11):5197-5210. doi: 10.1093/cercor/bhw300.

Orthographic and Phonological Representations in the Fusiform Cortex.

Zhao L(1)(2), Chen C(1)(2), Shao L(1)(2), Wang Y(1)(2), Xiao X(1)(2), Chen C(3), 
Yang J(4), Zevin J(5), Xue G(1)(2).

Author information:
(1)State Key Laboratory of Cognitive Neuroscience and Learning & IDG/McGovern 
Institute for Brain Research, Beijing Normal University, Beijing 100875, PR 
China.
(2)Center for Collaboration and Innovation in Brain and Learning Sciences, 
Beijing Normal University, Beijing 100875, PR China.
(3)Department of Psychology and Social Behavior, University of California, 
Irvine, CA 92697, USA.
(4)School of Psychology, Shanxi Normal University, Xi'an 710062, PR China.
(5)Department of Linguistics, University of Southern California, Los Angeles, CA 
90089, USA.

Mental and neural representations of words are at the core of understanding the 
cognitive and neural mechanisms of reading. Despite extensive studies, the 
nature of visual word representation remains highly controversial due to 
methodological limitations. In particular, it is unclear whether the fusiform 
cortex contains only abstract orthographic representation, or represents both 
lower and higher level orthography as well as phonology. Using representational 
similarity analysis, we integrated behavioral ratings, computational models of 
reading and visual object recognition, and neuroimaging data to examine the 
nature of visual word representations in the fusiform cortex. Our results 
provided clear evidence that the middle and anterior fusiform represented both 
phonological and orthographic information. Whereas lower level orthographic 
information was represented at every stage of the ventral visual stream, 
abstract orthographic information was increasingly represented along the 
posterior-to-anterior axis. Furthermore, the left and right hemispheres were 
tuned to high- and low-frequency orthographic information, respectively. These 
results help to resolve the long-standing debates regarding the role of the 
fusiform in reading, and have significant implications for the development of 
psychological, neural, and computational theories of reading.

© The Author 2016. Published by Oxford University Press. All rights reserved. 
For Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/cercor/bhw300
PMID: 27664959 [Indexed for MEDLINE]


204. Neuroimage. 2016 Dec;143:128-140. doi: 10.1016/j.neuroimage.2016.08.068. Epub 
2016 Sep 1.

Word meaning in the ventral visual path: a perceptual to conceptual gradient of 
semantic coding.

Borghesani V(1), Pedregosa F(2), Buiatti M(3), Amadon A(4), Eger E(5), Piazza 
M(3).

Author information:
(1)École Doctorale Cerveau-Cognition-Comportement, Université Pierre et Marie 
Curie, Paris 6, 75005 Paris, France; Cognitive Neuroimaging Unit, CEA DRF/I2BM, 
INSERM, Université Paris-Sud, Université Paris-Saclay, NeuroSpin center, 91191 
Gif/Yvette, France; NeuroSpin Center, Institute of BioImaging, Commissariat à 
l'Energie Atomique, F-91191 Gif/Yvette, France; Center for Mind/Brain Sciences, 
University of Trento, 38068 Rovereto, Italy. Electronic address: 
valentinaborghesani@gmail.com.
(2)Parietal, INRIA, 91191 Gif/Yvette, France; Centre De Recherche en 
Mathématiques de la Décision, CNRS-UMR, Université PARIS - DAUPHINE, 7534 Paris, 
France.
(3)Cognitive Neuroimaging Unit, CEA DRF/I2BM, INSERM, Université Paris-Sud, 
Université Paris-Saclay, NeuroSpin center, 91191 Gif/Yvette, France; NeuroSpin 
Center, Institute of BioImaging, Commissariat à l'Energie Atomique, F-91191 
Gif/Yvette, France; Center for Mind/Brain Sciences, University of Trento, 38068 
Rovereto, Italy.
(4)NeuroSpin Center, Institute of BioImaging, Commissariat à l'Energie Atomique, 
F-91191 Gif/Yvette, France.
(5)Cognitive Neuroimaging Unit, CEA DRF/I2BM, INSERM, Université Paris-Sud, 
Université Paris-Saclay, NeuroSpin center, 91191 Gif/Yvette, France; NeuroSpin 
Center, Institute of BioImaging, Commissariat à l'Energie Atomique, F-91191 
Gif/Yvette, France.

The meaning of words referring to concrete items is thought of as a 
multidimensional representation that includes both perceptual (e.g., average 
size, prototypical color) and conceptual (e.g., taxonomic class) dimensions. Are 
these different dimensions coded in different brain regions? In healthy human 
subjects, we tested the presence of a mapping between the implied real object 
size (a perceptual dimension) and the taxonomic categories at different levels 
of specificity (conceptual dimensions) of a series of words, and the patterns of 
brain activity recorded with functional magnetic resonance imaging in six areas 
along the ventral occipito-temporal cortical path. Combining multivariate 
pattern classification and representational similarity analysis, we found that 
the real object size implied by a word appears to be primarily encoded in early 
visual regions, while the taxonomic category and sub-categorical cluster in more 
anterior temporal regions. This anteroposterior gradient of information content 
indicates that different areas along the ventral stream encode complementary 
dimensions of the semantic space.

Copyright Â© 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2016.08.068
PMID: 27592809 [Indexed for MEDLINE]


205. Philos Trans R Soc Lond B Biol Sci. 2016 Oct 5;371(1705):20160278. doi: 
10.1098/rstb.2016.0278.

Inferring brain-computational mechanisms with models of activity measurements.

Kriegeskorte N(1), Diedrichsen J(2).

Author information:
(1)Medical Research Council Cognition and Brain Sciences Unit, Cambridge, UK 
nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk.
(2)Brain and Mind Institute, Department of Computer Science and Department of 
Statistical and Actuarial Sciences, Western University, London, Ontario, Canada.

High-resolution functional imaging is providing increasingly rich measurements 
of brain activity in animals and humans. A major challenge is to leverage such 
data to gain insight into the brain's computational mechanisms. The first step 
is to define candidate brain-computational models (BCMs) that can perform the 
behavioural task in question. We would then like to infer which of the candidate 
BCMs best accounts for measured brain-activity data. Here we describe a method 
that complements each BCM by a measurement model (MM), which simulates the way 
the brain-activity measurements reflect neuronal activity (e.g. local averaging 
in functional magnetic resonance imaging (fMRI) voxels or sparse sampling in 
array recordings). The resulting generative model (BCM-MM) produces simulated 
measurements. To avoid having to fit the MM to predict each individual 
measurement channel of the brain-activity data, we compare the measured and 
predicted data at the level of summary statistics. We describe a novel 
particular implementation of this approach, called probabilistic 
representational similarity analysis (pRSA) with MMs, which uses 
representational dissimilarity matrices (RDMs) as the summary statistics. We 
validate this method by simulations of fMRI measurements (locally averaging 
voxels) based on a deep convolutional neural network for visual object 
recognition. Results indicate that the way the measurements sample the activity 
patterns strongly affects the apparent representational dissimilarities. 
However, modelling of the measurement process can account for these effects, and 
different BCMs remain distinguishable even under substantial noise. The pRSA 
method enables us to perform Bayesian inference on the set of BCMs and to 
recognize the data-generating model in each case.This article is part of the 
themed issue 'Interpreting BOLD: a dialogue between cognitive and cellular 
neuroscience'.

© 2016 The Authors.

DOI: 10.1098/rstb.2016.0278
PMCID: PMC5003864
PMID: 27574316 [Indexed for MEDLINE]


206. Proc Natl Acad Sci U S A. 2016 Sep 6;113(36):10180-5. doi: 
10.1073/pnas.1610686113. Epub 2016 Aug 22.

Semantic representations in the temporal pole predict false memories.

Chadwick MJ(1), Anjum RS(2), Kumaran D(3), Schacter DL(4), Spiers HJ(2), 
Hassabis D(3).

Author information:
(1)Google DeepMind, London EC4A 3TW, United Kingdom; Division of Psychology and 
Language Sciences, Department of Experimental Psychology, Institute of 
Behavioural Neuroscience, University College London, London WC1H 0AP, United 
Kingdom; mjchadwick@google.com dls@wjh.harvard.edu.
(2)Division of Psychology and Language Sciences, Department of Experimental 
Psychology, Institute of Behavioural Neuroscience, University College London, 
London WC1H 0AP, United Kingdom;
(3)Google DeepMind, London EC4A 3TW, United Kingdom;
(4)Department of Psychology, Harvard University, Cambridge, MA 02138; Center for 
Brain Science, Harvard University, Cambridge, MA 02138 mjchadwick@google.com 
dls@wjh.harvard.edu.

Recent advances in neuroscience have given us unprecedented insight into the 
neural mechanisms of false memory, showing that artificial memories can be 
inserted into the memory cells of the hippocampus in a way that is 
indistinguishable from true memories. However, this alone is not enough to 
explain how false memories can arise naturally in the course of our daily lives. 
Cognitive psychology has demonstrated that many instances of false memory, both 
in the laboratory and the real world, can be attributed to semantic 
interference. Whereas previous studies have found that a diverse set of regions 
show some involvement in semantic false memory, none have revealed the nature of 
the semantic representations underpinning the phenomenon. Here we use fMRI with 
representational similarity analysis to search for a neural code consistent with 
semantic false memory. We find clear evidence that false memories emerge from a 
similarity-based neural code in the temporal pole, a region that has been called 
the "semantic hub" of the brain. We further show that each individual has a 
partially unique semantic code within the temporal pole, and this unique code 
can predict idiosyncratic patterns of memory errors. Finally, we show that the 
same neural code can also predict variation in true-memory performance, 
consistent with an adaptive perspective on false memory. Taken together, our 
findings reveal the underlying structure of neural representations of semantic 
knowledge, and how this semantic structure can both enhance and distort our 
memories.

DOI: 10.1073/pnas.1610686113
PMCID: PMC5018755
PMID: 27551087 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


207. Front Neuroinform. 2016 Jul 22;10:27. doi: 10.3389/fninf.2016.00027. eCollection 
2016.

CoSMoMVPA: Multi-Modal Multivariate Pattern Analysis of Neuroimaging Data in 
Matlab/GNU Octave.

Oosterhof NN(1), Connolly AC(2), Haxby JV(3).

Author information:
(1)Center for Mind/Brain Sciences, University of Trento Rovereto, Italy.
(2)Department of Psychological and Brain Sciences, Dartmouth College Hanover, 
NH, USA.
(3)Center for Mind/Brain Sciences, University of TrentoRovereto, Italy; 
Department of Psychological and Brain Sciences, Dartmouth CollegeHanover, NH, 
USA.

Recent years have seen an increase in the popularity of multivariate pattern 
(MVP) analysis of functional magnetic resonance (fMRI) data, and, to a much 
lesser extent, magneto- and electro-encephalography (M/EEG) data. We present 
CoSMoMVPA, a lightweight MVPA (MVP analysis) toolbox implemented in the 
intersection of the Matlab and GNU Octave languages, that treats both fMRI and 
M/EEG data as first-class citizens. CoSMoMVPA supports all state-of-the-art MVP 
analysis techniques, including searchlight analyses, classification, 
correlations, representational similarity analysis, and the time generalization 
method. These can be used to address both data-driven and hypothesis-driven 
questions about neural organization and representations, both within and across: 
space, time, frequency bands, neuroimaging modalities, individuals, and species. 
It uses a uniform data representation of fMRI data in the volume or on the 
surface, and of M/EEG data at the sensor and source level. Through various 
external toolboxes, it directly supports reading and writing a variety of fMRI 
and M/EEG neuroimaging formats, and, where applicable, can convert between them. 
As a result, it can be integrated readily in existing pipelines and used with 
existing preprocessed datasets. CoSMoMVPA overloads the traditional volumetric 
searchlight concept to support neighborhoods for M/EEG and surface-based fMRI 
data, which supports localization of multivariate effects of interest across 
space, time, and frequency dimensions. CoSMoMVPA also provides a generalized 
approach to multiple comparison correction across these dimensions using 
Threshold-Free Cluster Enhancement with state-of-the-art clustering and 
permutation techniques. CoSMoMVPA is highly modular and uses abstractions to 
provide a uniform interface for a variety of MVP measures. Typical analyses 
require a few lines of code, making it accessible to beginner users. At the same 
time, expert programmers can easily extend its functionality. CoSMoMVPA comes 
with extensive documentation, including a variety of runnable demonstration 
scripts and analysis exercises (with example data and solutions). It uses best 
software engineering practices including version control, distributed 
development, an automated test suite, and continuous integration testing. It can 
be used with the proprietary Matlab and the free GNU Octave software, and it 
complies with open source distribution platforms such as NeuroDebian. CoSMoMVPA 
is Free/Open Source Software under the permissive MIT license. Website: 
http://cosmomvpa.org Source code: https://github.com/CoSMoMVPA/CoSMoMVPA.

DOI: 10.3389/fninf.2016.00027
PMCID: PMC4956688
PMID: 27499741


208. J Neurosci. 2016 Jul 27;36(30):7985-95. doi: 10.1523/JNEUROSCI.0830-16.2016.

Parallel Engagement of Regions Associated with Encoding and Later Retrieval 
Forms Durable Memories.

Wagner IC(1), van Buuren M(2), Bovy L(2), Fernández G(2).

Author information:
(1)Donders Institute for Brain, Cognition and Behaviour, Radboud University 
Medical Center, 6525 EZ, Nijmegen, The Netherlands i.wagner@donders.ru.nl.
(2)Donders Institute for Brain, Cognition and Behaviour, Radboud University 
Medical Center, 6525 EZ, Nijmegen, The Netherlands.

The fate of a memory is partly determined at initial encoding. However, the 
behavioral consequences of memory formation are often tested only once and 
shortly after learning, which leaves the neuronal predictors for the formation 
of durable memories largely unknown. Here, we hypothesized that durable memory 
formation (as opposed to weak or no memory formation) is reflected through 
increased activation in the medial temporal lobes and prefrontal cortex, and 
more consistent processing (i.e., stronger pattern similarity) across encoding 
material. Thirty-four human subjects studied unique picture-location 
associations while undergoing fMRI and performed a cued recall test immediately 
after study as well as 48 h later. Associative memories were defined as "weak" 
if they were retrieved during the immediate test only. Conversely, "durable" 
memories persisted also after 48 h. The posterior cingulate cortex showed 
increased pattern similarity during successful memory formation, independent of 
the eventual durability. For durable memory encoding, we found increased 
activation in medial and inferior temporal, prefrontal, and parietal regions. 
This was accompanied by stronger pattern similarity in lateral prefrontal and 
parietal regions, as well as in anterior and posterior midline structures that 
were also engaged during later memory retrieval. Thus, we show that pattern 
similarity, or consistent processing, in the posterior cingulate cortex predicts 
associative memory formation at encoding. If this is paralleled by additional 
activation increases in regions typically related to encoding, and by consistent 
processing in regions involved in later retrieval, formed memories appear 
durable for at least 48 h.
SIGNIFICANCE STATEMENT: Successful memory formation is typically associated with 
increased neuronal activation in medial temporal and prefrontal regions at 
encoding, but memory is often assessed only once and shortly after study. Here, 
we addressed memory durability, and investigated the neuronal underpinnings of 
encoding for associations remembered over a longer period of time, less long, or 
immediately forgotten. We showed that durable memory formation is dependent on 
increased activation in the hippocampus and neocortical regions related to 
encoding, and on consistent processing of associative memory traces in midline 
structures that are involved in later memory retrieval. These findings highlight 
how durable memories are formed.

Copyright © 2016 the authors 0270-6474/16/367985-11$15.00/0.

DOI: 10.1523/JNEUROSCI.0830-16.2016
PMCID: PMC6601878
PMID: 27466342 [Indexed for MEDLINE]


209. J Neurosci. 2016 Jul 20;36(29):7648-62. doi: 10.1523/JNEUROSCI.0313-16.2016.

Disentangling Representations of Object and Grasp Properties in the Human Brain.

Fabbri S(1), Stubbs KM(2), Cusack R(3), Culham JC(4).

Author information:
(1)The Brain and Mind Institute, Department of Psychology, and Radboud 
University, Donders Institute for Brain, Cognition, and Behaviour, Nijmegen, 
6500 HE Nijmegen, The Netherlands, and s.fabbri@donders.ru.nl.
(2)The Brain and Mind Institute.
(3)The Brain and Mind Institute, Department of Psychology, and Department of 
Medical Biophysics, University of Western Ontario, London, Ontario N6A 5C2, 
Canada.
(4)The Brain and Mind Institute, Department of Psychology, and Center for 
Mind/Brain Sciences, University of Trento, 38068 Mattarello, Italy.

The properties of objects, such as shape, influence the way we grasp them. To 
quantify the role of different brain regions during grasping, it is necessary to 
disentangle the processing of visual dimensions related to object properties 
from the motor aspects related to the specific hand configuration. We 
orthogonally varied object properties (shape, size, and elongation) and task 
(passive viewing, precision grip with two or five digits, or coarse grip with 
five digits) and used representational similarity analysis of functional 
magnetic resonance imaging data to infer the representation of object properties 
and hand configuration in the human brain. We found that object elongation is 
the most strongly represented object feature during grasping and is coded 
preferentially in the primary visual cortex as well as the anterior and 
posterior superior-parieto-occipital cortex. By contrast, primary somatosensory, 
motor, and ventral premotor cortices coded preferentially the number of digits 
while ventral-stream and dorsal-stream regions coded a mix of visual and motor 
dimensions. The representation of object features varied with task modality, as 
object elongation was less relevant during passive viewing than grasping. To 
summarize, this study shows that elongation is a particularly relevant property 
of the object to grasp, which along with the number of digits used, is 
represented within both ventral-stream and parietal regions, suggesting that 
communication between the two streams about these specific visual and motor 
dimensions might be relevant to the execution of efficient grasping actions.
SIGNIFICANCE STATEMENT: To grasp something, the visual properties of an object 
guide preshaping of the hand into the appropriate configuration. Different grips 
can be used, and different objects require different hand configurations. 
However, in natural actions, grip and object type are often confounded, and the 
few experiments that have attempted to separate them have produced conflicting 
results. As such, it is unclear how visual and motor properties are represented 
across brain regions during grasping. Here we orthogonally manipulated object 
properties and grip, and revealed the visual dimension (object elongation) and 
the motor dimension (number of digits) that are more strongly coded in ventral 
and dorsal streams. These results suggest that both streams play a role in the 
visuomotor coding essential for grasping.

Copyright © 2016 the authors 0270-6474/16/367648-15$15.00/0.

DOI: 10.1523/JNEUROSCI.0313-16.2016
PMCID: PMC6705560
PMID: 27445143 [Indexed for MEDLINE]


210. Sci Rep. 2016 Jul 5;6:29079. doi: 10.1038/srep29079.

Multivariate Neural Representations of Value during Reward Anticipation and 
Consummation in the Human Orbitofrontal Cortex.

Yan C(1)(2), Su L(3), Wang Y(1), Xu T(1), Yin DZ(4), Fan MX(5), Deng CP(2), Hu 
Y(2), Wang ZX(2), Cheung EF(6), Lim KO(7), Chan RC(1).

Author information:
(1)Neuropsychology and Applied Cognitive Neuroscience Laboratory, Key Laboratory 
of Mental Health, Institute of Psychology, Chinese Academy of Sciences, Room 
606, South Building, 16 Lincui Road, Beijing, Beijing, 100101 China.
(2)Key Laboratory of Brain Functional Genomics, Ministry of Education, Shanghai 
Key Laboratory of Brain Functional Genomics (MOE &STCSM), East China Normal 
University, Room 213, Junxiu Building, 3663 North Zhongshan Road, Shanghai, 
200062 China.
(3)Department of Psychiatry, Cambridge Biomedical Campus, University of 
Cambridge, Cambridge, CB2 0SP UK.
(4)Institute of Neuroscience, Shanghai Institutes for Biological Sciences, 
Chinese Academy of Sciences, 320 Yue Yang Road, Shanghai, 200031 China.
(5)Shanghai Key Laboratory of MRI, East China Normal University, 3663 North 
Zhongshan Road, Shanghai, 200062 China.
(6)Department of General Adult Psychiatry, Castle Peak Hospital, 15 Tsing Chung 
Koon Road, Tuen Mun, N.T. Hong Kong Special Administrative Region, China.
(7)Department of Psychiatry, University of Minnesota, F282/2A West 2450 
Riverside Avenue, Minneapolis, MN 55454 USA.

The role of the orbitofrontal cortex (OFC) in value processing is a focus of 
research. Conventional imaging analysis, where smoothing and averaging are 
employed, may not be sufficiently sensitive in studying the OFC, which has 
heterogeneous anatomical structures and functions. In this study, we employed 
representational similarity analysis (RSA) to reveal the multi-voxel fMRI 
patterns in the OFC associated with value processing during the anticipatory and 
the consummatory phases. We found that multi-voxel activation patterns in the 
OFC encoded magnitude and partial valence information (win vs. loss) but not 
outcome (favourable vs. unfavourable) during reward consummation. Furthermore, 
the lateral OFC rather than the medial OFC encoded loss information. Also, we 
found that OFC encoded values in a similar way to the ventral striatum (VS) or 
the anterior insula (AI) during reward anticipation regardless of motivated 
response and to the medial prefrontal cortex (MPFC) and the VS in reward 
consummation. In contrast, univariate analysis did not show changes of 
activation in the OFC. These findings suggest an important role of the OFC in 
value processing during reward anticipation and consummation.

DOI: 10.1038/srep29079
PMCID: PMC4932626
PMID: 27378417 [Indexed for MEDLINE]


211. Front Integr Neurosci. 2016 Mar 30;10:16. doi: 10.3389/fnint.2016.00016. 
eCollection 2016.

Functional MRI Representational Similarity Analysis Reveals a Dissociation 
between Discriminative and Relative Location Information in the Human Visual 
System.

Roth ZN(1).

Author information:
(1)The Edmond and Lily Safra Center for Brain Sciences, The Hebrew 
UniversityJerusalem, Israel; Department of Neurobiology, The Hebrew 
UniversityJerusalem, Israel.

Neural responses in visual cortex are governed by a topographic mapping from 
retinal locations to cortical responses. Moreover, at the voxel population level 
early visual cortex (EVC) activity enables accurate decoding of stimuli 
locations. However, in many cases information enabling one to discriminate 
between locations (i.e., discriminative information) may be less relevant than 
information regarding the relative location of two objects (i.e., relative 
information). For example, when planning to grab a cup, determining whether the 
cup is located at the same retinal location as the hand is hardly relevant, 
whereas the location of the cup relative to the hand is crucial for performing 
the action. We have previously used multivariate pattern analysis techniques to 
measure discriminative location information, and found the highest levels in 
EVC, in line with other studies. Here we show, using representational similarity 
analysis, that availability of discriminative information in fMRI activation 
patterns does not entail availability of relative information. Specifically, we 
find that relative location information can be reliably extracted from activity 
patterns in posterior intraparietal sulcus (pIPS), but not from EVC, where we 
find the spatial representation to be warped. We further show that this 
variability in relative information levels between regions can be explained by a 
computational model based on an array of receptive fields. Moreover, when the 
model's receptive fields are extended to include inhibitory surround regions, 
the model can account for the spatial warping in EVC. These results demonstrate 
how size and shape properties of receptive fields in human visual cortex 
contribute to the transformation of discriminative spatial representations into 
relative spatial representations along the visual stream.

DOI: 10.3389/fnint.2016.00016
PMCID: PMC4876365
PMID: 27242455


212. Cereb Cortex. 2016 Aug;26(8):3563-3579. doi: 10.1093/cercor/bhw135. Epub 2016 
May 27.

Similarity-Based Fusion of MEG and fMRI Reveals Spatio-Temporal Dynamics in 
Human Cortex During Visual Object Recognition.

Cichy RM(1)(2), Pantazis D(3), Oliva A(1).

Author information:
(1)Computer Science and Artificial Intelligence Laboratory and.
(2)Department of Education and Psychology, Free University Berlin, Berlin, 
Germany.
(3)McGovern Institute for Brain Research, MIT, Cambridge, MA, USA.

Every human cognitive function, such as visual object recognition, is realized 
in a complex spatio-temporal activity pattern in the brain. Current brain 
imaging techniques in isolation cannot resolve the brain's spatio-temporal 
dynamics, because they provide either high spatial or temporal resolution but 
not both. To overcome this limitation, we developed an integration approach that 
uses representational similarities to combine measurements of 
magnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI) to 
yield a spatially and temporally integrated characterization of neuronal 
activation. Applying this approach to 2 independent MEG-fMRI data sets, we 
observed that neural activity first emerged in the occipital pole at 50-80 ms, 
before spreading rapidly and progressively in the anterior direction along the 
ventral and dorsal visual streams. Further region-of-interest analyses 
established that dorsal and ventral regions showed MEG-fMRI correspondence in 
representations later than early visual cortex. Together, these results provide 
a novel and comprehensive, spatio-temporally resolved view of the rapid neural 
dynamics during the first few hundred milliseconds of object vision. They 
further demonstrate the feasibility of spatially unbiased representational 
similarity-based fusion of MEG and fMRI, promising new insights into how the 
brain computes complex cognitive functions.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/cercor/bhw135
PMCID: PMC4961022
PMID: 27235099 [Indexed for MEDLINE]


213. J Neurosci. 2016 May 25;36(21):5763-74. doi: 10.1523/JNEUROSCI.3603-15.2016.

Multivariate Patterns in the Human Object-Processing Pathway Reveal a Shift from 
Retinotopic to Shape Curvature Representations in Lateral Occipital Areas, LO-1 
and LO-2.

Vernon RJ(1), Gouws AD(2), Lawrence SJ(1), Wade AR(1), Morland AB(3).

Author information:
(1)Department of Psychology and.
(2)York Neuroimaging Centre, University of York, Heslington, York YO10 5DD, 
United Kingdom.
(3)Department of Psychology and York Neuroimaging Centre, University of York, 
Heslington, York YO10 5DD, United Kingdom antony.morland@york.ac.uk.

Representations in early visual areas are organized on the basis of retinotopy, 
but this organizational principle appears to lose prominence in the extrastriate 
cortex. Nevertheless, an extrastriate region, such as the shape-selective 
lateral occipital cortex (LO), must still base its activation on the responses 
from earlier retinotopic visual areas, implying that a transition from 
retinotopic to "functional" organizations should exist. We hypothesized that 
such a transition may lie in LO-1 or LO-2, two visual areas lying between 
retinotopically defined V3d and functionally defined LO. Using a rapid 
event-related fMRI paradigm, we measured neural similarity in 12 human 
participants between pairs of stimuli differing along dimensions of shape 
exemplar and shape complexity within both retinotopically and functionally 
defined visual areas. These neural similarity measures were then compared with 
low-level and more abstract (curvature-based) measures of stimulus similarity. 
We found that low-level, but not abstract, stimulus measures predicted V1-V3 
responses, whereas the converse was true for LO, a double dissociation. 
Critically, abstract stimulus measures were most predictive of responses within 
LO-2, akin to LO, whereas both low-level and abstract measures were predictive 
for responses within LO-1, perhaps indicating a transitional point between those 
two organizational principles. Similar transitions to abstract representations 
were not observed in the more ventral stream passing through V4 and VO-1/2. The 
transition we observed in LO-1 and LO-2 demonstrates that a more "abstracted" 
representation, typically considered the preserve of "category-selective" 
extrastriate cortex, can nevertheless emerge in retinotopic regions.
SIGNIFICANCE STATEMENT: Visual areas are typically identified either through 
retinotopy (e.g., V1-V3) or from functional selectivity [e.g., shape-selective 
lateral occipital complex (LOC)]. We combined these approaches to explore the 
nature of shape representations through the visual hierarchy. Two different 
representations emerged: the first reflected low-level shape properties 
(dependent on the spatial layout of the shape outline), whereas the second 
captured more abstract curvature-related shape features. Critically, early 
visual cortex represented low-level information but this diminished in the 
extrastriate cortex (LO-1/LO-2/LOC), in which the abstract representation 
emerged. Therefore, this work further elucidates the nature of shape 
representations in the LOC, provides insight into how those representations 
emerge from early retinotopic cortex, and crucially demonstrates that 
retinotopically tuned regions (LO-1/LO-2) are not necessarily constrained to 
retinotopic representations.

Copyright © 2016 Vernon et al.

DOI: 10.1523/JNEUROSCI.3603-15.2016
PMCID: PMC4879197
PMID: 27225766 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing financial 
interests.


214. Psychophysiology. 2016 Aug;53(8):1117-27. doi: 10.1111/psyp.12665. Epub 2016 May 
6.

Quantifying learning-dependent changes in the brain: Single-trial multivoxel 
pattern analysis requires slow event-related fMRI.

Visser RM(1)(2)(3), de Haan MI(2)(4), Beemsterboer T(5), Haver P(5), Kindt 
M(1)(2), Scholte HS(2)(5)(6).

Author information:
(1)Department of Clinical Psychology, University of Amsterdam, Amsterdam, The 
Netherlands.
(2)Amsterdam Brain and Cognition (ABC), Amsterdam, The Netherlands.
(3)Medical Research Council-Cognition and Brain Sciences Unit, Cambridge, UK.
(4)Department of Psychiatry, Academic Medical Centre, University of Amsterdam, 
Amsterdam, The Netherlands.
(5)Spinoza Centre for Neuroimaging, University of Amsterdam, Amsterdam, The 
Netherlands.
(6)Department of Brain and Cognition, University of Amsterdam, Amsterdam, The 
Netherlands.

Single-trial analysis is particularly useful for assessing cognitive processes 
that are intrinsically dynamic, such as learning. Studying these processes with 
fMRI is problematic, as the low signal-to-noise ratio of fMRI requires the 
averaging over multiple trials, obscuring trial-by-trial changes in neural 
activation. The superior sensitivity of multivoxel pattern analysis over 
univariate analyses has opened up new possibilities for single-trial analysis, 
but this may require different fMRI designs. Here, we measured fMRI and pupil 
dilation responses during discriminant aversive conditioning, to assess 
associative learning in a trial-by-trial manner. The impact of design choices 
was examined by varying trial spacing and trial order in a series of five 
experiments (total n = 66), while keeping stimulus duration constant (4.5 s). 
Our outcome measure was the change in similarity between neural response 
patterns related to two consecutive presentations of the same stimulus 
(within-stimulus) and between patterns related to pairs of different stimuli 
(between-stimulus) that shared a specific outcome (electric stimulation vs. no 
consequence). This trial-by-trial similarity analysis revealed clear 
single-trial learning curves in conditions with intermediate (8.1-12.6 s) and 
long (16.5-18.4 s) intervals, with effects being strongest in designs with long 
intervals and counterbalanced stimulus presentation. No learning curves were 
observed in designs with shorter intervals (1.6-6.1 s), indicating that rapid 
event-related designs-at present, the most common designs in fMRI research-are 
not suited for single-trial pattern analysis. These findings emphasize the 
importance of deciding on the type of analysis prior to data collection.

© 2016 Society for Psychophysiological Research.

DOI: 10.1111/psyp.12665
PMID: 27153295 [Indexed for MEDLINE]


215. Neuroimage. 2017 Jan 15;145(Pt B):314-328. doi: 
10.1016/j.neuroimage.2016.04.003. Epub 2016 Apr 11.

Task-specific feature extraction and classification of fMRI volumes using a deep 
neural network initialized with a deep belief network: Evaluation using 
sensorimotor tasks.

Jang H(1), Plis SM(2), Calhoun VD(3), Lee JH(4).

Author information:
(1)Department of Brain and Cognitive Engineering, Korea University, Seoul, 
Republic of Korea.
(2)The Mind Research Network & LBERI, Albuquerque, NM, USA.
(3)The Mind Research Network & LBERI, Albuquerque, NM, USA; Department of 
Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM, 
USA. Electronic address: vcalhoun@mrn.org.
(4)Department of Brain and Cognitive Engineering, Korea University, Seoul, 
Republic of Korea. Electronic address: jonghwan_lee@korea.ac.kr.

Feedforward deep neural networks (DNNs), artificial neural networks with 
multiple hidden layers, have recently demonstrated a record-breaking performance 
in multiple areas of applications in computer vision and speech processing. 
Following the success, DNNs have been applied to neuroimaging modalities 
including functional/structural magnetic resonance imaging (MRI) and 
positron-emission tomography data. However, no study has explicitly applied DNNs 
to 3D whole-brain fMRI volumes and thereby extracted hidden volumetric 
representations of fMRI that are discriminative for a task performed as the fMRI 
volume was acquired. Our study applied fully connected feedforward DNN to fMRI 
volumes collected in four sensorimotor tasks (i.e., left-hand clenching, 
right-hand clenching, auditory attention, and visual stimulus) undertaken by 12 
healthy participants. Using a leave-one-subject-out cross-validation scheme, a 
restricted Boltzmann machine-based deep belief network was pretrained and used 
to initialize weights of the DNN. The pretrained DNN was fine-tuned while 
systematically controlling weight-sparsity levels across hidden layers. Optimal 
weight-sparsity levels were determined from a minimum validation error rate of 
fMRI volume classification. Minimum error rates (mean±standard deviation; %) of 
6.9 (±3.8) were obtained from the three-layer DNN with the sparsest condition of 
weights across the three hidden layers. These error rates were even lower than 
the error rates from the single-layer network (9.4±4.6) and the two-layer 
network (7.4±4.1). The estimated DNN weights showed spatial patterns that are 
remarkably task-specific, particularly in the higher layers. The output values 
of the third hidden layer represented distinct patterns/codes of the 3D 
whole-brain fMRI volume and encoded the information of the tasks as evaluated 
from representational similarity analysis. Our reported findings show the 
ability of the DNN to classify a single fMRI volume based on the extraction of 
hidden representations of fMRI volumes associated with tasks across multiple 
hidden layers. Our study may be beneficial to the automatic 
classification/diagnosis of neuropsychiatric and neurological diseases and 
prediction of disease severity and recovery in (pre-) clinical settings using 
fMRI volumes without requiring an estimation of activation patterns or ad hoc 
statistical evaluation.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2016.04.003
PMCID: PMC5064875
PMID: 27079534 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no conflicts of interest 
regarding this study, including financial, consultant, institutional, or other 
relationships.


216. Hum Brain Mapp. 2016 Jun;37(6):2161-72. doi: 10.1002/hbm.23164. Epub 2016 Mar 
16.

Multidimensional representation of odors in the human olfactory cortex.

Fournel A(1), Ferdenzi C(1), Sezille C(1), Rouby C(1), Bensafi M(1).

Author information:
(1)Lyon Neuroscience Research Center, CNRS UMR5292, INSERM U1028, University 
Lyon, F-69000, France.

What is known as an odor object is an integrated representation constructed from 
physical features, and perceptual attributes mainly mediated by the olfactory 
and trigeminal systems. The aim of the present study was to comprehend how this 
multidimensional representation is organized, by deciphering how similarities in 
the physical, olfactory and trigeminal perceptual spaces of odors are 
represented in the human brain. To achieve this aim, we combined psychophysics, 
functional MRI and multivariate representational similarity analysis. 
Participants were asked to smell odors diffused by an fMRI-compatible 
olfactometer and to rate each smell along olfactory dimensions (pleasantness, 
intensity, familiarity and edibility) and trigeminal dimensions (irritation, 
coolness, warmth and pain). An event-related design was implemented, presenting 
different odorants. Results revealed that (i) pairwise odorant similarities in 
anterior piriform cortex (PC) activity correlated with pairwise odorant 
similarities in chemical properties (P < 0.005), (ii) similarities in posterior 
PC activity correlated with similarities in olfactory perceptual properties (P 
<0.01), and (iii) similarities in amygdala activity correlated with similarities 
in trigeminal perceptual properties (P < 0.01). These findings provide new 
evidence that extraction of physical, olfactory and trigeminal features is based 
on specific fine processing of similarities between odorous stimuli in a 
distributed manner in the olfactory system. Hum Brain Mapp 37:2161-2172, 2016. © 
2016 Wiley Periodicals, Inc.

© 2016 Wiley Periodicals, Inc.

DOI: 10.1002/hbm.23164
PMCID: PMC6867239
PMID: 26991044 [Indexed for MEDLINE]


217. Cereb Cortex. 2016 Jun;26(6):2919-2934. doi: 10.1093/cercor/bhw068. Epub 2016 
Mar 14.

A Model of Representational Spaces in Human Cortex.

Guntupalli JS(1), Hanke M(2), Halchenko YO(1), Connolly AC(1), Ramadge PJ(3), 
Haxby JV(1)(4).

Author information:
(1)Department of Psychological and Brain Sciences, Dartmouth College, Hanover, 
NH 03755, USA.
(2)Department of Psychology, University of Magdeburg, Magdeburg 39106, Germany.
(3)Department of Electrical Engineering, Princeton University, Princeton, NJ 
08544, USA.
(4)Center for Mind/Brain Sciences (CIMeC), University of Trento, Rovereto, 
Trentino 38068, Italy.

Comment in
    Trends Cogn Sci. 2016 Aug;20(8):565-567.

Current models of the functional architecture of human cortex emphasize areas 
that capture coarse-scale features of cortical topography but provide no account 
for population responses that encode information in fine-scale patterns of 
activity. Here, we present a linear model of shared representational spaces in 
human cortex that captures fine-scale distinctions among population responses 
with response-tuning basis functions that are common across brains and models 
cortical patterns of neural responses with individual-specific topographic basis 
functions. We derive a common model space for the whole cortex using a new 
algorithm, searchlight hyperalignment, and complex, dynamic stimuli that provide 
a broad sampling of visual, auditory, and social percepts. The model aligns 
representations across brains in occipital, temporal, parietal, and prefrontal 
cortices, as shown by between-subject multivariate pattern classification and 
intersubject correlation of representational geometry, indicating that 
structural principles for shared neural representations apply across widely 
divergent domains of information. The model provides a rigorous account for 
individual variability of well-known coarse-scale topographies, such as 
retinotopy and category selectivity, and goes further to account for fine-scale 
patterns that are multiplexed with coarse-scale topographies and carry finer 
distinctions.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/cercor/bhw068
PMCID: PMC4869822
PMID: 26980615 [Indexed for MEDLINE]


218. Neuroimage. 2016 May 15;132:59-70. doi: 10.1016/j.neuroimage.2016.02.019. Epub 
2016 Feb 16.

Perceptual similarity of visual patterns predicts dynamic neural activation 
patterns measured with MEG.

Wardle SG(1), Kriegeskorte N(2), Grootswagers T(1), Khaligh-Razavi SM(2), 
Carlson TA(3).

Author information:
(1)Department of Cognitive Science and ARC Centre of Excellence in Cognition and 
Its Disorders and Perception in Action Research Centre, Macquarie University, 
Sydney, New South Wales 2109, Australia.
(2)Medical Research Council, Cognition and Brain Sciences Unit, Cambridge CB2 
7EF, UK.
(3)Department of Cognitive Science and ARC Centre of Excellence in Cognition and 
Its Disorders and Perception in Action Research Centre, Macquarie University, 
Sydney, New South Wales 2109, Australia; Department of Psychology, University of 
Maryland, College Park, MD, USA. Electronic address: thomas.carlson@mq.edu.au.

Perceptual similarity is a cognitive judgment that represents the end-stage of a 
complex cascade of hierarchical processing throughout visual cortex. Previous 
studies have shown a correspondence between the similarity of coarse-scale fMRI 
activation patterns and the perceived similarity of visual stimuli, suggesting 
that visual objects that appear similar also share similar underlying patterns 
of neural activation. Here we explore the temporal relationship between the 
human brain's time-varying representation of visual patterns and behavioral 
judgments of perceptual similarity. The visual stimuli were abstract patterns 
constructed from identical perceptual units (oriented Gabor patches) so that 
each pattern had a unique global form or perceptual 'Gestalt'. The visual 
stimuli were decodable from evoked neural activation patterns measured with 
magnetoencephalography (MEG), however, stimuli differed in the similarity of 
their neural representation as estimated by differences in decodability. Early 
after stimulus onset (from 50ms), a model based on retinotopic organization 
predicted the representational similarity of the visual stimuli. Following the 
peak correlation between the retinotopic model and neural data at 80ms, the 
neural representations quickly evolved so that retinotopy no longer provided a 
sufficient account of the brain's time-varying representation of the stimuli. 
Overall the strongest predictor of the brain's representation was a model based 
on human judgments of perceptual similarity, which reached the limits of the 
maximum correlation with the neural data defined by the 'noise ceiling'. Our 
results show that large-scale brain activation patterns contain a neural 
signature for the perceptual Gestalt of composite visual features, and 
demonstrate a strong correspondence between perception and complex patterns of 
brain activity.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2016.02.019
PMID: 26899210 [Indexed for MEDLINE]


219. J Cogn Neurosci. 2016 May;28(5):680-92. doi: 10.1162/jocn_a_00924. Epub 2016 Jan 
14.

Disentangling Representations of Object Shape and Object Category in Human 
Visual Cortex: The Animate-Inanimate Distinction.

Proklova D(1), Kaiser D(1), Peelen MV(1).

Author information:
(1)University of Trento.

Objects belonging to different categories evoke reliably different fMRI activity 
patterns in human occipitotemporal cortex, with the most prominent distinction 
being that between animate and inanimate objects. An unresolved question is 
whether these categorical distinctions reflect category-associated visual 
properties of objects or whether they genuinely reflect object category. Here, 
we addressed this question by measuring fMRI responses to animate and inanimate 
objects that were closely matched for shape and low-level visual features. 
Univariate contrasts revealed animate- and inanimate-preferring regions in 
ventral and lateral temporal cortex even for individually matched object pairs 
(e.g., snake-rope). Using representational similarity analysis, we mapped out 
brain regions in which the pairwise dissimilarity of multivoxel activity 
patterns (neural dissimilarity) was predicted by the objects' pairwise visual 
dissimilarity and/or their categorical dissimilarity. Visual dissimilarity was 
measured as the time it took participants to find a unique target among 
identical distractors in three visual search experiments, where we separately 
quantified overall dissimilarity, outline dissimilarity, and texture 
dissimilarity. All three visual dissimilarity structures predicted neural 
dissimilarity in regions of visual cortex. Interestingly, these analyses 
revealed several clusters in which categorical dissimilarity predicted neural 
dissimilarity after regressing out visual dissimilarity. Together, these results 
suggest that the animate-inanimate organization of human visual cortex is not 
fully explained by differences in the characteristic shape or texture properties 
of animals and inanimate objects. Instead, representations of visual object 
properties and object category may coexist in more anterior parts of the visual 
system.

DOI: 10.1162/jocn_a_00924
PMID: 26765944 [Indexed for MEDLINE]


220. J Neurosci. 2016 Jan 13;36(2):432-44. doi: 10.1523/JNEUROSCI.2314-15.2016.

Dissociations and Associations between Shape and Category Representations in the 
Two Visual Pathways.

Bracci S(1), Op de Beeck H(2).

Author information:
(1)Laboratory of Biological Psychology, KU Leuven, 3000, Belgium 
stefania.bracci@kuleuven.be.
(2)Laboratory of Biological Psychology, KU Leuven, 3000, Belgium.

Comment in
    J Neurosci. 2016 Apr 13;36(15):4149-51.

The dorsal and ventral visual pathways represent both visual and conceptual 
object properties. Yet the relative contribution of these two factors in the 
representational content of visual areas is unclear. Indeed, research 
investigating brain category representations rarely dissociate visual and 
semantic properties of objects. We present a human event-related fMRI study with 
a two-factorial stimulus set with 54 images that explicitly dissociates shape 
from category to investigate their independent contribution as well as their 
interactions through representational similarity analyses. Results reveal a 
contribution from each dimension in both streams, with a transition from shape 
to category along the posterior-to-anterior anatomical axis. The nature of 
category representations differs in the two pathways: ventral areas represent 
object animacy and dorsal areas represent object action properties. Furthermore, 
information about shape evolved from low-level pixel-based to high-level 
perceived shape following a posterior-to-anterior gradient similar to the 
shape-to-category emergence. To conclude, results show that representations of 
shape and category independently coexist, but at the same time they are closely 
related throughout the visual hierarchy.
SIGNIFICANCE STATEMENT: Research investigating visual cortex conceptual category 
representations rarely takes into account visual properties of objects. In this 
report, we explicitly dissociate shape from category and investigate independent 
contributions and interactions of these two highly correlated dimensions.

Copyright © 2016 the authors 0270-6474/16/360432-13$15.00/0.

DOI: 10.1523/JNEUROSCI.2314-15.2016
PMCID: PMC6602035
PMID: 26758835 [Indexed for MEDLINE]


221. Neuroimage. 2016 Mar;128:44-53. doi: 10.1016/j.neuroimage.2015.12.035. Epub 2015 
Dec 28.

Representational similarity encoding for fMRI: Pattern-based synthesis to 
predict brain activity using stimulus-model-similarities.

Anderson AJ(1), Zinszer BD(2), Raizada RDS(2).

Author information:
(1)Brain and Cognitive Sciences, University of Rochester, NY 14627, USA. 
Electronic address: andrewanderson@bcs.rochester.edu.
(2)Brain and Cognitive Sciences, University of Rochester, NY 14627, USA.

Patterns of neural activity are systematically elicited as the brain experiences 
categorical stimuli and a major challenge is to understand what these patterns 
represent. Two influential approaches, hitherto treated as separate analyses, 
have targeted this problem by using model-representations of stimuli to 
interpret the corresponding neural activity patterns. 
Stimulus-model-based-encoding synthesizes neural activity patterns by first 
training weights to map between stimulus-model features and voxels. This allows 
novel model-stimuli to be mapped into voxel space, and hence the strength of the 
model to be assessed by comparing predicted against observed neural activity. 
Representational Similarity Analysis (RSA) assesses models by testing how well 
the grand structure of pattern-similarities measured between all pairs of 
model-stimuli aligns with the same structure computed from neural activity 
patterns. RSA does not require model fitting, but also does not allow synthesis 
of neural activity patterns, thereby limiting its applicability. We introduce a 
new approach, representational similarity-encoding, that builds on the strengths 
of RSA and robustly enables stimulus-model-based neural encoding without model 
fitting. The approach therefore sidesteps problems associated with overfitting 
that notoriously confront any approach requiring parameter estimation (and is 
consequently low cost computationally), and importantly enables encoding 
analyses to be incorporated within the wider Representational Similarity 
Analysis framework. We illustrate this new approach by using it to synthesize 
and decode fMRI patterns representing the meanings of words, and discuss its 
potential biological relevance to encoding in semantic memory. Our new 
similarity-based encoding approach unites the two previously disparate methods 
of encoding models and RSA, capturing the strengths of both, and enabling 
similarity-based synthesis of predicted fMRI patterns.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2015.12.035
PMID: 26732404 [Indexed for MEDLINE]


222. Neuroimage. 2016 Aug 15;137:188-200. doi: 10.1016/j.neuroimage.2015.12.012. Epub 
2015 Dec 18.

Reliability of dissimilarity measures for multi-voxel pattern analysis.

Walther A(1), Nili H(2), Ejaz N(3), Alink A(4), Kriegeskorte N(5), Diedrichsen 
J(6).

Author information:
(1)MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, CB2 7EF, Cambridge, 
United Kingdom; Institute of Cognitive Neuroscience, University College London, 
Alexandra House, 17 Queen Square, London WC1N 3AR, United Kingdom. Electronic 
address: alexander.walther@mrc-cbu.cam.ac.uk.
(2)Department of Experimental Psychology, University of Oxford, South Parks 
Road, OX1 3UD, Oxford, United Kingdom. Electronic address: 
hamed.nili@psy.ox.ac.uk.
(3)Institute of Cognitive Neuroscience, University College London, Alexandra 
House, 17 Queen Square, London WC1N 3AR, United Kingdom. Electronic address: 
n.ejaz@ucl.ac.uk.
(4)MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, CB2 7EF, Cambridge, 
United Kingdom. Electronic address: arjen.alink@mrc-cbu.cam.ac.uk.
(5)MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, CB2 7EF, Cambridge, 
United Kingdom. Electronic address: nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk.
(6)Institute of Cognitive Neuroscience, University College London, Alexandra 
House, 17 Queen Square, London WC1N 3AR, United Kingdom. Electronic address: 
j.diedrichsen@ucl.ac.uk.

Representational similarity analysis of activation patterns has become an 
increasingly important tool for studying brain representations. The 
dissimilarity between two patterns is commonly quantified by the correlation 
distance or the accuracy of a linear classifier. However, there are many 
different ways to measure pattern dissimilarity and little is known about their 
relative reliability. Here, we compare the reliability of three classes of 
dissimilarity measure: classification accuracy, Euclidean/Mahalanobis distance, 
and Pearson correlation distance. Using simulations and four real functional 
magnetic resonance imaging (fMRI) datasets, we demonstrate that continuous 
dissimilarity measures are substantially more reliable than the classification 
accuracy. The difference in reliability can be explained by two characteristics 
of classifiers: discretization and susceptibility of the discriminant function 
to shifts of the pattern ensemble between imaging runs. Reliability can be 
further improved through multivariate noise normalization for all measures. 
Finally, unlike conventional distance measures, crossvalidated distances provide 
unbiased estimates of pattern dissimilarity on a ratio scale, thus providing an 
interpretable zero point. Overall, our results indicate that the crossvalidated 
Mahalanobis distance is preferable to both the classification accuracy and the 
correlation distance for characterizing representational geometries.

Copyright © 2015. Published by Elsevier Inc.

DOI: 10.1016/j.neuroimage.2015.12.012
PMID: 26707889 [Indexed for MEDLINE]


223. Neuropsychologia. 2016 Mar;83:201-226. doi: 
10.1016/j.neuropsychologia.2015.10.023. Epub 2015 Oct 19.

Visual features as stepping stones toward semantics: Explaining object 
similarity in IT and perception with non-negative least squares.

Jozwik KM(1), Kriegeskorte N(2), Mur M(3).

Author information:
(1)Medical Research Council, Cognition and Brain Sciences Unit, 15 Chaucer Road, 
Cambridge CB2 7EF, United Kingdom. Electronic address: kj287@cam.ac.uk.
(2)Medical Research Council, Cognition and Brain Sciences Unit, 15 Chaucer Road, 
Cambridge CB2 7EF, United Kingdom. Electronic address: 
nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk.
(3)Medical Research Council, Cognition and Brain Sciences Unit, 15 Chaucer Road, 
Cambridge CB2 7EF, United Kingdom. Electronic address: 
marieke.mur@mrc-cbu.cam.ac.uk.

Object similarity, in brain representations and conscious perception, must 
reflect a combination of the visual appearance of the objects on the one hand 
and the categories the objects belong to on the other. Indeed, visual object 
features and category membership have each been shown to contribute to the 
object representation in human inferior temporal (IT) cortex, as well as to 
object-similarity judgments. However, the explanatory power of features and 
categories has not been directly compared. Here, we investigate whether the IT 
object representation and similarity judgments are best explained by a 
categorical or a feature-based model. We use rich models (>100 dimensions) 
generated by human observers for a set of 96 real-world object images. The 
categorical model consists of a hierarchically nested set of category labels 
(such as "human", "mammal", and "animal"). The feature-based model includes both 
object parts (such as "eye", "tail", and "handle") and other descriptive 
features (such as "circular", "green", and "stubbly"). We used non-negative 
least squares to fit the models to the brain representations (estimated from 
functional magnetic resonance imaging data) and to similarity judgments. Model 
performance was estimated on held-out images not used in fitting. Both models 
explained significant variance in IT and the amounts explained were not 
significantly different. The combined model did not explain significant 
additional IT variance, suggesting that it is the shared model variance 
(features correlated with categories, categories correlated with features) that 
best explains IT. The similarity judgments were almost fully explained by the 
categorical model, which explained significantly more variance than the 
feature-based model. The combined model did not explain significant additional 
variance in the similarity judgments. Our findings suggest that IT uses features 
that help to distinguish categories as stepping stones toward a semantic 
representation. Similarity judgments contain additional categorical variance 
that is not explained by visual features, reflecting a higher-level more purely 
semantic representation.

Copyright © 2015 The Authors. Published by Elsevier Ltd.. All rights reserved.

DOI: 10.1016/j.neuropsychologia.2015.10.023
PMCID: PMC4783588
PMID: 26493748 [Indexed for MEDLINE]


224. J Neurosci. 2015 Sep 23;35(38):12977-85. doi: 10.1523/JNEUROSCI.4698-14.2015.

Representational Similarity of Body Parts in Human Occipitotemporal Cortex.

Bracci S(1), Caramazza A(2), Peelen MV(3).

Author information:
(1)Center for Mind/Brain Sciences, University of Trento, 38068 Rovereto, Italy, 
Brain and Cognition, University of Leuven, 3000 Leuven, Belgium, and 
stefania.bracci@ppw.kuleuven.be.
(2)Center for Mind/Brain Sciences, University of Trento, 38068 Rovereto, Italy, 
Department of Psychology, Harvard University, Cambridge, Massachusetts 02138.
(3)Center for Mind/Brain Sciences, University of Trento, 38068 Rovereto, Italy.

Erratum in
    J Neurosci. 2016 May 25;36(21):5906.

Comment in
    J Neurosci. 2016 Jan 13;36(2):265-7.

Regions in human lateral and ventral occipitotemporal cortices (OTC) respond 
selectively to pictures of the human body and its parts. What are the 
organizational principles underlying body part responses in these regions? Here 
we used representational similarity analysis (RSA) of fMRI data to test multiple 
possible organizational principles: shape similarity, physical proximity, 
cortical homunculus proximity, and semantic similarity. Participants viewed 
pictures of whole persons, chairs, and eight body parts (hands, arms, legs, 
feet, chests, waists, upper faces, and lower faces). The similarity of 
multivoxel activity patterns for all body part pairs was established in whole 
person-selective OTC regions. The resulting neural similarity matrices were then 
compared with similarity matrices capturing the hypothesized organizational 
principles. Results showed that the semantic similarity model best captured the 
neural similarity of body parts in lateral and ventral OTC, which followed an 
organization in three clusters: (1) body parts used as action effectors (hands, 
feet, arms, and legs), (2) noneffector body parts (chests and waists), and (3) 
face parts (upper and lower faces). Whole-brain RSA revealed, in addition to 
OTC, regions in parietal and frontal cortex in which neural similarity was 
related to semantic similarity. In contrast, neural similarity in occipital 
cortex was best predicted by shape similarity models. We suggest that the 
semantic organization of body parts in high-level visual cortex relates to the 
different functions associated with the three body part clusters, reflecting the 
unique processing and connectivity demands associated with the different types 
of information (e.g., action, social) different body parts (e.g., limbs, faces) 
convey. Significance statement: While the organization of body part 
representations in motor and somatosensory cortices has been well characterized, 
the principles underlying body part representations in visual cortex have not 
yet been explored. In the present fMRI study we used multivoxel pattern analysis 
and representational similarity analysis to characterize the organization of 
body maps in human occipitotemporal cortex (OTC). Results indicate that visual 
and shape dimensions do not fully account for the organization of body part 
representations in OTC. Instead, the representational structure of body maps in 
OTC appears strongly related to functional-semantic properties of body parts. We 
suggest that this organization reflects the unique processing and connectivity 
demands associated with the different types of information different body parts 
convey.

Copyright © 2015 the authors 0270-6474/15/3512977-09$15.00/0.

DOI: 10.1523/JNEUROSCI.4698-14.2015
PMCID: PMC6605446
PMID: 26400929 [Indexed for MEDLINE]


225. Neuroimage. 2015 Oct 15;120:309-22. doi: 10.1016/j.neuroimage.2015.06.093. Epub 
2015 Jul 15.

Reading visually embodied meaning from the brain: Visually grounded 
computational models decode visual-object mental imagery induced by written 
text.

Anderson AJ(1), Bruni E(2), Lopopolo A(2), Poesio M(3), Baroni M(2).

Author information:
(1)Brain and Cognitive Sciences, University of Rochester, NY 14627, USA; Center 
for Mind/Brain Sciences, 38068, Rovereto, Italy. Electronic address: 
andrewanderson@bcs.rochester.edu.
(2)Center for Mind/Brain Sciences, 38068, Rovereto, Italy.
(3)Center for Mind/Brain Sciences, 38068, Rovereto, Italy; University of Essex, 
CO4 3SQ, UK.

Embodiment theory predicts that mental imagery of object words recruits neural 
circuits involved in object perception. The degree of visual imagery present in 
routine thought and how it is encoded in the brain is largely unknown. We test 
whether fMRI activity patterns elicited by participants reading objects' names 
include embodied visual-object representations, and whether we can decode the 
representations using novel computational image-based semantic models. We first 
apply the image models in conjunction with text-based semantic models to test 
predictions of visual-specificity of semantic representations in different brain 
regions. Representational similarity analysis confirms that fMRI structure 
within ventral-temporal and lateral-occipital regions correlates most strongly 
with the image models and conversely text models correlate better with 
posterior-parietal/lateral-temporal/inferior-frontal regions. We use an 
unsupervised decoding algorithm that exploits commonalities in representational 
similarity structure found within both image model and brain data sets to 
classify embodied visual representations with high accuracy (8/10) and then 
extend it to exploit model combinations to robustly decode different brain 
regions in parallel. By capturing latent visual-semantic structure our models 
provide a route into analyzing neural representations derived from past 
perceptual experience rather than stimulus-driven brain activity. Our results 
also verify the benefit of combining multimodal data to model human-like 
semantic representations.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2015.06.093
PMID: 26188260 [Indexed for MEDLINE]


226. Cereb Cortex. 2015 Dec;25(12):4772-88. doi: 10.1093/cercor/bhv136. Epub 2015 Jul 
8.

Hierarchical Organization of Auditory and Motor Representations in Speech 
Perception: Evidence from Searchlight Similarity Analysis.

Evans S(1), Davis MH(2).

Author information:
(1)MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, UK Institute of 
Cognitive Neuroscience, University College London, WC1 3AR, UK.
(2)MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, UK.

How humans extract the identity of speech sounds from highly variable acoustic 
signals remains unclear. Here, we use searchlight representational similarity 
analysis (RSA) to localize and characterize neural representations of syllables 
at different levels of the hierarchically organized temporo-frontal pathways for 
speech perception. We asked participants to listen to spoken syllables that 
differed considerably in their surface acoustic form by changing speaker and 
degrading surface acoustics using noise-vocoding and sine wave synthesis while 
we recorded neural responses with functional magnetic resonance imaging. We 
found evidence for a graded hierarchy of abstraction across the brain. At the 
peak of the hierarchy, neural representations in somatomotor cortex encoded 
syllable identity but not surface acoustic form, at the base of the hierarchy, 
primary auditory cortex showed the reverse. In contrast, bilateral temporal 
cortex exhibited an intermediate response, encoding both syllable identity and 
the surface acoustic form of speech. Regions of somatomotor cortex associated 
with encoding syllable identity in perception were also engaged when producing 
the same syllables in a separate session. These findings are consistent with a 
hierarchical account of how variable acoustic signals are transformed into 
abstract representations of the identity of speech sounds.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/cercor/bhv136
PMCID: PMC4635918
PMID: 26157026 [Indexed for MEDLINE]


227. J Neurosci. 2015 Jul 1;35(26):9595-602. doi: 10.1523/JNEUROSCI.3550-14.2015.

Lesser Neural Pattern Similarity across Repeated Tests Is Associated with Better 
Long-Term Memory Retention.

Karlsson Wirebring L(1), Wiklund-Hörnqvist C(2), Eriksson J(3), Andersson M(3), 
Jonsson B(4), Nyberg L(5).

Author information:
(1)Department of Integrative Medical Biology, Umeå Center for Functional Brain 
Imaging (UFBI), Department of Psychology, Umeå University, 901 87 Umeå, Sweden 
linnea.karlsson@umu.se.
(2)Umeå Center for Functional Brain Imaging (UFBI), Department of Psychology, 
Umeå University, 901 87 Umeå, Sweden.
(3)Department of Integrative Medical Biology, Umeå Center for Functional Brain 
Imaging (UFBI).
(4)Department of Psychology, Umeå University, 901 87 Umeå, Sweden.
(5)Department of Integrative Medical Biology, Umeå Center for Functional Brain 
Imaging (UFBI), Department of Radiation Sciences, and.

Encoding and retrieval processes enhance long-term memory performance. The 
efficiency of encoding processes has recently been linked to representational 
consistency: the reactivation of a representation that gets more specific each 
time an item is further studied. Here we examined the complementary hypothesis 
of whether the efficiency of retrieval processes also is linked to 
representational consistency. Alternatively, recurrent retrieval might foster 
representational variability--the altering or adding of underlying memory 
representations. Human participants studied 60 Swahili-Swedish word pairs before 
being scanned with fMRI the same day and 1 week later. On Day 1, participants 
were tested three times on each word pair, and on Day 7 each pair was tested 
once. A BOLD signal change in right superior parietal cortex was associated with 
subsequent memory on Day 1 and with successful long-term retention on Day 7. A 
representational similarity analysis in this parietal region revealed that 
beneficial recurrent retrieval was associated with representational variability, 
such that the pattern similarity on Day 1 was lower for retrieved words 
subsequently remembered compared with those subsequently forgotten. This was 
mirrored by a monotonically decreased BOLD signal change in dorsolateral 
prefrontal cortex on Day 1 as a function of repeated successful retrieval for 
words subsequently remembered, but not for words subsequently forgotten. This 
reduction in prefrontal response could reflect reduced demands on cognitive 
control. Collectively, the results offer novel insights into why memory 
retention benefits from repeated retrieval, and they suggest fundamental 
differences between repeated study and repeated testing.
SIGNIFICANCE STATEMENT: Repeated testing is known to produce superior long-term 
retention of the to-be-learned material compared with repeated encoding and 
other learning techniques, much because it fosters repeated memory retrieval. 
This study demonstrates that repeated memory retrieval might strengthen memory 
by inducing more differentiated or elaborated memory representations in the 
parietal cortex, and at the same time reducing demands on 
prefrontal-cortex-mediated cognitive control processes during retrieval. The 
findings contrast with recent demonstrations that repeated encoding induces less 
differentiated or elaborated memory representations. Together, this study 
suggests a potential neurocognitive explanation of why repeated retrieval is 
more beneficial for long-term retention than repeated encoding, a phenomenon 
known as the testing effect.

Copyright © 2015 the authors 0270-6474/15/359595-08$15.00/0.

DOI: 10.1523/JNEUROSCI.3550-14.2015
PMCID: PMC6605150
PMID: 26134642 [Indexed for MEDLINE]


228. Cereb Cortex. 2015 Nov;25(11):4638-50. doi: 10.1093/cercor/bhv134. Epub 2015 Jun 
19.

Feel the Noise: Relating Individual Differences in Auditory Imagery to the 
Structure and Function of Sensorimotor Systems.

Lima CF(1), Lavan N(2), Evans S(3), Agnew Z(4), Halpern AR(5), Shanmugalingam 
P(3), Meekings S(3), Boebinger D(3), Ostarek M(3), McGettigan C(2), Warren 
JE(6), Scott SK(3).

Author information:
(1)Institute of Cognitive Neuroscience Center for Psychology, University of 
Porto, Porto, Portugal.
(2)Institute of Cognitive Neuroscience Department of Psychology, Royal Holloway 
University of London, London, UK.
(3)Institute of Cognitive Neuroscience.
(4)Institute of Cognitive Neuroscience Department of Otolaryngology, University 
of California, San Francisco, USA.
(5)Department of Psychology, Bucknell University, Lewisburg, USA.
(6)Faculty of Brain Sciences, University College London, London, UK.

Humans can generate mental auditory images of voices or songs, sometimes 
perceiving them almost as vividly as perceptual experiences. The functional 
networks supporting auditory imagery have been described, but less is known 
about the systems associated with interindividual differences in auditory 
imagery. Combining voxel-based morphometry and fMRI, we examined the structural 
basis of interindividual differences in how auditory images are subjectively 
perceived, and explored associations between auditory imagery, sensory-based 
processing, and visual imagery. Vividness of auditory imagery correlated with 
gray matter volume in the supplementary motor area (SMA), parietal cortex, 
medial superior frontal gyrus, and middle frontal gyrus. An analysis of 
functional responses to different types of human vocalizations revealed that the 
SMA and parietal sites that predict imagery are also modulated by sound type. 
Using representational similarity analysis, we found that higher 
representational specificity of heard sounds in SMA predicts vividness of 
imagery, indicating a mechanistic link between sensory- and imagery-based 
processing in sensorimotor cortex. Vividness of imagery in the visual domain 
also correlated with SMA structure, and with auditory imagery scores. 
Altogether, these findings provide evidence for a signature of imagery in brain 
structure, and highlight a common role of perceptual-motor interactions for 
processing heard and internally generated auditory information.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/cercor/bhv134
PMCID: PMC4816805
PMID: 26092220 [Indexed for MEDLINE]


229. Hum Brain Mapp. 2015 Aug;36(8):3213-26. doi: 10.1002/hbm.22842. Epub 2015 Jun 2.

Monitoring the growth of the neural representations of new animal concepts.

Bauer AJ(1), Just MA(1).

Author information:
(1)Department of Psychology, Center for Cognitive Brain Imaging, Baker Hall, 
Carnegie Mellon University, Pittsburgh, Pennsylvania, 15213.

Although enormous progress has recently been made in identifying the neural 
representations of individual object concepts, relatively little is known about 
the growth of a neural knowledge representation as a novel object concept is 
being learned. In this fMRI study, the growth of the neural representations of 
eight individual extinct animal concepts was monitored as participants learned 
two features of each animal, namely its habitat (i.e., a natural dwelling or 
scene) and its diet or eating habits. Dwelling/scene information and 
diet/eating-related information have each been shown to activate their own 
characteristic brain regions. Several converging methods were used here to 
capture the emergence of the neural representation of a new animal feature 
within these characteristic, a priori-specified brain regions. These methods 
include statistically reliable identification (classification) of the eight 
newly acquired multivoxel patterns, analysis of the neural representational 
similarity among the newly learned animal concepts, and conventional GLM 
assessments of the activation in the critical regions. Moreover, the 
representation of a recently learned feature showed some durability, remaining 
intact after another feature had been learned. This study provides a foundation 
for brain research to trace how a new concept makes its way from the words and 
graphics used to teach it, to a neural representation of that concept in a 
learner's brain.

© 2015 Wiley Periodicals, Inc.

DOI: 10.1002/hbm.22842
PMCID: PMC6869301
PMID: 26032608 [Indexed for MEDLINE]


230. Psychoneuroendocrinology. 2015 May;55:8-20. doi: 10.1016/j.psyneuen.2015.01.021. 
Epub 2015 Feb 3.

Representational similarity analysis offers a preview of the noradrenergic 
modulation of long-term fear memory at the time of encoding.

Visser RM(1), Kunze AE(1), Westhoff B(2), Scholte HS(1), Kindt M(3).

Author information:
(1)Department of Psychology, University of Amsterdam, 1018 XA Amsterdam, The 
Netherlands; Amsterdam Brain and Cognition (ABC), University of Amsterdam, 1018 
VZ Amsterdam, The Netherlands.
(2)Department of Psychology, University of Amsterdam, 1018 XA Amsterdam, The 
Netherlands.
(3)Department of Psychology, University of Amsterdam, 1018 XA Amsterdam, The 
Netherlands; Amsterdam Brain and Cognition (ABC), University of Amsterdam, 1018 
VZ Amsterdam, The Netherlands. Electronic address: M.Kindt@uva.nl.

Neuroimaging research on emotional memory has greatly advanced our understanding 
of the pathogenesis of anxiety disorders. While the behavioral expression of 
fear at the time of encoding does not predict whether an aversive experience 
will evolve into long-term fear memory, the application of multi-voxel pattern 
analysis (MVPA) for the analysis of BOLD-MRI data has recently provided a unique 
marker for memory formation. Here, we aimed to further investigate the utility 
of this marker by modulating the strength of fear memory with an α2-adrenoceptor 
antagonist (yohimbine HCl). Fifty-two healthy participants were randomly 
assigned to two conditions - either receiving 20mg yohimbine or a placebo pill 
(double-blind) - prior to differential fear conditioning and MRI-scanning. We 
examined the strength of fear associations during acquisition and retention of 
fear (48 h later) by assessing the similarity of BOLD-MRI patterns and pupil 
dilation responses. Additionally, participants returned for a follow-up test 
outside the scanner (2-4 weeks), during which we assessed fear-potentiated 
startle responses. Replicating our previous findings, neural pattern similarity 
reflected the development of fear associations over time, and unlike average 
activation or pupil dilation, predicted the later expression of fear memory 
(pupil dilation 48 h later). While no effect of yohimbine was observed on 
markers of autonomic arousal, including salivary α-amylase (sAA), we obtained 
indirect evidence for the noradrenergic enhancement of fear memory 
consolidation: sAA levels showed a strong increase prior to fMRI scanning, 
irrespective of whether participants had received yohimbine, and this increase 
correlated with the subsequent expression of fear (48 h later). Remarkably, this 
noradrenergic enhancement of fear was associated with changes in neural response 
patterns at the time of learning. These findings provide further evidence that 
representational similarity analysis is a sensitive tool for studying (enhanced) 
memory formation.

Copyright © 2015 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.psyneuen.2015.01.021
PMID: 25705798 [Indexed for MEDLINE]


231. Neuroimage. 2015 May 1;111:36-48. doi: 10.1016/j.neuroimage.2014.12.086. Epub 
2015 Feb 7.

Physics instruction induces changes in neural knowledge representation during 
successive stages of learning.

Mason RA(1), Just MA(2).

Author information:
(1)Center for Cognitive Brain Imaging, Psychology Department, Carnegie Mellon 
University, Pittsburgh, PA 15213, USA. Electronic address: 
rmason@andrew.cmu.edu.
(2)Center for Cognitive Brain Imaging, Psychology Department, Carnegie Mellon 
University, Pittsburgh, PA 15213, USA.

Incremental instruction on the workings of a set of mechanical systems induced a 
progression of changes in the neural representations of the systems. The neural 
representations of four mechanical systems were assessed before, during, and 
after three phases of incremental instruction (which first provided information 
about the system components, then provided partial causal information, and 
finally provided full functional information). In 14 participants, the neural 
representations of four systems (a bathroom scale, a fire extinguisher, an 
automobile braking system, and a trumpet) were assessed using three recently 
developed techniques: (1) machine learning and classification of multi-voxel 
patterns; (2) localization of consistently responding voxels; and (3) 
representational similarity analysis (RSA). The neural representations of the 
systems progressed through four stages, or states, involving spatially and 
temporally distinct multi-voxel patterns: (1) initially, the representation was 
primarily visual (occipital cortex); (2) it subsequently included a large 
parietal component; (3) it eventually became cortically diverse (frontal, 
parietal, temporal, and medial frontal regions); and (4) at the end, it 
demonstrated a strong frontal cortex weighting (frontal and motor regions). At 
each stage of knowledge, it was possible for a classifier to identify which one 
of four mechanical systems a participant was thinking about, based on their 
brain activation patterns. The progression of representational states was 
suggestive of progressive stages of learning: (1) encoding information from the 
display; (2) mental animation, possibly involving imagining the components 
moving; (3) generating causal hypotheses associated with mental animation; and 
finally (4) determining how a person (probably oneself) would interact with the 
system. This interpretation yields an initial, cortically-grounded, theory of 
learning of physical systems that potentially can be related to cognitive 
learning theories by suggesting links between cortical representations, stages 
of learning, and the understanding of simple systems.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2014.12.086
PMID: 25665967 [Indexed for MEDLINE]


232. Front Neuroinform. 2015 Jan 6;8:88. doi: 10.3389/fninf.2014.00088. eCollection 
2014.

The Decoding Toolbox (TDT): a versatile software package for multivariate 
analyses of functional imaging data.

Hebart MN(1), Görgen K(2), Haynes JD(3).

Author information:
(1)Department of Systems Neuroscience, University Medical Center 
Hamburg-Eppendorf Hamburg, Germany ; Bernstein Center for Computational 
Neuroscience, Charité Universitätsmedizin Berlin, Germany ; Berlin Center for 
Advanced Neuroimaging, Charité Universitätsmedizin Berlin, Germany ; Berlin 
School of Mind and Brain, Humboldt-Universität zu Berlin Berlin, Germany.
(2)Bernstein Center for Computational Neuroscience, Charité Universitätsmedizin 
Berlin, Germany ; Berlin Center for Advanced Neuroimaging, Charité 
Universitätsmedizin Berlin, Germany ; Fachgebiet Neurotechnologie, Technische 
Universität Berlin Berlin, Germany.
(3)Bernstein Center for Computational Neuroscience, Charité Universitätsmedizin 
Berlin, Germany ; Berlin Center for Advanced Neuroimaging, Charité 
Universitätsmedizin Berlin, Germany ; Berlin School of Mind and Brain, 
Humboldt-Universität zu Berlin Berlin, Germany.

The multivariate analysis of brain signals has recently sparked a great amount 
of interest, yet accessible and versatile tools to carry out decoding analyses 
are scarce. Here we introduce The Decoding Toolbox (TDT) which represents a 
user-friendly, powerful and flexible package for multivariate analysis of 
functional brain imaging data. TDT is written in Matlab and equipped with an 
interface to the widely used brain data analysis package SPM. The toolbox allows 
running fast whole-brain analyses, region-of-interest analyses and searchlight 
analyses, using machine learning classifiers, pattern correlation analysis, or 
representational similarity analysis. It offers automatic creation and 
visualization of diverse cross-validation schemes, feature scaling, nested 
parameter selection, a variety of feature selection methods, multiclass 
capabilities, and pattern reconstruction from classifier weights. While basic 
users can implement a generic analysis in one line of code, advanced users can 
extend the toolbox to their needs or exploit the structure to combine it with 
external high-performance classification toolboxes. The toolbox comes with an 
example data set which can be used to try out the various analysis methods. 
Taken together, TDT offers a promising option for researchers who want to employ 
multivariate analyses of brain activity patterns.

DOI: 10.3389/fninf.2014.00088
PMCID: PMC4285115
PMID: 25610393


233. Elife. 2015 Jan 13;4:e05025. doi: 10.7554/eLife.05025.

Delay-dependent contributions of medial temporal lobe regions to episodic memory 
retrieval.

Ritchey M(1), Montchal ME(1), Yonelinas AP(2), Ranganath C(1).

Author information:
(1)Center for Neuroscience, University of California, Davis, Davis, United 
States.
(2)Department of Psychology, University of California, Davis, Davis, United 
States.

The medial temporal lobes play an important role in episodic memory, but over 
time, hippocampal contributions to retrieval may be diminished. However, it is 
unclear whether such changes are related to the ability to retrieve contextual 
information, and whether they are common across all medial temporal regions. 
Here, we used functional neuroimaging to compare neural responses during 
immediate and delayed recognition. Results showed that recollection-related 
activity in the posterior hippocampus declined after a 1-day delay. In contrast, 
activity was relatively stable in the anterior hippocampus and in neocortical 
areas. Multi-voxel pattern similarity analyses also revealed that anterior 
hippocampal patterns contained information about context during item 
recognition, and after a delay, context coding in this region was related to 
successful retention of context information. Together, these findings suggest 
that the anterior and posterior hippocampus have different contributions to 
memory over time and that neurobiological models of memory must account for 
these differences.

DOI: 10.7554/eLife.05025
PMCID: PMC4337612
PMID: 25584461 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that no competing interests 
exist.


234. Front Neurosci. 2014 Nov 12;8:368. doi: 10.3389/fnins.2014.00368. eCollection 
2014.

Mapping tonotopic organization in human temporal cortex: representational 
similarity analysis in EMEG source space.

Su L(1), Zulfiqar I(2), Jamshed F(2), Fonteneau E(2), Marslen-Wilson W(3).

Author information:
(1)Department of Psychiatry, University of Cambridge Cambridge, UK ; Department 
of Psychology, University of Cambridge Cambridge, UK.
(2)Department of Psychology, University of Cambridge Cambridge, UK.
(3)Department of Psychology, University of Cambridge Cambridge, UK ; MRC 
Cognition and Brain Sciences Unit Cambridge, UK.

A wide variety of evidence, from neurophysiology, neuroanatomy, and imaging 
studies in humans and animals, suggests that human auditory cortex is in part 
tonotopically organized. Here we present a new means of resolving this spatial 
organization using a combination of non-invasive observables (EEG, MEG, and 
MRI), model-based estimates of spectrotemporal patterns of neural activation, 
and multivariate pattern analysis. The method exploits both the fine-grained 
temporal patterning of auditory cortical responses and the millisecond scale 
temporal resolution of EEG and MEG. Participants listened to 400 English words 
while MEG and scalp EEG were measured simultaneously. We estimated the location 
of cortical sources using the MRI anatomically constrained minimum norm estimate 
(MNE) procedure. We then combined a form of multivariate pattern analysis 
(representational similarity analysis) with a spatiotemporal searchlight 
approach to successfully decode information about patterns of neuronal frequency 
preference and selectivity in bilateral superior temporal cortex. Observed 
frequency preferences in and around Heschl's gyrus matched current proposals for 
the organization of tonotopic gradients in primary acoustic cortex, while the 
distribution of narrow frequency selectivity similarly matched results from the 
fMRI literature. The spatial maps generated by this novel combination of 
techniques seem comparable to those that have emerged from fMRI or ECOG studies, 
and a considerable advance over earlier MEG results.

DOI: 10.3389/fnins.2014.00368
PMCID: PMC4228977
PMID: 25429257


235. Front Neurosci. 2014 Sep 30;8:306. doi: 10.3389/fnins.2014.00306. eCollection 
2014.

Sensitivity of human auditory cortex to rapid frequency modulation revealed by 
multivariate representational similarity analysis.

Joanisse MF(1), DeSouza DD(1).

Author information:
(1)Department of Psychology, Brain and Mind Institute, The University of Western 
Ontario London, ON, Canada.

Functional Magnetic Resonance Imaging (fMRI) was used to investigate the extent, 
magnitude, and pattern of brain activity in response to rapid 
frequency-modulated sounds. We examined this by manipulating the direction (rise 
vs. fall) and the rate (fast vs. slow) of the apparent pitch of iterated rippled 
noise (IRN) bursts. Acoustic parameters were selected to capture features used 
in phoneme contrasts, however the stimuli themselves were not perceived as 
speech per se. Participants were scanned as they passively listened to sounds in 
an event-related paradigm. Univariate analyses revealed a greater level and 
extent of activation in bilateral auditory cortex in response to 
frequency-modulated sweeps compared to steady-state sounds. This effect was 
stronger in the left hemisphere. However, no regions showed selectivity for 
either rate or direction of frequency modulation. In contrast, multivoxel 
pattern analysis (MVPA) revealed feature-specific encoding for direction of 
modulation in auditory cortex bilaterally. Moreover, this effect was strongest 
when analyses were restricted to anatomical regions lying outside Heschl's 
gyrus. We found no support for feature-specific encoding of frequency modulation 
rate. Differential findings of modulation rate and direction of modulation are 
discussed with respect to their relevance to phonetic discrimination.

DOI: 10.3389/fnins.2014.00306
PMCID: PMC4179761
PMID: 25324713


236. Front Hum Neurosci. 2014 Sep 11;8:716. doi: 10.3389/fnhum.2014.00716. 
eCollection 2014.

Distributed cognitive maps reflecting real distances between places and views in 
the human brain.

Sulpizio V(1), Committeri G(2), Galati G(3).

Author information:
(1)Laboratory of Neuropsychology, Fondazione Santa Lucia IRCCS Roma, Italy.
(2)Department of Neuroscience, Imaging and Clinical Sciences, University G. 
d'Annunzio, and ITAB, Institute for Advanced Biomedical Technologies, G. 
d'Annunzio Foundation Chieti, Italy.
(3)Laboratory of Neuropsychology, Fondazione Santa Lucia IRCCS Roma, Italy ; 
Department of Psychology, Sapienza University Rome, Italy.

KEEPING ORIENTED IN THE ENVIRONMENT IS A MULTIFACETED ABILITY THAT REQUIRES 
KNOWLEDGE OF AT LEAST THREE PIECES OF INFORMATION: one's own location ("place") 
and orientation ("heading") within the environment, and which location in the 
environment one is looking at ("view"). We used functional magnetic resonance 
imaging (fMRI) in humans to examine the neural signatures of these information. 
Participants were scanned while viewing snapshots which varied for place, view 
and heading within a virtual room. We observed adaptation effects, proportional 
to the physical distances between consecutive places and views, in 
scene-responsive (retrosplenial complex and parahippocampal gyrus), 
fronto-parietal and lateral occipital regions. Multivoxel pattern classification 
of signals in scene-responsive regions and in the hippocampus allowed 
supra-chance decoding of place, view and heading, and revealed the existence of 
map-like representations, where places and views closer in physical space 
entailed activity patterns more similar in neural representational space. The 
pattern of hippocampal activity reflected both view- and place-based distances, 
the pattern of parahippocampal activity preferentially discriminated between 
views, and the pattern of retrosplenial activity combined place and view 
information, while the fronto-parietal cortex only showed transient effects of 
changes in place, view, and heading. Our findings provide evidence for the 
presence of map-like spatial representations which reflect metric distances in 
terms of both one's own and landmark locations.

DOI: 10.3389/fnhum.2014.00716
PMCID: PMC4160952
PMID: 25309392


237. J Cogn Neurosci. 2015 Apr;27(4):665-78. doi: 10.1162/jocn_a_00733. Epub 2014 Sep 
30.

The animacy continuum in the human ventral vision pathway.

Sha L(1), Haxby JV, Abdi H, Guntupalli JS, Oosterhof NN, Halchenko YO, Connolly 
AC.

Author information:
(1)Dartmouth College.

Major theories for explaining the organization of semantic memory in the human 
brain are premised on the often-observed dichotomous dissociation between living 
and nonliving objects. Evidence from neuroimaging has been interpreted to 
suggest that this distinction is reflected in the functional topography of the 
ventral vision pathway as lateral-to-medial activation gradients. Recently, we 
observed that similar activation gradients also reflect differences among living 
stimuli consistent with the semantic dimension of graded animacy. Here, we 
address whether the salient dichotomous distinction between living and nonliving 
objects is actually reflected in observable measured brain activity or whether 
previous observations of a dichotomous dissociation were the illusory result of 
stimulus sampling biases. Using fMRI, we measured neural responses while 
participants viewed 10 animal species with high to low animacy and two inanimate 
categories. Representational similarity analysis of the activity in ventral 
vision cortex revealed a main axis of variation with high-animacy species 
maximally different from artifacts and with the least animate species closest to 
artifacts. Although the associated functional topography mirrored activation 
gradients observed for animate-inanimate contrasts, we found no evidence for a 
dichotomous dissociation. We conclude that a central organizing principle of 
human object vision corresponds to the graded psychological property of animacy 
with no clear distinction between living and nonliving stimuli. The lack of 
evidence for a dichotomous dissociation in the measured brain activity 
challenges theories based on this premise.

DOI: 10.1162/jocn_a_00733
PMID: 25269114 [Indexed for MEDLINE]


238. Proc Natl Acad Sci U S A. 2014 Oct 7;111(40):14565-70. doi: 
10.1073/pnas.1402594111. Epub 2014 Sep 22.

Unique semantic space in the brain of each beholder predicts perceived 
similarity.

Charest I(1), Kievit RA(2), Schmitz TW(2), Deca D(3), Kriegeskorte N(1).

Author information:
(1)Medical Research Council Cognition and Brain Sciences Unit, Cambridge CB2 
7EF, United Kingdom; and ian.charest@mrc-cbu.cam.ac.uk 
nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk.
(2)Medical Research Council Cognition and Brain Sciences Unit, Cambridge CB2 
7EF, United Kingdom; and.
(3)Institute of Neuroscience, Technische Universität München, 80802 Munich, 
Germany.

The unique way in which each of us perceives the world must arise from our brain 
representations. If brain imaging could reveal an individual's unique mental 
representation, it could help us understand the biological substrate of our 
individual experiential worlds in mental health and disease. However, imaging 
studies of object vision have focused on commonalities between individuals 
rather than individual differences and on category averages rather than 
representations of particular objects. Here we investigate the individually 
unique component of brain representations of particular objects with functional 
MRI (fMRI). Subjects were presented with unfamiliar and personally meaningful 
object images while we measured their brain activity on two separate days. We 
characterized the representational geometry by the dissimilarity matrix of 
activity patterns elicited by particular object images. The representational 
geometry remained stable across scanning days and was unique in each individual 
in early visual cortex and human inferior temporal cortex (hIT). The hIT 
representation predicted perceived similarity as reflected in dissimilarity 
judgments. Importantly, hIT predicted the individually unique component of the 
judgments when the objects were personally meaningful. Our results suggest that 
hIT brain representational idiosyncrasies accessible to fMRI are expressed in an 
individual's perceptual judgments. The unique way each of us perceives the world 
thus might reflect the individually unique representation in high-level visual 
areas.

DOI: 10.1073/pnas.1402594111
PMCID: PMC4209976
PMID: 25246586 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflict of interest.


239. Hum Brain Mapp. 2015 Feb;36(2):475-88. doi: 10.1002/hbm.22641. Epub 2014 Sep 19.

Qualitatively different coding of symbolic and nonsymbolic numbers in the human 
brain.

Lyons IM(1), Ansari D, Beilock SL.

Author information:
(1)University of Western Ontario, London, Ontario, Canada.

Are symbolic and nonsymbolic numbers coded differently in the brain? Neuronal 
data indicate that overlap in numerical tuning curves is a hallmark of the 
approximate, analogue nature of nonsymbolic number representation. Consequently, 
patterns of fMRI activity should be more correlated when the representational 
overlap between two numbers is relatively high. In bilateral intraparietal sulci 
(IPS), for nonsymbolic numbers, the pattern of voxelwise correlations between 
pairs of numbers mirrored the amount of overlap in their tuning curves under the 
assumption of approximate, analogue coding. In contrast, symbolic numbers showed 
a flat field of modest correlations more consistent with discrete, categorical 
representation (no systematic overlap between numbers). Directly correlating 
activity patterns for a given number across formats (e.g., the numeral "6" with 
six dots) showed no evidence of shared symbolic and nonsymbolic number-specific 
representations. Overall (univariate) activity in bilateral IPS was well fit by 
the log of the number being processed for both nonsymbolic and symbolic numbers. 
IPS activity is thus sensitive to numerosity regardless of format; however, the 
nature in which symbolic and nonsymbolic numbers are encoded is fundamentally 
different.

© 2014 Wiley Periodicals, Inc.

DOI: 10.1002/hbm.22641
PMCID: PMC6869776
PMID: 25238646 [Indexed for MEDLINE]


240. J Cogn Neurosci. 2015 Jan;27(1):73-82. doi: 10.1162/jocn_a_00697.

Representational similarity of social and valence information in the medial pFC.

Chavez RS(1), Heatherton TF.

Author information:
(1)Dartmouth College.

The human brain is remarkably adept at integrating complex information to form 
unified psychological representations of agents, objects, and events in the 
environment. Two domains in which this ability is particularly salient are the 
processing of social and valence information and are supported by common 
cortical areas in the medial pFC (MPFC). Because social information is often 
embedded within valenced emotional contexts, it is possible that activation 
patterns within the MPFC may represent both of these types of cognitive 
processes when presented simultaneously. The current study tested this 
possibility by employing a large-scale automated meta-analysis tool, together 
with multivoxel pattern analysis to investigate the representational similarity 
of social and valence information in the MPFC during fMRI. Using a 
representational similarity analysis, we found a high degree of representational 
similarity both within social dimensions and within valence dimensions, but not 
across them (e.g., positive social information was highly dissimilar to negative 
nonsocial information), in a ventral portion of the MPFC. These results were 
significantly correlated with a behaviorally measured similarity structure of 
the same stimuli, suggesting that a psychologically meaningful representation of 
social and valence information is reflected by multivoxel activation patterns in 
the ventral MPFC.

DOI: 10.1162/jocn_a_00697
PMCID: PMC4373660
PMID: 25100218 [Indexed for MEDLINE]


241. Annu Rev Neurosci. 2014;37:435-56. doi: 10.1146/annurev-neuro-062012-170325. 
Epub 2014 Jun 25.

Decoding neural representational spaces using multivariate pattern analysis.

Haxby JV(1), Connolly AC, Guntupalli JS.

Author information:
(1)Department of Psychological and Brain Sciences, Center for Cognitive 
Neuroscience, Dartmouth College, Hanover, New Hampshire 03755; email: 
james.v.haxby@dartmouth.edu , andrew.c.connolly@dartmouth.edu , 
swaroopgj@gmail.com.

A major challenge for systems neuroscience is to break the neural code. 
Computational algorithms for encoding information into neural activity and 
extracting information from measured activity afford understanding of how 
percepts, memories, thought, and knowledge are represented in patterns of brain 
activity. The past decade and a half has seen significant advances in the 
development of methods for decoding human neural activity, such as multivariate 
pattern classification, representational similarity analysis, hyperalignment, 
and stimulus-model-based encoding and decoding. This article reviews these 
advances and integrates neural decoding methods into a common framework 
organized around the concept of high-dimensional representational spaces.

DOI: 10.1146/annurev-neuro-062012-170325
PMID: 25002277 [Indexed for MEDLINE]


242. PLoS Comput Biol. 2014 Apr 17;10(4):e1003553. doi: 10.1371/journal.pcbi.1003553. 
eCollection 2014 Apr.

A toolbox for representational similarity analysis.

Nili H(1), Wingfield C(2), Walther A(1), Su L(3), Marslen-Wilson W(4), 
Kriegeskorte N(1).

Author information:
(1)MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom.
(2)Department of Computer Science, University of Bath, Bath, United Kingdom.
(3)MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom; Department 
of Experimental Psychology, University of Cambridge, Cambridge, United Kingdom.
(4)Department of Experimental Psychology, University of Cambridge, Cambridge, 
United Kingdom.

Neuronal population codes are increasingly being investigated with multivariate 
pattern-information analyses. A key challenge is to use measured brain-activity 
patterns to test computational models of brain information processing. One 
approach to this problem is representational similarity analysis (RSA), which 
characterizes a representation in a brain or computational model by the distance 
matrix of the response patterns elicited by a set of stimuli. The 
representational distance matrix encapsulates what distinctions between stimuli 
are emphasized and what distinctions are de-emphasized in the representation. A 
model is tested by comparing the representational distance matrix it predicts to 
that of a measured brain region. RSA also enables us to compare representations 
between stages of processing within a given brain or model, between brain and 
behavioral data, and between individuals and species. Here, we introduce a 
Matlab toolbox for RSA. The toolbox supports an analysis approach that is 
simultaneously data- and hypothesis-driven. It is designed to help integrate a 
wide range of computational models into the analysis of multichannel 
brain-activity measurements as provided by modern functional imaging and 
neuronal recording techniques. Tools for visualization and inference enable the 
user to relate sets of models to sets of brain regions and to statistically test 
and compare the models using nonparametric inference methods. The toolbox 
supports searchlight-based RSA, to continuously map a measured brain volume in 
search of a neuronal population code with a specific geometry. Finally, we 
introduce the linear-discriminant t value as a measure of representational 
discriminability that bridges the gap between linear decoding analyses and RSA. 
In order to demonstrate the capabilities of the toolbox, we apply it to both 
simulated and real fMRI data. The key functions are equally applicable to other 
modalities of brain-activity measurement. The toolbox is freely available to the 
community under an open-source license agreement 
(http://www.mrc-cbu.cam.ac.uk/methods-and-resources/toolboxes/license/).

DOI: 10.1371/journal.pcbi.1003553
PMCID: PMC3990488
PMID: 24743308 [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing 
interests exist.


243. J Neurosci. 2014 Apr 2;34(14):4766-75. doi: 10.1523/JNEUROSCI.2828-13.2014.

Object-specific semantic coding in human perirhinal cortex.

Clarke A(1), Tyler LK.

Author information:
(1)Centre for Speech, Language and the Brain, Department of Psychology, 
University of Cambridge, Cambridge CB2 3EB, United Kingdom.

Comment in
    J Neurosci. 2014 Aug 6;34(32):10462-4.

Category-specificity has been demonstrated in the human posterior ventral 
temporal cortex for a variety of object categories. Although object 
representations within the ventral visual pathway must be sufficiently rich and 
complex to support the recognition of individual objects, little is known about 
how specific objects are represented. Here, we used representational similarity 
analysis to determine what different kinds of object information are reflected 
in fMRI activation patterns and uncover the relationship between categorical and 
object-specific semantic representations. Our results show a gradient of 
informational specificity along the ventral stream from representations of 
image-based visual properties in early visual cortex, to categorical 
representations in the posterior ventral stream. A key finding showed that 
object-specific semantic information is uniquely represented in the perirhinal 
cortex, which was also increasingly engaged for objects that are more 
semantically confusable. These findings suggest a key role for the perirhinal 
cortex in representing and processing object-specific semantic information that 
is more critical for highly confusable objects. Our findings extend current 
distributed models by showing coarse dissociations between objects in posterior 
ventral cortex, and fine-grained distinctions between objects supported by the 
anterior medial temporal lobes, including the perirhinal cortex, which serve to 
integrate complex object information.

DOI: 10.1523/JNEUROSCI.2828-13.2014
PMCID: PMC6802719
PMID: 24695697 [Indexed for MEDLINE]


244. Nat Neurosci. 2014 Mar;17(3):455-62. doi: 10.1038/nn.3635. Epub 2014 Jan 26.

Resolving human object recognition in space and time.

Cichy RM(1), Pantazis D(2), Oliva A(1).

Author information:
(1)Computer Science and Artificial Intelligence Laboratory, Massachusetts 
Institute of Technology, Cambridge, Massachusetts, USA.
(2)McGovern Institute for Brain Research, Massachusetts Institute of Technology, 
Cambridge, Massachusetts, USA.

Comment in
    Nat Neurosci. 2014 Mar;17(3):332-3.

A comprehensive picture of object processing in the human brain requires 
combining both spatial and temporal information about brain activity. Here we 
acquired human magnetoencephalography (MEG) and functional magnetic resonance 
imaging (fMRI) responses to 92 object images. Multivariate pattern 
classification applied to MEG revealed the time course of object processing: 
whereas individual images were discriminated by visual representations early, 
ordinate and superordinate category levels emerged relatively late. Using 
representational similarity analysis, we combined human fMRI and MEG to show 
content-specific correspondence between early MEG responses and primary visual 
cortex (V1), and later MEG responses and inferior temporal (IT) cortex. We 
identified transient and persistent neural activities during object processing 
with sources in V1 and IT. Finally, we correlated human MEG signals to 
single-unit responses in monkey IT. Together, our findings provide an integrated 
space- and time-resolved view of human object categorization during the first 
few hundred milliseconds of vision.

DOI: 10.1038/nn.3635
PMCID: PMC4261693
PMID: 24464044 [Indexed for MEDLINE]


245. J Neurosci. 2014 Jan 1;34(1):163-70. doi: 10.1523/JNEUROSCI.1114-13.2014.

Nonvisual and visual object shape representations in occipitotemporal cortex: 
evidence from congenitally blind and sighted adults.

Peelen MV(1), He C, Han Z, Caramazza A, Bi Y.

Author information:
(1)Center for Mind/Brain Sciences, University of Trento, 38068 Rovereto, Italy, 
State Key Laboratory of Cognitive Neuroscience and Learning and IDG/McGovern 
Institute for Brain Research, Beijing Normal University, Beijing 100875, China, 
and Department of Psychology, Harvard University, Cambridge, Massachusetts 
02138.

Knowledge of object shape is primarily acquired through the visual modality but 
can also be acquired through other sensory modalities. In the present study, we 
investigated the representation of object shape in humans without visual 
experience. Congenitally blind and sighted participants rated the shape 
similarity of pairs of 33 familiar objects, referred to by their names. The 
resulting shape similarity matrices were highly similar for the two groups, 
indicating that knowledge of the objects' shapes was largely independent of 
visual experience. Using fMRI, we tested for brain regions that represented 
object shape knowledge in blind and sighted participants. Multivoxel activity 
patterns were established for each of the 33 aurally presented object names. 
Sighted participants additionally viewed pictures of these objects. Using 
representational similarity analysis, neural similarity matrices were related to 
the behavioral shape similarity matrices. Results showed that activity patterns 
in occipitotemporal cortex (OTC) regions, including inferior temporal (IT) 
cortex and functionally defined object-selective cortex (OSC), reflected the 
behavioral shape similarity ratings in both blind and sighted groups, also when 
controlling for the objects' tactile and semantic similarity. Furthermore, 
neural similarity matrices of IT and OSC showed similarities across blind and 
sighted groups (within the auditory modality) and across modality (within the 
sighted group), but not across both modality and group (blind auditory-sighted 
visual). Together, these findings provide evidence that OTC not only represents 
objects visually (requiring visual experience) but also represents objects 
nonvisually, reflecting knowledge of object shape independently of the modality 
through which this knowledge was acquired.

DOI: 10.1523/JNEUROSCI.1114-13.2014
PMCID: PMC6608164
PMID: 24381278 [Indexed for MEDLINE]


246. J Neurosci. 2013 Nov 27;33(48):18906-16. doi: 10.1523/JNEUROSCI.3809-13.2013.

Representational similarity analysis reveals commonalities and differences in 
the semantic processing of words and objects.

Devereux BJ(1), Clarke A, Marouchos A, Tyler LK.

Author information:
(1)Centre for Speech, Language, and the Brain, Department of Psychology, 
University of Cambridge, Cambridge, CB2 3EB, United Kingdom.

Understanding the meanings of words and objects requires the activation of 
underlying conceptual representations. Semantic representations are often 
assumed to be coded such that meaning is evoked regardless of the input 
modality. However, the extent to which meaning is coded in modality-independent 
or amodal systems remains controversial. We address this issue in a human fMRI 
study investigating the neural processing of concepts, presented separately as 
written words and pictures. Activation maps for each individual word and picture 
were used as input for searchlight-based multivoxel pattern analyses. 
Representational similarity analysis was used to identify regions correlating 
with low-level visual models of the words and objects and the semantic category 
structure common to both. Common semantic category effects for both modalities 
were found in a left-lateralized network, including left posterior middle 
temporal gyrus (LpMTG), left angular gyrus, and left intraparietal sulcus 
(LIPS), in addition to object- and word-specific semantic processing in ventral 
temporal cortex and more anterior MTG, respectively. To explore differences in 
representational content across regions and modalities, we developed novel 
data-driven analyses, based on k-means clustering of searchlight dissimilarity 
matrices and seeded correlation analysis. These revealed subtle differences in 
the representations in semantic-sensitive regions, with representations in LIPS 
being relatively invariant to stimulus modality and representations in LpMTG 
being uncorrelated across modality. These results suggest that, although both 
LpMTG and LIPS are involved in semantic processing, only the functional role of 
LIPS is the same regardless of the visual input, whereas the functional role of 
LpMTG differs for words and objects.

DOI: 10.1523/JNEUROSCI.3809-13.2013
PMCID: PMC3852350
PMID: 24285896 [Indexed for MEDLINE]


247. J Neurosci. 2013 Nov 20;33(47):18597-607. doi: 10.1523/JNEUROSCI.1548-13.2013.

Similarity of fMRI activity patterns in left perirhinal cortex reflects semantic 
similarity between words.

Bruffaerts R(1), Dupont P, Peeters R, De Deyne S, Storms G, Vandenberghe R.

Author information:
(1)Laboratory for Cognitive Neurology, Department of Neurosciences, Neurology 
Department, and Radiology Department, University Hospitals Leuven, 3000 Leuven, 
Belgium, and Laboratory of Experimental Psychology, Humanities and Social 
Sciences Group, University of Leuven, 3000 Leuven, Belgium.

How verbal and nonverbal visuoperceptual input connects to semantic knowledge is 
a core question in visual and cognitive neuroscience, with significant clinical 
ramifications. In an event-related functional magnetic resonance imaging (fMRI) 
experiment we determined how cosine similarity between fMRI response patterns to 
concrete words and pictures reflects semantic clustering and semantic distances 
between the represented entities within a single category. Semantic clustering 
and semantic distances between 24 animate entities were derived from a 
concept-feature matrix based on feature generation by >1000 subjects. In the 
main fMRI study, 19 human subjects performed a property verification task with 
written words and pictures and a low-level control task. The univariate contrast 
between the semantic and the control task yielded extensive bilateral 
occipitotemporal activation from posterior cingulate to anteromedial temporal 
cortex. Entities belonging to a same semantic cluster elicited more similar fMRI 
activity patterns in left occipitotemporal cortex. When words and pictures were 
analyzed separately, the effect reached significance only for words. The 
semantic similarity effect for words was localized to left perirhinal cortex. 
According to a representational similarity analysis of left perirhinal 
responses, semantic distances between entities correlated inversely with cosine 
similarities between fMRI response patterns to written words. An independent 
replication study in 16 novel subjects confirmed these novel findings. Semantic 
similarity is reflected by similarity of functional topography at a fine-grained 
level in left perirhinal cortex. The word specificity excludes perceptually 
driven confounds as an explanation and is likely to be task dependent.

DOI: 10.1523/JNEUROSCI.1548-13.2013
PMCID: PMC6618797
PMID: 24259581 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no conflicting financial 
interests.


248. J Neurosci. 2013 Nov 13;33(46):18247-58. doi: 10.1523/JNEUROSCI.1322-13.2013.

Body and object effectors: the organization of object representations in 
high-level visual cortex reflects body-object interactions.

Bracci S(1), Peelen MV.

Author information:
(1)Center for Mind/Brain Sciences, University of Trento, TN 38068 Rovereto, 
Italy.

Comment in
    J Neurosci. 2014 Feb 26;34(9):3119-21.

The principles driving the functional organization of object representations in 
high-level visual cortex are not yet fully understood. In four human fMRI 
experiments, we provide evidence that the organization of high-level visual 
cortex partly reflects the degree to which objects are typically controlled by 
the body to interact with the world, thereby extending the body's boundaries. 
Univariate whole-brain analysis showed an overlap between responses to body 
effectors (e.g., hands, feet, and limbs) and object effectors (e.g., hammers, 
combs, and tennis rackets) in lateral occipitotemporal cortex (LOTC) and 
parietal cortex. Region of interest analyses showed that a hand-selective region 
in left LOTC responded selectively to object effectors relative to a range of 
noneffector object control conditions (e.g., graspable objects, "act-on" 
objects, musical instruments). Object ratings showed that the strong response to 
object effectors in hand-selective LOTC was not due to general action-related 
object properties shared with these control conditions, such as hand priming, 
hand grasping, and hand-action centrality. Finally, whole-brain representational 
similarity analysis revealed that the similarity of multivoxel object response 
patterns in left lateral occipitotemporal cortex selectively predicted the 
degree to which objects were rated as being controlled by and extending the 
body. Together, these results reveal a clustering of body and object effector 
representations, indicating that the organization of object representations in 
high-level visual cortex partly reflects how objects relate to the body.

DOI: 10.1523/JNEUROSCI.1322-13.2013
PMCID: PMC6619748
PMID: 24227734 [Indexed for MEDLINE]


249. Curr Biol. 2013 Nov 18;23(22):2268-2272. doi: 10.1016/j.cub.2013.09.016. Epub 
2013 Oct 31.

Decoding the yellow of a gray banana.

Bannert MM(1), Bartels A(2).

Author information:
(1)Vision and Cognition Lab, Werner Reichardt Centre for Integrative 
Neuroscience, University of Tübingen, 72076 Tübingen, Germany; Bernstein Center 
for Computational Neuroscience, 72076 Tübingen, Germany. Electronic address: 
michael.bannert@tuebingen.mpg.de.
(2)Vision and Cognition Lab, Werner Reichardt Centre for Integrative 
Neuroscience, University of Tübingen, 72076 Tübingen, Germany; Bernstein Center 
for Computational Neuroscience, 72076 Tübingen, Germany. Electronic address: 
andreas.bartels@tuebingen.mpg.de.

Some everyday objects are associated with a particular color, such as bananas, 
which are typically yellow. Behavioral studies show that perception of these 
so-called color-diagnostic objects is influenced by our knowledge of their 
typical color, referred to as memory color. However, neural representations of 
memory colors are unknown. Here we investigated whether memory color can be 
decoded from visual cortex activity when color-diagnostic objects are viewed as 
grayscale images. We trained linear classifiers to distinguish patterns of fMRI 
responses to four different hues. We found that activity in V1 allowed 
predicting the memory color of color-diagnostic objects presented in grayscale 
in naive participants performing a motion task. The results imply that higher 
areas feed back memory-color signals to V1. When classifiers were trained on 
neural responses to some exemplars of color-diagnostic objects and tested on 
others, areas V4 and LOC also predicted memory colors. Representational 
similarity analysis showed that memory-color representations in V1 were 
correlated specifically with patterns in V4 but not LOC. Our findings suggest 
that prior knowledge is projected from midlevel visual regions onto primary 
visual cortex, consistent with predictive coding theory.

Copyright © 2013 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.cub.2013.09.016
PMID: 24184103 [Indexed for MEDLINE]


250. J Exp Psychol Gen. 2013 Nov;142(4):1264-76. doi: 10.1037/a0033609. Epub 2013 Jul 
8.

Distributed hippocampal patterns that discriminate reward context are associated 
with enhanced associative binding.

Wolosin SM(1), Zeithamova D, Preston AR.

Author information:
(1)Center for Learning and Memory.

Recent research indicates that reward-based motivation impacts medial temporal 
lobe (MTL) encoding processes, leading to enhanced memory for rewarded events. 
In particular, previous functional magnetic resonance imaging (fMRI) studies of 
motivated learning have shown that MTL activation is greater for highly rewarded 
events, with the degree of reward-related activation enhancement tracking the 
corresponding behavioral memory advantage. These studies, however, do not 
directly address leading theoretical perspectives that propose such reward-based 
enhancements in MTL encoding activation reflect enhanced discrimination of the 
motivational context of specific events. In this study, a high-value or 
low-value monetary cue preceded a pair of objects, indicating the future reward 
for successfully remembering the pair. Using representational similarity 
analysis and high-resolution fMRI, we show that MTL activation patterns are more 
similar for encoding trials preceded by the same versus different reward cues, 
indicating a distributed code in this region that distinguishes between 
motivational contexts. Moreover, we show that activation patterns in hippocampus 
and parahippocampal cortex (PHc) that differentiate reward conditions during 
anticipatory cues and object pairs relate to successful associative memory. 
Additionally, the degree to which patterns differentiate reward contexts in 
dentate gyrus/CA2,3 and PHc is related to individual differences in reward 
modulation of memory. Collectively, these findings suggest that distributed 
activation patterns in the human hippocampus and PHc reflect the rewards 
associated with individual events. Furthermore, we show that these activation 
patterns-which discriminate between reward conditions--may influence memory 
through the incorporation of information about motivational contexts into stored 
memory representations.

PsycINFO Database Record (c) 2013 APA, all rights reserved.

DOI: 10.1037/a0033609
PMCID: PMC4731099
PMID: 23834024 [Indexed for MEDLINE]


251. J Neurosci. 2013 Jun 19;33(25):10552-8. doi: 10.1523/JNEUROSCI.0051-13.2013.

Brain regions that represent amodal conceptual knowledge.

Fairhall SL(1), Caramazza A.

Author information:
(1)Center for Mind/Brain Sciences, University of Trento, Trento, 38068, Italy. 
fairhall@wjh.harvard.edu

To what extent do the brain regions implicated in semantic processing contribute 
to the representation of amodal conceptual content rather than modality-specific 
mechanisms or mechanisms of semantic access and manipulation? Here, we propose 
that a brain region can be considered to represent amodal conceptual object 
knowledge if it is supramodal and plays a role in distinguishing among the 
conceptual representations of different objects. In an fMRI study, human 
participants made category typicality judgments about pictured objects or their 
names drawn from five different categories. Crossmodal multivariate pattern 
analysis revealed a network of six left-lateralized regions largely outside of 
category-selective visual cortex that showed a supramodal representation of 
object categories. These were located in the posterior middle/inferior temporal 
gyrus (pMTG/ITG), angular gyrus, ventral temporal cortex, posterior 
cingulate/precuneus (PC), and lateral and dorsomedial prefrontal cortex. 
Representational similarity analysis within these regions determined that the 
similarity between category-specific patterns of neural activity in the pMTG/ITG 
and the PC was consistent with the semantic similarity between these categories. 
This finding supports the PC and pMTG/ITG as candidate regions for the amodal 
representation of the conceptual properties of objects.

DOI: 10.1523/JNEUROSCI.0051-13.2013
PMCID: PMC6618586
PMID: 23785167 [Indexed for MEDLINE]


252. Front Psychol. 2013 Mar 22;4:128. doi: 10.3389/fpsyg.2013.00128. eCollection 
2013.

Human Object-Similarity Judgments Reflect and Transcend the Primate-IT Object 
Representation.

Mur M(1), Meys M, Bodurka J, Goebel R, Bandettini PA, Kriegeskorte N.

Author information:
(1)Section on Functional Imaging Methods, Laboratory of Brain and Cognition, 
National Institute of Mental Health, National Institutes of Health Bethesda, MD, 
USA ; Department of Cognitive Neuroscience, Faculty of Psychology and 
Neuroscience, Maastricht University Maastricht, Netherlands.

Primate inferior temporal (IT) cortex is thought to contain a high-level 
representation of objects at the interface between vision and semantics. This 
suggests that the perceived similarity of real-world objects might be predicted 
from the IT representation. Here we show that objects that elicit similar 
activity patterns in human IT (hIT) tend to be judged as similar by humans. The 
IT representation explained the human judgments better than early visual cortex, 
other ventral-stream regions, and a range of computational models. Human 
similarity judgments exhibited category clusters that reflected several 
categorical divisions that are prevalent in the IT representation of both human 
and monkey, including the animate/inanimate and the face/body division. Human 
judgments also reflected the within-category representation of IT. However, the 
judgments transcended the IT representation in that they introduced additional 
categorical divisions. In particular, human judgments emphasized human-related 
additional divisions between human and non-human animals and between man-made 
and natural objects. hIT was more similar to monkey IT than to human judgments. 
One interpretation is that IT has evolved visual-feature detectors that 
distinguish between animates and inanimates and between faces and bodies because 
these divisions are fundamental to survival and reproduction for all primate 
species, and that other brain systems serve to more flexibly introduce 
species-dependent and evolutionarily more recent divisions.

DOI: 10.3389/fpsyg.2013.00128
PMCID: PMC3605517
PMID: 23525516


253. Neuroimage. 2011 Apr 15;55(4):1665-78. doi: 10.1016/j.neuroimage.2011.01.044. 
Epub 2011 Jan 20.

Comparing the similarity and spatial structure of neural representations: a 
pattern-component model.

Diedrichsen J(1), Ridgway GR, Friston KJ, Wiestler T.

Author information:
(1)Institute of Cognitive Neuroscience, University College London, London, UK. 
j.diedrichsen@ucl.ac.uk

In recent years there has been growing interest in multivariate analyses of 
neuroimaging data, which can be used to detect distributed patterns of activity 
that encode an experimental factor of interest. In this setting, it has become 
common practice to study the correlations between patterns to make inferences 
about the way a brain region represents stimuli or tasks (known as 
representational similarity analysis). Although it would be of great interest to 
compare these correlations from different regions, direct comparisons are 
currently not possible. This is because sample correlations are strongly 
influenced by voxel-selection, fMRI noise, and nonspecific activation patterns, 
all of which can differ widely between regions. Here, we present a multivariate 
modeling framework in which the measured patterns are decomposed into their 
constituent parts. The model is based on a standard linear mixed model, in which 
pattern components are considered to be randomly distributed over voxels. The 
model allows one to estimate the true correlations of the underlying neuronal 
pattern components, thereby enabling comparisons between different regions or 
individuals. The pattern estimates also allow us to make inferences about the 
spatial structure of different response components. Thus, the new model provides 
a theoretical and analytical framework to study the structure of distributed 
neural representations.

Copyright © 2011 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2011.01.044
PMCID: PMC3221047
PMID: 21256225 [Indexed for MEDLINE]


254. Front Syst Neurosci. 2008 Nov 24;2:4. doi: 10.3389/neuro.06.004.2008. 
eCollection 2008.

Representational similarity analysis - connecting the branches of systems 
neuroscience.

Kriegeskorte N(1), Mur M, Bandettini P.

Author information:
(1)Section on Functional Imaging Methods, Laboratory of Brain and Cognition, 
National Institute of Mental Health, National Institutes of Health Bethesda, MD, 
USA.

A FUNDAMENTAL CHALLENGE FOR SYSTEMS NEUROSCIENCE IS TO QUANTITATIVELY RELATE ITS 
THREE MAJOR BRANCHES OF RESEARCH: brain-activity measurement, behavioral 
measurement, and computational modeling. Using measured brain-activity patterns 
to evaluate computational network models is complicated by the need to define 
the correspondency between the units of the model and the channels of the 
brain-activity data, e.g., single-cell recordings or voxels from functional 
magnetic resonance imaging (fMRI). Similar correspondency problems complicate 
relating activity patterns between different modalities of brain-activity 
measurement (e.g., fMRI and invasive or scalp electrophysiology), and between 
subjects and species. In order to bridge these divides, we suggest abstracting 
from the activity patterns themselves and computing representational 
dissimilarity matrices (RDMs), which characterize the information carried by a 
given representation in a brain or model. Building on a rich psychological and 
mathematical literature on similarity analysis, we propose a new experimental 
and data-analytical framework called representational similarity analysis (RSA), 
in which multi-channel measures of neural activity are quantitatively related to 
each other and to computational theory and behavior by comparing RDMs. We 
demonstrate RSA by relating representations of visual objects as measured with 
fMRI in early visual cortex and the fusiform face area to computational models 
spanning a wide range of complexities. The RDMs are simultaneously related via 
second-level application of multidimensional scaling and tested using 
randomization and bootstrap techniques. We discuss the broad potential of RSA, 
including novel approaches to experimental design, and argue that these ideas, 
which have deep roots in psychology and neuroscience, will allow the integrated 
quantitative analysis of data from all three branches, thus contributing to a 
more unified systems neuroscience.

DOI: 10.3389/neuro.06.004.2008
PMCID: PMC2605405
PMID: 19104670